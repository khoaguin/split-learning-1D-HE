{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from icecream import ic\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import syft as sy\n",
        "from syft.core.node.vm.vm import VirtualMachine\n",
        "from syft.core.node.vm.client import VirtualMachineClient\n",
        "from syft.ast.module import Module\n",
        "from syft.core.remote_dataloader import RemoteDataLoader\n",
        "from syft.core.remote_dataloader import RemoteDataset\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'syft version: {sy.__version__}')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch version: 1.8.1+cu102\nsyft version: 0.5.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1631728123882
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Files and Directories"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to files and directories\n",
        "project_path = Path.cwd().parent\n",
        "print(f'project_path: {project_path}')\n",
        "data_dir = 'mitdb'\n",
        "train_name = 'train_ecg.hdf5'\n",
        "test_name = 'test_ecg.hdf5'\n",
        "all_name = 'all_ecg.hdf5'\n",
        "model_dir = 'model'\n",
        "model_name = 'conv2'\n",
        "model_ext = '.pth'\n",
        "csv_dir = 'csv'\n",
        "csv_ext = '.csv'\n",
        "csv_name = 'conv2'\n",
        "csv_accs_name = 'accs_conv2'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "project_path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80-56gbram/code/Users/dkn.work/split-learning-he\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728124365
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the client and server"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "server: VirtualMachine = sy.VirtualMachine(name=\"server\")\n",
        "client: VirtualMachineClient = server.get_root_client()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728125060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_torch: Module = client.torch\n",
        "remote_torch"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Module:\n\t.Tensor -> <syft.ast.klass.Class object at 0x7efd95c13280>\n\t.BFloat16Tensor -> <syft.ast.klass.Class object at 0x7efd95c132e0>\n\t.BoolTensor -> <syft.ast.klass.Class object at 0x7efd95c13340>\n\t.ByteTensor -> <syft.ast.klass.Class object at 0x7efd95c133a0>\n\t.CharTensor -> <syft.ast.klass.Class object at 0x7efd95c13400>\n\t.DoubleTensor -> <syft.ast.klass.Class object at 0x7efd95c13460>\n\t.FloatTensor -> <syft.ast.klass.Class object at 0x7efd95c134c0>\n\t.HalfTensor -> <syft.ast.klass.Class object at 0x7efd95c13520>\n\t.IntTensor -> <syft.ast.klass.Class object at 0x7efd95c13580>\n\t.LongTensor -> <syft.ast.klass.Class object at 0x7efd95c135e0>\n\t.ShortTensor -> <syft.ast.klass.Class object at 0x7efd95c13640>\n\t.nn -> Module:\n\t\t.Parameter -> <syft.ast.klass.Class object at 0x7efd95c13760>\n\t\t.Module -> <syft.ast.klass.Class object at 0x7efd95b60c40>\n\t\t.Conv2d -> <syft.ast.klass.Class object at 0x7efd95b65160>\n\t\t.Dropout2d -> <syft.ast.klass.Class object at 0x7efd95b65580>\n\t\t.Linear -> <syft.ast.klass.Class object at 0x7efd95b658e0>\n\t\t.functional -> Module:\n\t\t\t.relu -> <syft.ast.callable.Callable object at 0x7efd95b68220>\n\t\t\t.gelu -> <syft.ast.callable.Callable object at 0x7efd95b68280>\n\t\t\t.max_pool2d -> <syft.ast.callable.Callable object at 0x7efd95b682e0>\n\t\t\t.log_softmax -> <syft.ast.callable.Callable object at 0x7efd95b68340>\n\t\t\t.cosine_embedding_loss -> <syft.ast.callable.Callable object at 0x7efd95af2100>\n\t\t\t.ctc_loss -> <syft.ast.callable.Callable object at 0x7efd95af2160>\n\t\t\t.hinge_embedding_loss -> <syft.ast.callable.Callable object at 0x7efd95af2220>\n\t\t\t.l1_loss -> <syft.ast.callable.Callable object at 0x7efd95af2280>\n\t\t\t.margin_ranking_loss -> <syft.ast.callable.Callable object at 0x7efd95af2340>\n\t\t\t.mse_loss -> <syft.ast.callable.Callable object at 0x7efd95af23a0>\n\t\t\t.multi_margin_loss -> <syft.ast.callable.Callable object at 0x7efd95af2460>\n\t\t\t.multilabel_margin_loss -> <syft.ast.callable.Callable object at 0x7efd95af2520>\n\t\t\t.multilabel_soft_margin_loss -> <syft.ast.callable.Callable object at 0x7efd95af25e0>\n\t\t\t.nll_loss -> <syft.ast.callable.Callable object at 0x7efd95af2640>\n\t\t\t.cross_entropy -> <syft.ast.callable.Callable object at 0x7efd95af2700>\n\t\t\t.poisson_nll_loss -> <syft.ast.callable.Callable object at 0x7efd95af27c0>\n\t\t\t.smooth_l1_loss -> <syft.ast.callable.Callable object at 0x7efd95af2880>\n\t\t\t.soft_margin_loss -> <syft.ast.callable.Callable object at 0x7efd95af2940>\n\t\t\t.triplet_margin_loss -> <syft.ast.callable.Callable object at 0x7efd95af2a00>\n\n\t\t.Sequential -> <syft.ast.klass.Class object at 0x7efd95b6ed00>\n\t\t.AdaptiveLogSoftmaxWithLoss -> <syft.ast.klass.Class object at 0x7efd95af2ac0>\n\t\t.BCELoss -> <syft.ast.klass.Class object at 0x7efd95af2c40>\n\t\t.BCEWithLogitsLoss -> <syft.ast.klass.Class object at 0x7efd95af2d00>\n\t\t.CTCLoss -> <syft.ast.klass.Class object at 0x7efd95af2e20>\n\t\t.CrossEntropyLoss -> <syft.ast.klass.Class object at 0x7efd95af2ee0>\n\t\t.CosineEmbeddingLoss -> <syft.ast.klass.Class object at 0x7efd95af6040>\n\t\t.HingeEmbeddingLoss -> <syft.ast.klass.Class object at 0x7efd95af6160>\n\t\t.KLDivLoss -> <syft.ast.klass.Class object at 0x7efd95af6280>\n\t\t.L1Loss -> <syft.ast.klass.Class object at 0x7efd95af6340>\n\t\t.MSELoss -> <syft.ast.klass.Class object at 0x7efd95af6400>\n\t\t.MarginRankingLoss -> <syft.ast.klass.Class object at 0x7efd95af64c0>\n\t\t.MultiLabelMarginLoss -> <syft.ast.klass.Class object at 0x7efd95af65e0>\n\t\t.MultiLabelSoftMarginLoss -> <syft.ast.klass.Class object at 0x7efd95af6760>\n\t\t.MultiMarginLoss -> <syft.ast.klass.Class object at 0x7efd95af6880>\n\t\t.NLLLoss -> <syft.ast.klass.Class object at 0x7efd95af69a0>\n\t\t.NLLLoss2d -> <syft.ast.klass.Class object at 0x7efd95af6a60>\n\t\t.PoissonNLLLoss -> <syft.ast.klass.Class object at 0x7efd95af6b20>\n\t\t.SmoothL1Loss -> <syft.ast.klass.Class object at 0x7efd95af6c40>\n\t\t.SoftMarginLoss -> <syft.ast.klass.Class object at 0x7efd95af6d00>\n\t\t.TripletMarginLoss -> <syft.ast.klass.Class object at 0x7efd95af6e20>\n\t\t.AdaptiveAvgPool1d -> <syft.ast.klass.Class object at 0x7efd95af6f40>\n\t\t.AdaptiveAvgPool2d -> <syft.ast.klass.Class object at 0x7efd95afb5e0>\n\t\t.AdaptiveAvgPool3d -> <syft.ast.klass.Class object at 0x7efd95afbc40>\n\t\t.AdaptiveMaxPool1d -> <syft.ast.klass.Class object at 0x7efd95afd2e0>\n\t\t.AdaptiveMaxPool2d -> <syft.ast.klass.Class object at 0x7efd95afd940>\n\t\t.AdaptiveMaxPool3d -> <syft.ast.klass.Class object at 0x7efd95afdfa0>\n\t\t.AlphaDropout -> <syft.ast.klass.Class object at 0x7efd95b01640>\n\t\t.AvgPool1d -> <syft.ast.klass.Class object at 0x7efd95b01be0>\n\t\t.AvgPool2d -> <syft.ast.klass.Class object at 0x7efd95b040a0>\n\t\t.AvgPool3d -> <syft.ast.klass.Class object at 0x7efd95b04520>\n\t\t.BatchNorm1d -> <syft.ast.klass.Class object at 0x7efd95b049a0>\n\t\t.BatchNorm2d -> <syft.ast.klass.Class object at 0x7efd95b04e20>\n\t\t.BatchNorm3d -> <syft.ast.klass.Class object at 0x7efd95b082e0>\n\t\t.Bilinear -> <syft.ast.klass.Class object at 0x7efd95b08760>\n\t\t.CELU -> <syft.ast.klass.Class object at 0x7efd95b08be0>\n\t\t.ConstantPad1d -> <syft.ast.klass.Class object at 0x7efd95b0c040>\n\t\t.ConstantPad2d -> <syft.ast.klass.Class object at 0x7efd95b0c5e0>\n\t\t.ConstantPad3d -> <syft.ast.klass.Class object at 0x7efd95b0cb80>\n\t\t.Container -> <syft.ast.klass.Class object at 0x7efd95b10160>\n\t\t.Conv1d -> <syft.ast.klass.Class object at 0x7efd95b105e0>\n\t\t.Conv3d -> <syft.ast.klass.Class object at 0x7efd95b10a00>\n\t\t.ConvTranspose1d -> <syft.ast.klass.Class object at 0x7efd95b10e20>\n\t\t.ConvTranspose2d -> <syft.ast.klass.Class object at 0x7efd95b13460>\n\t\t.ConvTranspose3d -> <syft.ast.klass.Class object at 0x7efd95b13a60>\n\t\t.CosineSimilarity -> <syft.ast.klass.Class object at 0x7efd95b180a0>\n\t\t.CrossMapLRN2d -> <syft.ast.klass.Class object at 0x7efd95b186a0>\n\t\t.DataParallel -> <syft.ast.klass.Class object at 0x7efd95b18c40>\n\t\t.Dropout -> <syft.ast.klass.Class object at 0x7efd95b1b220>\n\t\t.Dropout3d -> <syft.ast.klass.Class object at 0x7efd95b1b7c0>\n\t\t.ELU -> <syft.ast.klass.Class object at 0x7efd95b1bc40>\n\t\t.Embedding -> <syft.ast.klass.Class object at 0x7efd95b1e040>\n\t\t.EmbeddingBag -> <syft.ast.klass.Class object at 0x7efd95b1e4c0>\n\t\t.FeatureAlphaDropout -> <syft.ast.klass.Class object at 0x7efd95b1ea60>\n\t\t.Flatten -> <syft.ast.klass.Class object at 0x7efd95b221c0>\n\t\t.Fold -> <syft.ast.klass.Class object at 0x7efd95b22640>\n\t\t.FractionalMaxPool2d -> <syft.ast.klass.Class object at 0x7efd95b22a60>\n\t\t.FractionalMaxPool3d -> <syft.ast.klass.Class object at 0x7efd95b261c0>\n\t\t.GELU -> <syft.ast.klass.Class object at 0x7efd95b268e0>\n\t\t.GLU -> <syft.ast.klass.Class object at 0x7efd95b26d00>\n\t\t.GRU -> <syft.ast.klass.Class object at 0x7efd95b28100>\n\t\t.GRUCell -> <syft.ast.klass.Class object at 0x7efd95b284c0>\n\t\t.GroupNorm -> <syft.ast.klass.Class object at 0x7efd95b28940>\n\t\t.Hardshrink -> <syft.ast.klass.Class object at 0x7efd95b28dc0>\n\t\t.Hardsigmoid -> <syft.ast.klass.Class object at 0x7efd95b2e280>\n\t\t.Hardswish -> <syft.ast.klass.Class object at 0x7efd95b2e640>\n\t\t.Hardtanh -> <syft.ast.klass.Class object at 0x7efd95b2ea00>\n\t\t.Identity -> <syft.ast.klass.Class object at 0x7efd95b2ee80>\n\t\t.InstanceNorm1d -> <syft.ast.klass.Class object at 0x7efd95ab1340>\n\t\t.InstanceNorm2d -> <syft.ast.klass.Class object at 0x7efd95ab1940>\n\t\t.InstanceNorm3d -> <syft.ast.klass.Class object at 0x7efd95ab1f40>\n\t\t.LPPool1d -> <syft.ast.klass.Class object at 0x7efd95ab6580>\n\t\t.LPPool2d -> <syft.ast.klass.Class object at 0x7efd95ab6a00>\n\t\t.LSTM -> <syft.ast.klass.Class object at 0x7efd95ab6e80>\n\t\t.LSTMCell -> <syft.ast.klass.Class object at 0x7efd95ab92e0>\n\t\t.LayerNorm -> <syft.ast.klass.Class object at 0x7efd95ab9760>\n\t\t.LeakyReLU -> <syft.ast.klass.Class object at 0x7efd95ab9be0>\n\t\t.LocalResponseNorm -> <syft.ast.klass.Class object at 0x7efd95abd0a0>\n\t\t.LogSigmoid -> <syft.ast.klass.Class object at 0x7efd95abd700>\n\t\t.LogSoftmax -> <syft.ast.klass.Class object at 0x7efd95abdb80>\n\t\t.MaxPool1d -> <syft.ast.klass.Class object at 0x7efd95ac0040>\n\t\t.MaxPool2d -> <syft.ast.klass.Class object at 0x7efd95ac04c0>\n\t\t.MaxPool3d -> <syft.ast.klass.Class object at 0x7efd95ac0940>\n\t\t.MaxUnpool1d -> <syft.ast.klass.Class object at 0x7efd95ac0dc0>\n\t\t.MaxUnpool2d -> <syft.ast.klass.Class object at 0x7efd95ac5280>\n\t\t.MaxUnpool3d -> <syft.ast.klass.Class object at 0x7efd95ac5700>\n\t\t.ModuleDict -> <syft.ast.klass.Class object at 0x7efd95ac5b80>\n\t\t.ModuleList -> <syft.ast.klass.Class object at 0x7efd95aca040>\n\t\t.MultiheadAttention -> <syft.ast.klass.Class object at 0x7efd95aca580>\n\t\t.PReLU -> <syft.ast.klass.Class object at 0x7efd95acac40>\n\t\t.PairwiseDistance -> <syft.ast.klass.Class object at 0x7efd95acd0a0>\n\t\t.PixelShuffle -> <syft.ast.klass.Class object at 0x7efd95acd6a0>\n\t\t.RNN -> <syft.ast.klass.Class object at 0x7efd95acdc40>\n\t\t.RNNBase -> <syft.ast.klass.Class object at 0x7efd95ad1040>\n\t\t.RNNCell -> <syft.ast.klass.Class object at 0x7efd95ad14c0>\n\t\t.RNNCellBase -> <syft.ast.klass.Class object at 0x7efd95ad1940>\n\t\t.RReLU -> <syft.ast.klass.Class object at 0x7efd95ad1dc0>\n\t\t.ReLU -> <syft.ast.klass.Class object at 0x7efd95ad4220>\n\t\t.ReLU6 -> <syft.ast.klass.Class object at 0x7efd95ad4640>\n\t\t.ReflectionPad1d -> <syft.ast.klass.Class object at 0x7efd95ad4a60>\n\t\t.ReflectionPad2d -> <syft.ast.klass.Class object at 0x7efd95ad90a0>\n\t\t.ReplicationPad1d -> <syft.ast.klass.Class object at 0x7efd95ad96a0>\n\t\t.ReplicationPad2d -> <syft.ast.klass.Class object at 0x7efd95ad9ca0>\n\t\t.ReplicationPad3d -> <syft.ast.klass.Class object at 0x7efd95adc2e0>\n\t\t.SELU -> <syft.ast.klass.Class object at 0x7efd95adc8e0>\n\t\t.Sigmoid -> <syft.ast.klass.Class object at 0x7efd95adce80>\n\t\t.Softmax -> <syft.ast.klass.Class object at 0x7efd95adf340>\n\t\t.Softmax2d -> <syft.ast.klass.Class object at 0x7efd95adf7c0>\n\t\t.Softmin -> <syft.ast.klass.Class object at 0x7efd95adfc40>\n\t\t.Softplus -> <syft.ast.klass.Class object at 0x7efd95ae4100>\n\t\t.Softshrink -> <syft.ast.klass.Class object at 0x7efd95ae4580>\n\t\t.Softsign -> <syft.ast.klass.Class object at 0x7efd95ae4a00>\n\t\t.SyncBatchNorm -> <syft.ast.klass.Class object at 0x7efd95ae4e80>\n\t\t.Tanh -> <syft.ast.klass.Class object at 0x7efd95ae8460>\n\t\t.Tanhshrink -> <syft.ast.klass.Class object at 0x7efd95ae8880>\n\t\t.Threshold -> <syft.ast.klass.Class object at 0x7efd95ae8d00>\n\t\t.Transformer -> <syft.ast.klass.Class object at 0x7efd95aec1c0>\n\t\t.TransformerDecoder -> <syft.ast.klass.Class object at 0x7efd95aec640>\n\t\t.TransformerDecoderLayer -> <syft.ast.klass.Class object at 0x7efd95aecd60>\n\t\t.TransformerEncoder -> <syft.ast.klass.Class object at 0x7efd95aef400>\n\t\t.TransformerEncoderLayer -> <syft.ast.klass.Class object at 0x7efd95aefb20>\n\t\t.Unfold -> <syft.ast.klass.Class object at 0x7efd95a721c0>\n\t\t.Upsample -> <syft.ast.klass.Class object at 0x7efd95a725e0>\n\t\t.UpsamplingBilinear2d -> <syft.ast.klass.Class object at 0x7efd95a72a60>\n\t\t.UpsamplingNearest2d -> <syft.ast.klass.Class object at 0x7efd95a76160>\n\t\t.ZeroPad2d -> <syft.ast.klass.Class object at 0x7efd95a76880>\n\n\t.return_types -> Module:\n\t\t.cummax -> <syft.ast.klass.Class object at 0x7efd95be34c0>\n\t\t.cummin -> <syft.ast.klass.Class object at 0x7efd95be3520>\n\t\t.eig -> <syft.ast.klass.Class object at 0x7efd95be3580>\n\t\t.kthvalue -> <syft.ast.klass.Class object at 0x7efd95be35e0>\n\t\t.lstsq -> <syft.ast.klass.Class object at 0x7efd95be3640>\n\t\t.slogdet -> <syft.ast.klass.Class object at 0x7efd95be36a0>\n\t\t.qr -> <syft.ast.klass.Class object at 0x7efd95be3700>\n\t\t.mode -> <syft.ast.klass.Class object at 0x7efd95be3760>\n\t\t.solve -> <syft.ast.klass.Class object at 0x7efd95be37c0>\n\t\t.sort -> <syft.ast.klass.Class object at 0x7efd95be3820>\n\t\t.symeig -> <syft.ast.klass.Class object at 0x7efd95be3880>\n\t\t.topk -> <syft.ast.klass.Class object at 0x7efd95be38e0>\n\t\t.triangular_solve -> <syft.ast.klass.Class object at 0x7efd95be39a0>\n\t\t.svd -> <syft.ast.klass.Class object at 0x7efd95be3a00>\n\t\t.geqrf -> <syft.ast.klass.Class object at 0x7efd95be3a60>\n\t\t.median -> <syft.ast.klass.Class object at 0x7efd95be3ac0>\n\t\t.max -> <syft.ast.klass.Class object at 0x7efd95be3b20>\n\t\t.min -> <syft.ast.klass.Class object at 0x7efd95be3b80>\n\n\t.Size -> <syft.ast.klass.Class object at 0x7efd95b3cca0>\n\t.set_grad_enabled -> <syft.ast.klass.Class object at 0x7efd95b3cfa0>\n\t.zeros -> <syft.ast.callable.Callable object at 0x7efd95b42040>\n\t.randn -> <syft.ast.callable.Callable object at 0x7efd95b420a0>\n\t.ones_like -> <syft.ast.callable.Callable object at 0x7efd95b42100>\n\t.arange -> <syft.ast.callable.Callable object at 0x7efd95b42220>\n\t.abs_ -> <syft.ast.callable.Callable object at 0x7efd95b42280>\n\t.abs -> <syft.ast.callable.Callable object at 0x7efd95b422e0>\n\t.acos_ -> <syft.ast.callable.Callable object at 0x7efd95b42340>\n\t.acos -> <syft.ast.callable.Callable object at 0x7efd95b423a0>\n\t.add -> <syft.ast.callable.Callable object at 0x7efd95b42400>\n\t.addbmm -> <syft.ast.callable.Callable object at 0x7efd95b42460>\n\t.addcdiv -> <syft.ast.callable.Callable object at 0x7efd95b424c0>\n\t.addcmul -> <syft.ast.callable.Callable object at 0x7efd95b42520>\n\t.addmm -> <syft.ast.callable.Callable object at 0x7efd95b42580>\n\t.addmv_ -> <syft.ast.callable.Callable object at 0x7efd95b425e0>\n\t.addmv -> <syft.ast.callable.Callable object at 0x7efd95b42640>\n\t.addr -> <syft.ast.callable.Callable object at 0x7efd95b426a0>\n\t.all -> <syft.ast.callable.Callable object at 0x7efd95b42700>\n\t.allclose -> <syft.ast.callable.Callable object at 0x7efd95b42760>\n\t.angle -> <syft.ast.callable.Callable object at 0x7efd95b427c0>\n\t.any -> <syft.ast.callable.Callable object at 0x7efd95b42820>\n\t.argmax -> <syft.ast.callable.Callable object at 0x7efd95b42880>\n\t.argmin -> <syft.ast.callable.Callable object at 0x7efd95b428e0>\n\t.argsort -> <syft.ast.callable.Callable object at 0x7efd95b42940>\n\t.as_strided_ -> <syft.ast.callable.Callable object at 0x7efd95b429a0>\n\t.as_strided -> <syft.ast.callable.Callable object at 0x7efd95b42a00>\n\t.asin_ -> <syft.ast.callable.Callable object at 0x7efd95b42a60>\n\t.asin -> <syft.ast.callable.Callable object at 0x7efd95b42ac0>\n\t.atan_ -> <syft.ast.callable.Callable object at 0x7efd95b42b20>\n\t.atan -> <syft.ast.callable.Callable object at 0x7efd95b42b80>\n\t.atan2 -> <syft.ast.callable.Callable object at 0x7efd95b42be0>\n\t.baddbmm -> <syft.ast.callable.Callable object at 0x7efd95b42c40>\n\t.bernoulli -> <syft.ast.callable.Callable object at 0x7efd95b42ca0>\n\t.bitwise_and -> <syft.ast.callable.Callable object at 0x7efd95b42d00>\n\t.bitwise_not -> <syft.ast.callable.Callable object at 0x7efd95b42d60>\n\t.bitwise_or -> <syft.ast.callable.Callable object at 0x7efd95b42dc0>\n\t.bitwise_xor -> <syft.ast.callable.Callable object at 0x7efd95b42e20>\n\t.bmm -> <syft.ast.callable.Callable object at 0x7efd95b42e80>\n\t.cat -> <syft.ast.callable.Callable object at 0x7efd95b42ee0>\n\t.ceil_ -> <syft.ast.callable.Callable object at 0x7efd95b42f40>\n\t.ceil -> <syft.ast.callable.Callable object at 0x7efd95b42fa0>\n\t.cholesky_inverse -> <syft.ast.callable.Callable object at 0x7efd95b46040>\n\t.cholesky_solve -> <syft.ast.callable.Callable object at 0x7efd95b460a0>\n\t.cholesky -> <syft.ast.callable.Callable object at 0x7efd95b46100>\n\t.chunk -> <syft.ast.callable.Callable object at 0x7efd95b46160>\n\t.clamp_ -> <syft.ast.callable.Callable object at 0x7efd95b461c0>\n\t.clamp_max_ -> <syft.ast.callable.Callable object at 0x7efd95b46220>\n\t.clamp_max -> <syft.ast.callable.Callable object at 0x7efd95b46280>\n\t.clamp_min_ -> <syft.ast.callable.Callable object at 0x7efd95b462e0>\n\t.clamp_min -> <syft.ast.callable.Callable object at 0x7efd95b46340>\n\t.clamp -> <syft.ast.callable.Callable object at 0x7efd95b463a0>\n\t.clone -> <syft.ast.callable.Callable object at 0x7efd95b46400>\n\t.conj -> <syft.ast.callable.Callable object at 0x7efd95b46460>\n\t.cos_ -> <syft.ast.callable.Callable object at 0x7efd95b464c0>\n\t.cos -> <syft.ast.callable.Callable object at 0x7efd95b46520>\n\t.cosh_ -> <syft.ast.callable.Callable object at 0x7efd95b46580>\n\t.cosh -> <syft.ast.callable.Callable object at 0x7efd95b465e0>\n\t.cross -> <syft.ast.callable.Callable object at 0x7efd95b46640>\n\t.cummax -> <syft.ast.callable.Callable object at 0x7efd95b466a0>\n\t.cummin -> <syft.ast.callable.Callable object at 0x7efd95b46700>\n\t.cumprod -> <syft.ast.callable.Callable object at 0x7efd95b46760>\n\t.cumsum -> <syft.ast.callable.Callable object at 0x7efd95b467c0>\n\t.dequantize -> <syft.ast.callable.Callable object at 0x7efd95b46820>\n\t.det -> <syft.ast.callable.Callable object at 0x7efd95b46880>\n\t.detach -> <syft.ast.callable.Callable object at 0x7efd95b468e0>\n\t.diag_embed -> <syft.ast.callable.Callable object at 0x7efd95b46940>\n\t.diag -> <syft.ast.callable.Callable object at 0x7efd95b469a0>\n\t.diagflat -> <syft.ast.callable.Callable object at 0x7efd95b46a00>\n\t.diagonal -> <syft.ast.callable.Callable object at 0x7efd95b46a60>\n\t.digamma -> <syft.ast.callable.Callable object at 0x7efd95b46ac0>\n\t.dist -> <syft.ast.callable.Callable object at 0x7efd95b46b20>\n\t.div -> <syft.ast.callable.Callable object at 0x7efd95b46b80>\n\t.dot -> <syft.ast.callable.Callable object at 0x7efd95b46be0>\n\t.eig -> <syft.ast.callable.Callable object at 0x7efd95b46c40>\n\t.eq -> <syft.ast.callable.Callable object at 0x7efd95b46ca0>\n\t.equal -> <syft.ast.callable.Callable object at 0x7efd95b46d00>\n\t.erf_ -> <syft.ast.callable.Callable object at 0x7efd95b46d60>\n\t.erf -> <syft.ast.callable.Callable object at 0x7efd95b46dc0>\n\t.erfc_ -> <syft.ast.callable.Callable object at 0x7efd95b46e20>\n\t.erfc -> <syft.ast.callable.Callable object at 0x7efd95b46e80>\n\t.erfinv -> <syft.ast.callable.Callable object at 0x7efd95b46ee0>\n\t.exp_ -> <syft.ast.callable.Callable object at 0x7efd95b46f40>\n\t.exp -> <syft.ast.callable.Callable object at 0x7efd95b46fa0>\n\t.expm1_ -> <syft.ast.callable.Callable object at 0x7efd95b4a040>\n\t.expm1 -> <syft.ast.callable.Callable object at 0x7efd95b4a0a0>\n\t.fft -> Module:\n\n\t.fill_ -> <syft.ast.callable.Callable object at 0x7efd95b4a160>\n\t.flatten -> <syft.ast.callable.Callable object at 0x7efd95b4a1c0>\n\t.flip -> <syft.ast.callable.Callable object at 0x7efd95b4a220>\n\t.floor_ -> <syft.ast.callable.Callable object at 0x7efd95b4a280>\n\t.floor_divide -> <syft.ast.callable.Callable object at 0x7efd95b4a2e0>\n\t.floor -> <syft.ast.callable.Callable object at 0x7efd95b4a340>\n\t.fmod -> <syft.ast.callable.Callable object at 0x7efd95b4a3a0>\n\t.frac_ -> <syft.ast.callable.Callable object at 0x7efd95b4a400>\n\t.frac -> <syft.ast.callable.Callable object at 0x7efd95b4a460>\n\t.from_numpy -> <syft.ast.callable.Callable object at 0x7efd95b4a4c0>\n\t.gather -> <syft.ast.callable.Callable object at 0x7efd95b4a520>\n\t.ge -> <syft.ast.callable.Callable object at 0x7efd95b4a580>\n\t.geqrf -> <syft.ast.callable.Callable object at 0x7efd95b4a5e0>\n\t.ger -> <syft.ast.callable.Callable object at 0x7efd95b4a640>\n\t.get_device -> <syft.ast.callable.Callable object at 0x7efd95b4a6a0>\n\t.gt -> <syft.ast.callable.Callable object at 0x7efd95b4a700>\n\t.hardshrink -> <syft.ast.callable.Callable object at 0x7efd95b4a760>\n\t.histc -> <syft.ast.callable.Callable object at 0x7efd95b4a7c0>\n\t.index_add -> <syft.ast.callable.Callable object at 0x7efd95b4a820>\n\t.index_copy -> <syft.ast.callable.Callable object at 0x7efd95b4a880>\n\t.index_fill -> <syft.ast.callable.Callable object at 0x7efd95b4a8e0>\n\t.index_put_ -> <syft.ast.callable.Callable object at 0x7efd95b4a940>\n\t.index_put -> <syft.ast.callable.Callable object at 0x7efd95b4a9a0>\n\t.index_select -> <syft.ast.callable.Callable object at 0x7efd95b4aa00>\n\t.int_repr -> <syft.ast.callable.Callable object at 0x7efd95b4aa60>\n\t.inverse -> <syft.ast.callable.Callable object at 0x7efd95b4aac0>\n\t.is_complex -> <syft.ast.callable.Callable object at 0x7efd95b4ab20>\n\t.is_distributed -> <syft.ast.callable.Callable object at 0x7efd95b4ab80>\n\t.is_floating_point -> <syft.ast.callable.Callable object at 0x7efd95b4abe0>\n\t.is_nonzero -> <syft.ast.callable.Callable object at 0x7efd95b4ac40>\n\t.is_same_size -> <syft.ast.callable.Callable object at 0x7efd95b4aca0>\n\t.is_signed -> <syft.ast.callable.Callable object at 0x7efd95b4ad00>\n\t.isclose -> <syft.ast.callable.Callable object at 0x7efd95b4ad60>\n\t.kthvalue -> <syft.ast.callable.Callable object at 0x7efd95b4adc0>\n\t.le -> <syft.ast.callable.Callable object at 0x7efd95b4ae20>\n\t.lerp -> <syft.ast.callable.Callable object at 0x7efd95b4ae80>\n\t.lgamma -> <syft.ast.callable.Callable object at 0x7efd95b4aee0>\n\t.log_ -> <syft.ast.callable.Callable object at 0x7efd95b4af40>\n\t.log_softmax -> <syft.ast.callable.Callable object at 0x7efd95b4afa0>\n\t.log -> <syft.ast.callable.Callable object at 0x7efd95b4e040>\n\t.log10_ -> <syft.ast.callable.Callable object at 0x7efd95b4e0a0>\n\t.log10 -> <syft.ast.callable.Callable object at 0x7efd95b4e100>\n\t.log1p_ -> <syft.ast.callable.Callable object at 0x7efd95b4e160>\n\t.log1p -> <syft.ast.callable.Callable object at 0x7efd95b4e1c0>\n\t.log2_ -> <syft.ast.callable.Callable object at 0x7efd95b4e220>\n\t.log2 -> <syft.ast.callable.Callable object at 0x7efd95b4e280>\n\t.logdet -> <syft.ast.callable.Callable object at 0x7efd95b4e2e0>\n\t.logical_and -> <syft.ast.callable.Callable object at 0x7efd95b4e340>\n\t.logical_not -> <syft.ast.callable.Callable object at 0x7efd95b4e3a0>\n\t.logical_or -> <syft.ast.callable.Callable object at 0x7efd95b4e400>\n\t.logical_xor -> <syft.ast.callable.Callable object at 0x7efd95b4e460>\n\t.logsumexp -> <syft.ast.callable.Callable object at 0x7efd95b4e4c0>\n\t.lstsq -> <syft.ast.callable.Callable object at 0x7efd95b4e520>\n\t.lt -> <syft.ast.callable.Callable object at 0x7efd95b4e580>\n\t.lu_solve -> <syft.ast.callable.Callable object at 0x7efd95b4e5e0>\n\t.lu -> <syft.ast.callable.Callable object at 0x7efd95b4e640>\n\t.masked_fill -> <syft.ast.callable.Callable object at 0x7efd95b4e6a0>\n\t.masked_scatter -> <syft.ast.callable.Callable object at 0x7efd95b4e700>\n\t.masked_select -> <syft.ast.callable.Callable object at 0x7efd95b4e760>\n\t.matmul -> <syft.ast.callable.Callable object at 0x7efd95b4e7c0>\n\t.matrix_power -> <syft.ast.callable.Callable object at 0x7efd95b4e820>\n\t.mean -> <syft.ast.callable.Callable object at 0x7efd95b4e880>\n\t.mm -> <syft.ast.callable.Callable object at 0x7efd95b4e8e0>\n\t.mode -> <syft.ast.callable.Callable object at 0x7efd95b4e940>\n\t.mul -> <syft.ast.callable.Callable object at 0x7efd95b4e9a0>\n\t.multinomial -> <syft.ast.callable.Callable object at 0x7efd95b4ea00>\n\t.mv -> <syft.ast.callable.Callable object at 0x7efd95b4ea60>\n\t.mvlgamma -> <syft.ast.callable.Callable object at 0x7efd95b4eac0>\n\t.narrow -> <syft.ast.callable.Callable object at 0x7efd95b4eb20>\n\t.ne -> <syft.ast.callable.Callable object at 0x7efd95b4eb80>\n\t.neg_ -> <syft.ast.callable.Callable object at 0x7efd95b4ebe0>\n\t.neg -> <syft.ast.callable.Callable object at 0x7efd95b4ec40>\n\t.nonzero -> <syft.ast.callable.Callable object at 0x7efd95b4eca0>\n\t.norm -> <syft.ast.callable.Callable object at 0x7efd95b4ed00>\n\t.orgqr -> <syft.ast.callable.Callable object at 0x7efd95b4ed60>\n\t.ormqr -> <syft.ast.callable.Callable object at 0x7efd95b4edc0>\n\t.pinverse -> <syft.ast.callable.Callable object at 0x7efd95b4ee20>\n\t.polygamma -> <syft.ast.callable.Callable object at 0x7efd95b4ee80>\n\t.pow -> <syft.ast.callable.Callable object at 0x7efd95b4eee0>\n\t.prelu -> <syft.ast.callable.Callable object at 0x7efd95b4ef40>\n\t.q_per_channel_axis -> <syft.ast.callable.Callable object at 0x7efd95b4efa0>\n\t.q_per_channel_scales -> <syft.ast.callable.Callable object at 0x7efd95b53040>\n\t.q_per_channel_zero_points -> <syft.ast.callable.Callable object at 0x7efd95b530a0>\n\t.q_scale -> <syft.ast.callable.Callable object at 0x7efd95b53100>\n\t.q_zero_point -> <syft.ast.callable.Callable object at 0x7efd95b53160>\n\t.qr -> <syft.ast.callable.Callable object at 0x7efd95b531c0>\n\t.reciprocal_ -> <syft.ast.callable.Callable object at 0x7efd95b53220>\n\t.reciprocal -> <syft.ast.callable.Callable object at 0x7efd95b53280>\n\t.relu_ -> <syft.ast.callable.Callable object at 0x7efd95b532e0>\n\t.relu -> <syft.ast.callable.Callable object at 0x7efd95b53340>\n\t.remainder -> <syft.ast.callable.Callable object at 0x7efd95b533a0>\n\t.renorm -> <syft.ast.callable.Callable object at 0x7efd95b53400>\n\t.repeat_interleave -> <syft.ast.callable.Callable object at 0x7efd95b53460>\n\t.reshape -> <syft.ast.callable.Callable object at 0x7efd95b534c0>\n\t.resize_as_ -> <syft.ast.callable.Callable object at 0x7efd95b53520>\n\t.roll -> <syft.ast.callable.Callable object at 0x7efd95b53580>\n\t.rot90 -> <syft.ast.callable.Callable object at 0x7efd95b535e0>\n\t.round_ -> <syft.ast.callable.Callable object at 0x7efd95b53640>\n\t.round -> <syft.ast.callable.Callable object at 0x7efd95b536a0>\n\t.rsqrt_ -> <syft.ast.callable.Callable object at 0x7efd95b53700>\n\t.rsqrt -> <syft.ast.callable.Callable object at 0x7efd95b53760>\n\t.scatter_add -> <syft.ast.callable.Callable object at 0x7efd95b537c0>\n\t.scatter -> <syft.ast.callable.Callable object at 0x7efd95b53820>\n\t.select -> <syft.ast.callable.Callable object at 0x7efd95b53880>\n\t.sigmoid_ -> <syft.ast.callable.Callable object at 0x7efd95b538e0>\n\t.sigmoid -> <syft.ast.callable.Callable object at 0x7efd95b53940>\n\t.sign -> <syft.ast.callable.Callable object at 0x7efd95b539a0>\n\t.sin_ -> <syft.ast.callable.Callable object at 0x7efd95b53a00>\n\t.sin -> <syft.ast.callable.Callable object at 0x7efd95b53a60>\n\t.sinh_ -> <syft.ast.callable.Callable object at 0x7efd95b53ac0>\n\t.sinh -> <syft.ast.callable.Callable object at 0x7efd95b53b20>\n\t.slogdet -> <syft.ast.callable.Callable object at 0x7efd95b53b80>\n\t.softmax -> <syft.ast.callable.Callable object at 0x7efd95b53be0>\n\t.solve -> <syft.ast.callable.Callable object at 0x7efd95b53c40>\n\t.sort -> <syft.ast.callable.Callable object at 0x7efd95b53ca0>\n\t.split_with_sizes -> <syft.ast.callable.Callable object at 0x7efd95b53d00>\n\t.split -> <syft.ast.callable.Callable object at 0x7efd95b53d60>\n\t.sqrt_ -> <syft.ast.callable.Callable object at 0x7efd95b53dc0>\n\t.sqrt -> <syft.ast.callable.Callable object at 0x7efd95b53e20>\n\t.square_ -> <syft.ast.callable.Callable object at 0x7efd95b53e80>\n\t.square -> <syft.ast.callable.Callable object at 0x7efd95b53ee0>\n\t.squeeze -> <syft.ast.callable.Callable object at 0x7efd95b53f40>\n\t.stack -> <syft.ast.callable.Callable object at 0x7efd95b53fa0>\n\t.std -> <syft.ast.callable.Callable object at 0x7efd95b57040>\n\t.stft -> <syft.ast.callable.Callable object at 0x7efd95b570a0>\n\t.sub -> <syft.ast.callable.Callable object at 0x7efd95b57100>\n\t.sum -> <syft.ast.callable.Callable object at 0x7efd95b57160>\n\t.svd -> <syft.ast.callable.Callable object at 0x7efd95b571c0>\n\t.symeig -> <syft.ast.callable.Callable object at 0x7efd95b57220>\n\t.t -> <syft.ast.callable.Callable object at 0x7efd95b57280>\n\t.take -> <syft.ast.callable.Callable object at 0x7efd95b572e0>\n\t.tan_ -> <syft.ast.callable.Callable object at 0x7efd95b57340>\n\t.tan -> <syft.ast.callable.Callable object at 0x7efd95b573a0>\n\t.tanh_ -> <syft.ast.callable.Callable object at 0x7efd95b57400>\n\t.tanh -> <syft.ast.callable.Callable object at 0x7efd95b57460>\n\t.topk -> <syft.ast.callable.Callable object at 0x7efd95b574c0>\n\t.trace -> <syft.ast.callable.Callable object at 0x7efd95b57520>\n\t.transpose -> <syft.ast.callable.Callable object at 0x7efd95b57580>\n\t.triangular_solve -> <syft.ast.callable.Callable object at 0x7efd95b575e0>\n\t.tril -> <syft.ast.callable.Callable object at 0x7efd95b57640>\n\t.triu -> <syft.ast.callable.Callable object at 0x7efd95b576a0>\n\t.true_divide -> <syft.ast.callable.Callable object at 0x7efd95b57700>\n\t.trunc_ -> <syft.ast.callable.Callable object at 0x7efd95b57760>\n\t.trunc -> <syft.ast.callable.Callable object at 0x7efd95b577c0>\n\t.unique_consecutive -> <syft.ast.callable.Callable object at 0x7efd95b57820>\n\t.unique -> <syft.ast.callable.Callable object at 0x7efd95b57880>\n\t.unsqueeze -> <syft.ast.callable.Callable object at 0x7efd95b578e0>\n\t.var -> <syft.ast.callable.Callable object at 0x7efd95b57940>\n\t.unsafe_chunk -> <syft.ast.callable.Callable object at 0x7efd95b579a0>\n\t.absolute -> <syft.ast.callable.Callable object at 0x7efd95b57a00>\n\t.acosh_ -> <syft.ast.callable.Callable object at 0x7efd95b57a60>\n\t.acosh -> <syft.ast.callable.Callable object at 0x7efd95b57ac0>\n\t.asinh_ -> <syft.ast.callable.Callable object at 0x7efd95b57b20>\n\t.asinh -> <syft.ast.callable.Callable object at 0x7efd95b57b80>\n\t.atanh_ -> <syft.ast.callable.Callable object at 0x7efd95b57be0>\n\t.atanh -> <syft.ast.callable.Callable object at 0x7efd95b57c40>\n\t.deg2rad_ -> <syft.ast.callable.Callable object at 0x7efd95b57ca0>\n\t.deg2rad -> <syft.ast.callable.Callable object at 0x7efd95b57d00>\n\t.fliplr -> <syft.ast.callable.Callable object at 0x7efd95b57d60>\n\t.flipud -> <syft.ast.callable.Callable object at 0x7efd95b57dc0>\n\t.isfinite -> <syft.ast.callable.Callable object at 0x7efd95b57e20>\n\t.isinf -> <syft.ast.callable.Callable object at 0x7efd95b57e80>\n\t.isnan -> <syft.ast.callable.Callable object at 0x7efd95b57ee0>\n\t.logaddexp -> <syft.ast.callable.Callable object at 0x7efd95b57f40>\n\t.logaddexp2 -> <syft.ast.callable.Callable object at 0x7efd95b57fa0>\n\t.logcumsumexp -> <syft.ast.callable.Callable object at 0x7efd95b5c040>\n\t.rad2deg_ -> <syft.ast.callable.Callable object at 0x7efd95b5c0a0>\n\t.rad2deg -> <syft.ast.callable.Callable object at 0x7efd95b5c100>\n\t.istft -> <syft.ast.callable.Callable object at 0x7efd95b5c160>\n\t.amax -> <syft.ast.callable.Callable object at 0x7efd95b5c1c0>\n\t.amin -> <syft.ast.callable.Callable object at 0x7efd95b5c220>\n\t.arccos -> <syft.ast.callable.Callable object at 0x7efd95b5c280>\n\t.arccos_ -> <syft.ast.callable.Callable object at 0x7efd95b5c2e0>\n\t.arccosh -> <syft.ast.callable.Callable object at 0x7efd95b5c340>\n\t.arccosh_ -> <syft.ast.callable.Callable object at 0x7efd95b5c3a0>\n\t.arcsin -> <syft.ast.callable.Callable object at 0x7efd95b5c400>\n\t.arcsin_ -> <syft.ast.callable.Callable object at 0x7efd95b5c460>\n\t.arcsinh -> <syft.ast.callable.Callable object at 0x7efd95b5c4c0>\n\t.arcsinh_ -> <syft.ast.callable.Callable object at 0x7efd95b5c520>\n\t.arctan -> <syft.ast.callable.Callable object at 0x7efd95b5c580>\n\t.arctan_ -> <syft.ast.callable.Callable object at 0x7efd95b5c5e0>\n\t.arctanh -> <syft.ast.callable.Callable object at 0x7efd95b5c640>\n\t.arctanh_ -> <syft.ast.callable.Callable object at 0x7efd95b5c6a0>\n\t.clip -> <syft.ast.callable.Callable object at 0x7efd95b5c700>\n\t.clip_ -> <syft.ast.callable.Callable object at 0x7efd95b5c760>\n\t.count_nonzero -> <syft.ast.callable.Callable object at 0x7efd95b5c7c0>\n\t.divide -> <syft.ast.callable.Callable object at 0x7efd95b5c820>\n\t.exp2 -> <syft.ast.callable.Callable object at 0x7efd95b5c880>\n\t.exp2_ -> <syft.ast.callable.Callable object at 0x7efd95b5c8e0>\n\t.fix -> <syft.ast.callable.Callable object at 0x7efd95b5c940>\n\t.fix_ -> <syft.ast.callable.Callable object at 0x7efd95b5c9a0>\n\t.gcd -> <syft.ast.callable.Callable object at 0x7efd95b5ca00>\n\t.gcd_ -> <syft.ast.callable.Callable object at 0x7efd95b5ca60>\n\t.greater -> <syft.ast.callable.Callable object at 0x7efd95b5cac0>\n\t.greater_equal -> <syft.ast.callable.Callable object at 0x7efd95b5cb20>\n\t.heaviside -> <syft.ast.callable.Callable object at 0x7efd95b5cb80>\n\t.hypot -> <syft.ast.callable.Callable object at 0x7efd95b5cbe0>\n\t.i0 -> <syft.ast.callable.Callable object at 0x7efd95b5cc40>\n\t.i0_ -> <syft.ast.callable.Callable object at 0x7efd95b5cca0>\n\t.isneginf -> <syft.ast.callable.Callable object at 0x7efd95b5cd00>\n\t.isposinf -> <syft.ast.callable.Callable object at 0x7efd95b5cd60>\n\t.isreal -> <syft.ast.callable.Callable object at 0x7efd95b5cdc0>\n\t.lcm -> <syft.ast.callable.Callable object at 0x7efd95b5ce20>\n\t.lcm_ -> <syft.ast.callable.Callable object at 0x7efd95b5ce80>\n\t.less -> <syft.ast.callable.Callable object at 0x7efd95b5cee0>\n\t.less_equal -> <syft.ast.callable.Callable object at 0x7efd95b5cf40>\n\t.logit -> <syft.ast.callable.Callable object at 0x7efd95b5cfa0>\n\t.logit_ -> <syft.ast.callable.Callable object at 0x7efd95b60040>\n\t.maximum -> <syft.ast.callable.Callable object at 0x7efd95b600a0>\n\t.minimum -> <syft.ast.callable.Callable object at 0x7efd95b60100>\n\t.matrix_exp -> <syft.ast.callable.Callable object at 0x7efd95b60160>\n\t.multiply -> <syft.ast.callable.Callable object at 0x7efd95b601c0>\n\t.nanquantile -> <syft.ast.callable.Callable object at 0x7efd95b60220>\n\t.nansum -> <syft.ast.callable.Callable object at 0x7efd95b60280>\n\t.negative -> <syft.ast.callable.Callable object at 0x7efd95b602e0>\n\t.negative_ -> <syft.ast.callable.Callable object at 0x7efd95b60340>\n\t.nextafter -> <syft.ast.callable.Callable object at 0x7efd95b603a0>\n\t.outer -> <syft.ast.callable.Callable object at 0x7efd95b60400>\n\t.quantile -> <syft.ast.callable.Callable object at 0x7efd95b60460>\n\t.sgn -> <syft.ast.callable.Callable object at 0x7efd95b604c0>\n\t.signbit -> <syft.ast.callable.Callable object at 0x7efd95b60520>\n\t.subtract -> <syft.ast.callable.Callable object at 0x7efd95b60580>\n\t.unsafe_split -> <syft.ast.callable.Callable object at 0x7efd95b605e0>\n\t.vdot -> <syft.ast.callable.Callable object at 0x7efd95b60640>\n\t.movedim -> <syft.ast.callable.Callable object at 0x7efd95b606a0>\n\t.unsafe_split_with_sizes -> <syft.ast.callable.Callable object at 0x7efd95b60700>\n\t.cuda -> Module:\n\t\t.is_available -> <syft.ast.callable.Callable object at 0x7efd95b607c0>\n\n\t.device -> <syft.ast.klass.Class object at 0x7efd95b60820>\n\t.random -> Module:\n\t\t.initial_seed -> <syft.ast.callable.Callable object at 0x7efd95b609a0>\n\n\t.zeros_like -> <syft.ast.callable.Callable object at 0x7efd95b60a00>\n\t.manual_seed -> <syft.ast.callable.Callable object at 0x7efd95b60a60>\n\t.Generator -> <syft.ast.klass.Class object at 0x7efd95b60ac0>\n\t.utils -> Module:\n\t\t.data -> Module:\n\t\t\t.DataLoader -> <syft.ast.klass.Class object at 0x7efd95b65dc0>\n\t\t\t.dataloader -> Module:\n\t\t\t\t._SingleProcessDataLoaderIter -> <syft.ast.klass.Class object at 0x7efd95b68040>\n\n\n\n\t.optim -> Module:\n\t\t.ASGD -> <syft.ast.klass.Class object at 0x7efd95b68400>\n\t\t.Adadelta -> <syft.ast.klass.Class object at 0x7efd95b68580>\n\t\t.Adagrad -> <syft.ast.klass.Class object at 0x7efd95b68700>\n\t\t.Adam -> <syft.ast.klass.Class object at 0x7efd95b68880>\n\t\t.AdamW -> <syft.ast.klass.Class object at 0x7efd95b68a00>\n\t\t.Adamax -> <syft.ast.klass.Class object at 0x7efd95b68b80>\n\t\t.LBFGS -> <syft.ast.klass.Class object at 0x7efd95b68d00>\n\t\t.Optimizer -> <syft.ast.klass.Class object at 0x7efd95b68e80>\n\t\t.RMSprop -> <syft.ast.klass.Class object at 0x7efd95b6e0a0>\n\t\t.Rprop -> <syft.ast.klass.Class object at 0x7efd95b6e220>\n\t\t.SGD -> <syft.ast.klass.Class object at 0x7efd95b6e3a0>\n\t\t.SparseAdam -> <syft.ast.klass.Class object at 0x7efd95b6e520>\n\t\t.lr_scheduler -> Module:\n\t\t\t.StepLR -> <syft.ast.klass.Class object at 0x7efd95b6e7c0>\n\n\n\t.no_grad -> <syft.ast.klass.Class object at 0x7efd95b6e9a0>\n\t.autograd -> Module:\n\t\t.grad_mode -> Module:\n\t\t\t.no_grad -> <syft.ast.klass.Class object at 0x7efd95b6eb20>\n\n\n\t.distributions -> Module:\n\t\t.Categorical -> <syft.ast.klass.Class object at 0x7efd95a76d60>\n\n\t.kron -> <syft.ast.callable.Callable object at 0x7efd95a7a340>\n\t.msort -> <syft.ast.callable.Callable object at 0x7efd95a7a460>\n\t.row_stack -> <syft.ast.callable.Callable object at 0x7efd95a7a4c0>\n\t.moveaxis -> <syft.ast.callable.Callable object at 0x7efd95a7a7c0>\n\t.tensor_split -> <syft.ast.callable.Callable object at 0x7efd95a7a8e0>\n\t.tile -> <syft.ast.callable.Callable object at 0x7efd95a7aa00>\n\t.fmin -> <syft.ast.callable.Callable object at 0x7efd95a7abe0>\n\t.ldexp -> <syft.ast.callable.Callable object at 0x7efd95a7ac40>\n\t.igamma -> <syft.ast.callable.Callable object at 0x7efd95a7ad60>\n\t.float_power -> <syft.ast.callable.Callable object at 0x7efd95a7e280>\n\t.xlogy -> <syft.ast.callable.Callable object at 0x7efd95a7e3a0>\n\t.copysign -> <syft.ast.callable.Callable object at 0x7efd95a7e400>\n\t.nanmedian -> <syft.ast.callable.Callable object at 0x7efd95a7e460>\n\t.igammac -> <syft.ast.callable.Callable object at 0x7efd95a7e4c0>\n\t.diff -> <syft.ast.callable.Callable object at 0x7efd95a7e5e0>\n\t.sinc -> <syft.ast.callable.Callable object at 0x7efd95a7e700>\n\t.column_stack -> <syft.ast.callable.Callable object at 0x7efd95a7e8e0>\n\t.pixel_unshuffle -> <syft.ast.callable.Callable object at 0x7efd95a7ea00>\n\t.swapaxes -> <syft.ast.callable.Callable object at 0x7efd95a7eca0>\n\t.nan_to_num -> <syft.ast.callable.Callable object at 0x7efd95a7ed00>\n\t.inner -> <syft.ast.callable.Callable object at 0x7efd95a7ed60>\n\t.fmax -> <syft.ast.callable.Callable object at 0x7efd95a7edc0>\n\t.ravel -> <syft.ast.callable.Callable object at 0x7efd95a82160>\n\t.broadcast_to -> <syft.ast.callable.Callable object at 0x7efd95a821c0>\n\t.swapdims -> <syft.ast.callable.Callable object at 0x7efd95a823a0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1631728125596
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Client: loading and exploring the dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class ECG(Dataset):\n",
        "    # The class used to load the ECG dataset\n",
        "    def __init__(self, mode='train'):\n",
        "        if mode == 'train':\n",
        "            with h5py.File(project_path/data_dir/train_name, 'r') as hdf:\n",
        "                self.x = torch.tensor(hdf['x_train'][:], dtype=torch.float)\n",
        "                self.y = torch.tensor(hdf['y_train'][:])                \n",
        "        elif mode == 'test':\n",
        "            with h5py.File(project_path/data_dir/test_name, 'r') as hdf:\n",
        "                self.x = torch.tensor(hdf['x_test'][:], dtype=torch.float)\n",
        "                self.y = torch.tensor(hdf['y_test'][:])\n",
        "        else:\n",
        "            raise ValueError('Argument of mode should be train or test')\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728126198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ECG(mode='train')\n",
        "test_dataset = ECG(mode='test')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728128802
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first get everything in the dataset and see how many examples we have, and how each\n",
        "of them look like"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
        "x_train, y_train = next(iter(train_loader))\n",
        "x_test, y_test = next(iter(test_loader))\n",
        "print(f'x_train: {type(x_train)}, {x_train.size()}')\n",
        "print(f'y_train: {type(y_train)}, {y_train.size()}')\n",
        "print(f'x_test: {type(x_test)}, {x_test.size()}')\n",
        "print(f'y_test: {type(y_test)}, {y_test.size()}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "x_train: <class 'torch.Tensor'>, torch.Size([13245, 1, 128])\ny_train: <class 'torch.Tensor'>, torch.Size([13245])\nx_test: <class 'torch.Tensor'>, torch.Size([13245, 1, 128])\ny_test: <class 'torch.Tensor'>, torch.Size([13245])\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1631728129488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = x_train[0, :, :]\n",
        "print(f'x_0: {x0.shape}')\n",
        "x0_unroll = x0.view(-1)\n",
        "print(f'unrolling: {x0_unroll.shape}')\n",
        "indx = np.arange(0, 128)\n",
        "\n",
        "# plt.figure(figsize=(3,3))\n",
        "plt.style.use('dark_background')\n",
        "plt.plot(indx, x0_unroll)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "x_0: torch.Size([1, 128])\nunrolling: torch.Size([128])\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1631728131529
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The client creates the Dataset object and save it in a `.pt` file. \n",
        "If using `duet`, he can send the string path to the server using \n",
        "`sy.lib.python.String(string_path).send(duet, pointable=True, tags=[\"data\"])`"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(train_dataset, \"train_dataset.pt\")\n",
        "torch.save(test_dataset, \"test_dataset.pt\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728134907
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: creating remote dataset and dataloader"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_rds = RemoteDataset(path='train_dataset.pt', data_type=\"torch_tensor\")\n",
        "train_rds"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "<class 'syft.core.remote_dataloader.remote_dataloader.RemoteDataset'>: torch_tensor"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728139282
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the remote dataset, the server constructs the data loader. Then the server uses `.send`\n",
        "to create a pointer to do remote data loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_rdl = RemoteDataLoader(remote_dataset=train_rds, batch_size=32)\n",
        "train_rdl_ptr = train_rdl.send(client)\n",
        "ic(train_rdl, train_rdl_ptr)\n",
        "# call create_dataset to create the real Dataset object on remote side\n",
        "train_rdl_ptr.load_dataset()\n",
        "# call create_dataloader to create the real DataLoader object on remote side\n",
        "train_rdl_ptr.create_dataloader()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| train_rdl: <syft.core.remote_dataloader.remote_dataloader.RemoteDataLoader object at 0x7efd95783df0>\n    train_rdl_ptr: <syft.proxy.syft.core.remote_dataloader.RemoteDataLoaderPointer object at 0x7efe500d6430>\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<syft.proxy.syft.lib.python._SyNonePointer at 0x7efd958d12e0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728141531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, b in enumerate(tqdm(train_rdl_ptr)):\n",
        "    if i<2:\n",
        "        X, y = b[0], b[1]\n",
        "        ic(X, y)\n",
        "        ic(X.get_copy(), y.get_copy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/414 [00:00<?, ?it/s]ic| X: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd955b1640>\n    y: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd97751940>\nic| X.get_copy(): tensor([[[0.4761, 0.5021, 0.5030,  ..., 0.3667, 0.3652, 0.3637]],\n                  \n                          [[0.4289, 0.4280, 0.4266,  ..., 0.5638, 0.5616, 0.5601]],\n                  \n                          [[0.3616, 0.3616, 0.3616,  ..., 0.4379, 0.4326, 0.4278]],\n                  \n                          ...,\n                  \n                          [[0.4732, 0.4599, 0.4674,  ..., 0.5969, 0.5994, 0.6010]],\n                  \n                          [[0.5071, 0.5071, 0.5072,  ..., 0.6265, 0.6249, 0.6236]],\n                  \n                          [[0.3654, 0.3660, 0.3667,  ..., 0.3375, 0.3387, 0.3395]]])\n    y.get_copy(): tensor([2, 4, 2, 4, 2, 1, 1, 1, 2, 1, 0, 0, 2, 4, 3, 1, 2, 4, 1, 0, 1, 0, 4, 2,\n                          4, 3, 0, 1, 2, 4, 4, 2])\n  0%|          | 1/414 [00:00<02:04,  3.32it/s]ic| X: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd955dbf40>\n    y: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd955c2eb0>\nic| X.get_copy(): tensor([[[0.5597, 0.5637, 0.5695,  ..., 0.4344, 0.4351, 0.4359]],\n                  \n                          [[0.3872, 0.4312, 0.4242,  ..., 0.1426, 0.1372, 0.1328]],\n                  \n                          [[0.3621, 0.3553, 0.3503,  ..., 0.4690, 0.4744, 0.4790]],\n                  \n                          ...,\n                  \n                          [[0.2475, 0.2479, 0.2483,  ..., 0.2655, 0.2658, 0.2661]],\n                  \n                          [[0.4383, 0.4384, 0.4385,  ..., 0.3680, 0.3686, 0.3693]],\n                  \n                          [[0.4436, 0.4427, 0.4413,  ..., 0.5677, 0.5653, 0.5636]]])\n    y.get_copy(): tensor([0, 4, 3, 4, 2, 0, 1, 4, 1, 0, 3, 4, 2, 4, 1, 0, 2, 0, 0, 2, 0, 1, 1, 0,\n                          2, 4, 4, 2, 4, 4, 1, 4])\n100%|| 414/414 [00:01<00:00, 309.96it/s]\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728146464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, for the test dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_rds = RemoteDataset(path='test_dataset.pt', data_type=\"torch_tensor\")\n",
        "test_rdl = RemoteDataLoader(remote_dataset=test_rds, batch_size=32)\n",
        "test_rdl_ptr = test_rdl.send(client)\n",
        "ic(test_rds, test_rdl, test_rdl_ptr)\n",
        "# call create_dataset to create the real Dataset object on remote side\n",
        "test_rdl_ptr.load_dataset()\n",
        "# call create_dataloader to create the real DataLoader object on remote side\n",
        "test_rdl_ptr.create_dataloader()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| test_rds: <class 'syft.core.remote_dataloader.remote_dataloader.RemoteDataset'>: torch_tensor\n    test_rdl: <syft.core.remote_dataloader.remote_dataloader.RemoteDataLoader object at 0x7efd95783190>\n    test_rdl_ptr: <syft.proxy.syft.core.remote_dataloader.RemoteDataLoaderPointer object at 0x7efd958a3d30>\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<syft.proxy.syft.lib.python._SyNonePointer at 0x7efd954cb070>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728152029
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, b in enumerate(test_rdl_ptr):\n",
        "    if i<2:\n",
        "        X, y = b[0], b[1]\n",
        "        ic(X, y)\n",
        "        ic(X.get_copy(), y.get_copy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| X: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd955c9c70>\n    y: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd95783430>\nic| X.get_copy(): tensor([[[0.4378, 0.4380, 0.4382,  ..., 0.3650, 0.3653, 0.3656]],\n                  \n                          [[0.3724, 0.3577, 0.3532,  ..., 0.4559, 0.4563, 0.4621]],\n                  \n                          [[0.3691, 0.3687, 0.3683,  ..., 0.4174, 0.4165, 0.4158]],\n                  \n                          ...,\n                  \n                          [[0.4871, 0.4874, 0.4877,  ..., 0.4661, 0.4672, 0.4679]],\n                  \n                          [[0.4054, 0.4028, 0.3990,  ..., 0.4981, 0.5023, 0.5059]],\n                  \n                          [[0.4811, 0.4434, 0.4642,  ..., 0.8065, 0.8028, 0.7990]]])\n    y.get_copy(): tensor([1, 3, 0, 0, 3, 2, 3, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 0, 4, 1, 0, 4, 4, 1,\n                          4, 2, 0, 2, 4, 1, 3, 4])\nic| X: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd9538d220>\n    y: <syft.proxy.syft.lib.python.AnyPointer object at 0x7efd957833d0>\nic| X.get_copy(): tensor([[[0.6082, 0.6080, 0.6077,  ..., 0.6892, 0.6895, 0.6897]],\n                  \n                          [[0.3046, 0.3047, 0.3048,  ..., 0.3734, 0.3746, 0.3755]],\n                  \n                          [[0.3587, 0.3584, 0.3581,  ..., 0.4264, 0.4269, 0.4272]],\n                  \n                          ...,\n                  \n                          [[0.4198, 0.4198, 0.4197,  ..., 0.3744, 0.3746, 0.3749]],\n                  \n                          [[0.5958, 0.5953, 0.5948,  ..., 0.6727, 0.6731, 0.6734]],\n                  \n                          [[0.3507, 0.3506, 0.3506,  ..., 0.4903, 0.4891, 0.4880]]])\n    y.get_copy(): tensor([1, 2, 0, 1, 0, 3, 0, 3, 4, 0, 2, 2, 2, 1, 4, 1, 3, 2, 0, 1, 4, 1, 0, 4,\n                          4, 2, 4, 0, 4, 2, 1, 2])\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728158924
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: define the spit neural network used to train on the ECG dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Client's side contains conv layers"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EcgClient(sy.Module):\n",
        "    # used by the data owners\n",
        "    def __init__(self, torch_ref):\n",
        "        super(EcgClient, self).__init__(torch_ref=torch_ref)\n",
        "        self.conv1 = self.torch_ref.nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
        "        self.relu1 = self.torch_ref.nn.LeakyReLU()\n",
        "        self.pool1 = self.torch_ref.nn.MaxPool1d(2)  # 64 x 16\n",
        "        self.conv2 = self.torch_ref.nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
        "        self.relu2 = self.torch_ref.nn.LeakyReLU()\n",
        "        self.pool2 = self.torch_ref.nn.MaxPool1d(2)  # 32 x 16\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 32 * 16)\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1631728162461
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Server's side contains fully connected layers"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EcgServer(sy.Module):\n",
        "    def __init__(self, torch_ref):\n",
        "        super(EcgServer, self).__init__(torch_ref=torch_ref)\n",
        "        self.linear3 = nn.Linear(32 * 16, 128)\n",
        "        self.relu3 = nn.LeakyReLU() \n",
        "        self.linear4 = nn.Linear(128, 5)\n",
        "        self.softmax4 = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.linear3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.linear4(x)\n",
        "        x = self.softmax4(x)\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1631728164329
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: training process"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_client = EcgClient(torch_ref=torch)\n",
        "checkpoint = torch.load(\"init_weight.pth\")\n",
        "ecg_client.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
        "ecg_client.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
        "ecg_client.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
        "ecg_client.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
        "\n",
        "ecg_server = EcgServer(torch_ref=torch)\n",
        "checkpoint = torch.load(\"init_weight.pth\")\n",
        "ecg_server.linear3.weight.data = checkpoint[\"linear3.weight\"]\n",
        "ecg_server.linear3.bias.data = checkpoint[\"linear3.bias\"]\n",
        "ecg_server.linear4.weight.data = checkpoint[\"linear4.weight\"]\n",
        "ecg_server.linear4.bias.data = checkpoint[\"linear4.bias\"]\n",
        "\n",
        "# Send the client's model to the client\n",
        "ecg_client_ptr = ecg_client.send(client)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728166406
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some hyper-parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = 414  # 32*414=13248. We have 13245 data samples\n",
        "\n",
        "epoch = 400\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "\n",
        "optim_client = remote_torch.optim.Adam(params=ecg_client_ptr.parameters(), lr=lr)\n",
        "optim_server = torch.optim.Adam(params=ecg_server.parameters(), lr=lr)\n",
        "\n",
        "seed = 0  # the meaning of life\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631728168564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training (with CPU)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = list()\n",
        "train_accs = list()\n",
        "test_losses = list()\n",
        "test_accs = list()\n",
        "best_test_acc = 0  # best test accuracy\n",
        "for e in range(epoch):\n",
        "    print(f\"Epoch {e+1} - train \", end='')\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for i, batch in enumerate(tqdm(train_rdl_ptr)):\n",
        "        x_ptr, y_gt_ptr = batch[0], batch[1]\n",
        "        # ic(x.get_copy(), y.get_copy())\n",
        "        # initialize all gradients to zero\n",
        "        optim_server.zero_grad()\n",
        "        optim_client.zero_grad()\n",
        "        # compute and get the activation signals from the first half of the network\n",
        "        activs_ptr = ecg_client_ptr(x_ptr)\n",
        "        # the server still gets access to plain activation signals\n",
        "        activs = activs_ptr.clone().get(request_block=True)\n",
        "        # the server continues the forward pass on the activation maps\n",
        "        y_hat = ecg_server(activs)\n",
        "        # the server asks to access ground truths in plain text\n",
        "        y_gt = y_gt_ptr.get_copy()\n",
        "        # calculates cross-entropy loss\n",
        "        loss = criterion(y_hat, y_gt)\n",
        "        train_loss += loss.item()\n",
        "        correct += torch.sum(y_hat.argmax(dim=1) == y_gt).item()\n",
        "        # backward propagation (calculating gradients of the loss w.r.t the weights)\n",
        "        loss.backward()\n",
        "        # send the gradients to the client\n",
        "        client_grad_ptr = activs.grad.clone().send(client)\n",
        "        # update the gradients of the client's model\n",
        "        activs_ptr.backward(client_grad_ptr)\n",
        "        # update the weights based on the gradients\n",
        "        optim_client.step()\n",
        "        optim_server.step()\n",
        "        total += len(y_gt)\n",
        "\n",
        "    train_losses.append(train_loss / total_batch)\n",
        "    train_accs.append(correct / total)\n",
        "\n",
        "    print(f'loss: {train_losses[-1]: .4f}, accuracy: {train_accs[-1]*100: 2f}')\n",
        "\n",
        "    # testing\n",
        "    with torch.no_grad():  \n",
        "        test_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for i, batch in enumerate(tqdm(test_rdl_ptr)):\n",
        "            x_ptr, y_gt_ptr = batch[0], batch[1]\n",
        "            # forward pass\n",
        "            activs_ptr = ecg_client_ptr(x_ptr)\n",
        "            activs = activs_ptr.clone().get(request_block=True)\n",
        "            y_hat = ecg_server(activs)\n",
        "            # the server asks to access ground truths in plain text\n",
        "            y_gt = y_gt_ptr.get_copy()\n",
        "            # calculate test loss\n",
        "            loss = criterion(y_hat, y_gt)\n",
        "            test_loss += loss.item()\n",
        "            correct += torch.sum(y_hat.argmax(dim=1) == y_gt).item()\n",
        "            total += len(y_gt)\n",
        "\n",
        "        test_losses.append(test_loss / total_batch)\n",
        "        test_accs.append(correct / total)\n",
        "        print(f'test_loss: {test_losses[-1]: .4f}, test_acc: {test_accs[-1]*100: 2f}')\n",
        "        \n",
        "    if test_accs[-1] > best_test_acc:\n",
        "        best_test_acc = test_accs[-1]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1 - train loss:  1.3243, accuracy:  59.041148\ntest_loss:  1.1502, test_acc:  78.391846\nEpoch 2 - train loss:  1.0875, accuracy:  83.057758\ntest_loss:  1.0550, test_acc:  85.730464\nEpoch 3 - train loss:  1.0533, accuracy:  85.654964\ntest_loss:  1.0352, test_acc:  87.180068\nEpoch 4 - train loss:  1.0423, accuracy:  86.621367\ntest_loss:  1.0261, test_acc:  88.070970\nEpoch 5 - train loss:  1.0350, accuracy:  87.240468\ntest_loss:  1.0218, test_acc:  88.478671\nEpoch 6 - train loss:  1.0306, accuracy:  87.580219\ntest_loss:  1.0184, test_acc:  88.682522\nEpoch 7 - train loss:  1.0270, accuracy:  87.889770\ntest_loss:  1.0208, test_acc:  88.614572\nEpoch 8 - train loss:  1.0258, accuracy:  87.950170\ntest_loss:  1.0208, test_acc:  88.493771\nEpoch 9 - train loss:  1.0245, accuracy:  88.101170\ntest_loss:  1.0184, test_acc:  88.659872\nEpoch 10 - train loss:  1.0216, accuracy:  88.289921\ntest_loss:  1.0123, test_acc:  89.188373\nEpoch 11 - train loss:  1.0219, accuracy:  88.244621\ntest_loss:  1.0139, test_acc:  89.014723\nEpoch 12 - train loss:  1.0201, accuracy:  88.463571\ntest_loss:  1.0134, test_acc:  89.158173\nEpoch 13 - train loss:  1.0198, accuracy:  88.463571\ntest_loss:  1.0107, test_acc:  89.294073\nEpoch 14 - train loss:  1.0178, accuracy:  88.599471\ntest_loss:  1.0084, test_acc:  89.445074\nEpoch 15 - train loss:  1.0166, accuracy:  88.735372\ntest_loss:  1.0092, test_acc:  89.497924\nEpoch 16 - train loss:  1.0128, accuracy:  89.135523\ntest_loss:  1.0077, test_acc:  89.558324\nEpoch 17 - train loss:  1.0123, accuracy:  89.097773\ntest_loss:  1.0078, test_acc:  89.596074\nEpoch 18 - train loss:  1.0118, accuracy:  89.263873\ntest_loss:  1.0129, test_acc:  89.165723\nEpoch 19 - train loss:  1.0115, accuracy:  89.188373\ntest_loss:  1.0074, test_acc:  89.626274\nEpoch 20 - train loss:  1.0117, accuracy:  89.173273\ntest_loss:  1.0052, test_acc:  89.799924\nEpoch 21 - train loss:  1.0096, accuracy:  89.437524\ntest_loss:  1.0028, test_acc:  90.026425\nEpoch 22 - train loss:  1.0085, accuracy:  89.475274\ntest_loss:  1.0040, test_acc:  89.935825\nEpoch 23 - train loss:  1.0083, accuracy:  89.513024\ntest_loss:  1.0047, test_acc:  89.867875\nEpoch 24 - train loss:  1.0081, accuracy:  89.558324\ntest_loss:  1.0063, test_acc:  89.769724\nEpoch 25 - train loss:  1.0087, accuracy:  89.452624\ntest_loss:  1.0046, test_acc:  89.830125\nEpoch 26 - train loss:  1.0078, accuracy:  89.573424\ntest_loss:  1.0044, test_acc:  89.860325\nEpoch 27 - train loss:  1.0063, accuracy:  89.724424\ntest_loss:  1.0036, test_acc:  90.026425\nEpoch 28 - train loss:  1.0071, accuracy:  89.603624\ntest_loss:  1.0052, test_acc:  89.845225\nEpoch 29 - train loss:  1.0057, accuracy:  89.724424\ntest_loss:  1.0023, test_acc:  90.018875\nEpoch 30 - train loss:  1.0064, accuracy:  89.679124\ntest_loss:  1.0018, test_acc:  90.169875\nEpoch 31 - train loss:  1.0051, accuracy:  89.754624\ntest_loss:  1.0017, test_acc:  90.132125\nEpoch 32 - train loss:  1.0055, accuracy:  89.754624\ntest_loss:  1.0011, test_acc:  90.117025\nEpoch 33 - train loss:  1.0046, accuracy:  89.799924\ntest_loss:  1.0043, test_acc:  89.943375\nEpoch 34 - train loss:  1.0046, accuracy:  89.875425\ntest_loss:  1.0011, test_acc:  90.200076\nEpoch 35 - train loss:  1.0063, accuracy:  89.656474\ntest_loss:  1.0058, test_acc:  89.845225\nEpoch 36 - train loss:  1.0056, accuracy:  89.694224\ntest_loss:  1.0006, test_acc:  90.154775\nEpoch 37 - train loss:  1.0052, accuracy:  89.754624\ntest_loss:  1.0024, test_acc:  90.003775\nEpoch 38 - train loss:  1.0032, accuracy:  89.928275\ntest_loss:  0.9985, test_acc:  90.403926\nEpoch 39 - train loss:  1.0044, accuracy:  89.815025\ntest_loss:  0.9990, test_acc:  90.335976\nEpoch 40 - train loss:  1.0024, accuracy:  90.018875\ntest_loss:  0.9981, test_acc:  90.419026\nEpoch 41 - train loss:  1.0027, accuracy:  90.003775\ntest_loss:  1.0003, test_acc:  90.230276\nEpoch 42 - train loss:  1.0022, accuracy:  90.018875\ntest_loss:  0.9989, test_acc:  90.320876\nEpoch 43 - train loss:  1.0007, accuracy:  90.139675\ntest_loss:  0.9968, test_acc:  90.554926\nEpoch 44 - train loss:  1.0018, accuracy:  90.064175\ntest_loss:  0.9996, test_acc:  90.222726\nEpoch 45 - train loss:  1.0023, accuracy:  89.996225\ntest_loss:  0.9964, test_acc:  90.547376\nEpoch 46 - train loss:  1.0008, accuracy:  90.154775\ntest_loss:  0.9974, test_acc:  90.441676\nEpoch 47 - train loss:  1.0010, accuracy:  90.139675\ntest_loss:  0.9990, test_acc:  90.320876\nEpoch 48 - train loss:  1.0006, accuracy:  90.177425\ntest_loss:  0.9985, test_acc:  90.381276\nEpoch 49 - train loss:  1.0000, accuracy:  90.215176\ntest_loss:  0.9965, test_acc:  90.562476\nEpoch 50 - train loss:  0.9993, accuracy:  90.298226\ntest_loss:  0.9970, test_acc:  90.524726\nEpoch 51 - train loss:  0.9992, accuracy:  90.252926\ntest_loss:  0.9963, test_acc:  90.562476\nEpoch 52 - train loss:  0.9984, accuracy:  90.358626\ntest_loss:  0.9964, test_acc:  90.479426\nEpoch 53 - train loss:  0.9998, accuracy:  90.230276\ntest_loss:  0.9974, test_acc:  90.449226\nEpoch 54 - train loss:  0.9992, accuracy:  90.283126\ntest_loss:  0.9969, test_acc:  90.449226\nEpoch 55 - train loss:  0.9990, accuracy:  90.320876\ntest_loss:  0.9963, test_acc:  90.554926\nEpoch 56 - train loss:  0.9993, accuracy:  90.268026\ntest_loss:  0.9956, test_acc:  90.622877\nEpoch 57 - train loss:  0.9976, accuracy:  90.403926\ntest_loss:  0.9961, test_acc:  90.577576\nEpoch 58 - train loss:  0.9996, accuracy:  90.215176\ntest_loss:  0.9961, test_acc:  90.577576\nEpoch 59 - train loss:  0.9983, accuracy:  90.373726\ntest_loss:  0.9948, test_acc:  90.683277\nEpoch 60 - train loss:  0.9964, accuracy:  90.532276\ntest_loss:  0.9945, test_acc:  90.683277\nEpoch 61 - train loss:  0.9955, accuracy:  90.607777\ntest_loss:  0.9941, test_acc:  90.766327\nEpoch 62 - train loss:  0.9967, accuracy:  90.539826\ntest_loss:  0.9971, test_acc:  90.539826\nEpoch 63 - train loss:  0.9978, accuracy:  90.441676\ntest_loss:  0.9981, test_acc:  90.464326\nEpoch 64 - train loss:  0.9977, accuracy:  90.411476\ntest_loss:  0.9954, test_acc:  90.705927\nEpoch 65 - train loss:  0.9956, accuracy:  90.645527\ntest_loss:  0.9938, test_acc:  90.841827\nEpoch 66 - train loss:  0.9957, accuracy:  90.630427\ntest_loss:  0.9935, test_acc:  90.804077\nEpoch 67 - train loss:  0.9952, accuracy:  90.637977\ntest_loss:  0.9941, test_acc:  90.743677\nEpoch 68 - train loss:  0.9954, accuracy:  90.660627\ntest_loss:  0.9938, test_acc:  90.773877\nEpoch 69 - train loss:  0.9959, accuracy:  90.562476\ntest_loss:  0.9942, test_acc:  90.743677\nEpoch 70 - train loss:  0.9956, accuracy:  90.570026\ntest_loss:  0.9935, test_acc:  90.804077\nEpoch 71 - train loss:  0.9936, accuracy:  90.788977\ntest_loss:  0.9931, test_acc:  90.872027\nEpoch 72 - train loss:  0.9920, accuracy:  90.939977\ntest_loss:  0.9926, test_acc:  90.909777\nEpoch 73 - train loss:  0.9927, accuracy:  90.872027\ntest_loss:  0.9923, test_acc:  90.932427\nEpoch 74 - train loss:  0.9926, accuracy:  90.909777\ntest_loss:  0.9945, test_acc:  90.758777\nEpoch 75 - train loss:  0.9925, accuracy:  90.932427\ntest_loss:  0.9920, test_acc:  90.977727\nEpoch 76 - train loss:  0.9935, accuracy:  90.811627\ntest_loss:  0.9946, test_acc:  90.705927\nEpoch 77 - train loss:  0.9921, accuracy:  90.962627\ntest_loss:  0.9906, test_acc:  91.106078\nEpoch 78 - train loss:  0.9894, accuracy:  91.257078\ntest_loss:  0.9952, test_acc:  90.660627\nEpoch 79 - train loss:  0.9862, accuracy:  91.536429\ntest_loss:  0.9889, test_acc:  91.234428\nEpoch 80 - train loss:  0.9835, accuracy:  91.793129\ntest_loss:  0.9820, test_acc:  92.034730\nEpoch 81 - train loss:  0.9808, accuracy:  92.072480\ntest_loss:  0.9818, test_acc:  91.981880\nEpoch 82 - train loss:  0.9783, accuracy:  92.359381\ntest_loss:  0.9805, test_acc:  92.110230\nEpoch 83 - train loss:  0.9772, accuracy:  92.442431\ntest_loss:  0.9797, test_acc:  92.155530\nEpoch 84 - train loss:  0.9788, accuracy:  92.246131\ntest_loss:  0.9795, test_acc:  92.253681\nEpoch 85 - train loss:  0.9767, accuracy:  92.517931\ntest_loss:  0.9791, test_acc:  92.246131\nEpoch 86 - train loss:  0.9763, accuracy:  92.533031\ntest_loss:  0.9780, test_acc:  92.397131\nEpoch 87 - train loss:  0.9766, accuracy:  92.510381\ntest_loss:  0.9782, test_acc:  92.321631\nEpoch 88 - train loss:  0.9743, accuracy:  92.721782\ntest_loss:  0.9774, test_acc:  92.374481\nEpoch 89 - train loss:  0.9747, accuracy:  92.699132\ntest_loss:  0.9774, test_acc:  92.412231\nEpoch 90 - train loss:  0.9737, accuracy:  92.835032\ntest_loss:  0.9770, test_acc:  92.419781\nEpoch 91 - train loss:  0.9734, accuracy:  92.835032\ntest_loss:  0.9783, test_acc:  92.374481\nEpoch 92 - train loss:  0.9746, accuracy:  92.691582\ntest_loss:  0.9769, test_acc:  92.449981\nEpoch 93 - train loss:  0.9362, accuracy:  96.896942\ntest_loss:  0.9383, test_acc:  96.776142\nEpoch 94 - train loss:  0.9315, accuracy:  97.387693\ntest_loss:  0.9379, test_acc:  96.776142\nEpoch 95 - train loss:  0.9292, accuracy:  97.636844\ntest_loss:  0.9373, test_acc:  96.791242\nEpoch 96 - train loss:  0.9293, accuracy:  97.606644\ntest_loss:  0.9354, test_acc:  96.957342\nEpoch 97 - train loss:  0.9290, accuracy:  97.629294\ntest_loss:  0.9347, test_acc:  97.032843\nEpoch 98 - train loss:  0.9302, accuracy:  97.508494\ntest_loss:  0.9361, test_acc:  96.874292\nEpoch 99 - train loss:  0.9284, accuracy:  97.667044\ntest_loss:  0.9335, test_acc:  97.063043\nEpoch 100 - train loss:  0.9253, accuracy:  97.991695\ntest_loss:  0.9312, test_acc:  97.395243\nEpoch 101 - train loss:  0.9241, accuracy:  98.120045\ntest_loss:  0.9362, test_acc:  96.896942\nEpoch 102 - train loss:  0.9246, accuracy:  98.067195\ntest_loss:  0.9309, test_acc:  97.417894\nEpoch 103 - train loss:  0.9233, accuracy:  98.195545\ntest_loss:  0.9310, test_acc:  97.395243\nEpoch 104 - train loss:  0.9251, accuracy:  97.976595\ntest_loss:  0.9345, test_acc:  97.055493\nEpoch 105 - train loss:  0.9242, accuracy:  98.112495\ntest_loss:  0.9309, test_acc:  97.380143\nEpoch 106 - train loss:  0.9229, accuracy:  98.240846\ntest_loss:  0.9305, test_acc:  97.463194\nEpoch 107 - train loss:  0.9233, accuracy:  98.210646\ntest_loss:  0.9353, test_acc:  96.934692\nEpoch 108 - train loss:  0.9252, accuracy:  98.006795\ntest_loss:  0.9380, test_acc:  96.700642\nEpoch 109 - train loss:  0.9274, accuracy:  97.780294\ntest_loss:  0.9339, test_acc:  97.123443\nEpoch 110 - train loss:  0.9269, accuracy:  97.757644\ntest_loss:  0.9330, test_acc:  97.153643\nEpoch 111 - train loss:  0.9241, accuracy:  98.135145\ntest_loss:  0.9286, test_acc:  97.621744\nEpoch 112 - train loss:  0.9223, accuracy:  98.286146\ntest_loss:  0.9293, test_acc:  97.568894\nEpoch 113 - train loss:  0.9224, accuracy:  98.263496\ntest_loss:  0.9328, test_acc:  97.183843\nEpoch 114 - train loss:  0.9232, accuracy:  98.195545\ntest_loss:  0.9294, test_acc:  97.546244\nEpoch 115 - train loss:  0.9229, accuracy:  98.233296\ntest_loss:  0.9322, test_acc:  97.266893\nEpoch 116 - train loss:  0.9239, accuracy:  98.067195\ntest_loss:  0.9348, test_acc:  97.047943\nEpoch 117 - train loss:  0.9216, accuracy:  98.346546\ntest_loss:  0.9306, test_acc:  97.372593\nEpoch 118 - train loss:  0.9220, accuracy:  98.308796\ntest_loss:  0.9304, test_acc:  97.455644\nEpoch 119 - train loss:  0.9243, accuracy:  98.067195\ntest_loss:  0.9284, test_acc:  97.644394\nEpoch 120 - train loss:  0.9221, accuracy:  98.301246\ntest_loss:  0.9309, test_acc:  97.380143\nEpoch 121 - train loss:  0.9220, accuracy:  98.316346\ntest_loss:  0.9301, test_acc:  97.493394\nEpoch 122 - train loss:  0.9215, accuracy:  98.391846\ntest_loss:  0.9305, test_acc:  97.410344\nEpoch 123 - train loss:  0.9215, accuracy:  98.376746\ntest_loss:  0.9363, test_acc:  96.851642\nEpoch 124 - train loss:  0.9216, accuracy:  98.346546\ntest_loss:  0.9286, test_acc:  97.538694\nEpoch 125 - train loss:  0.9207, accuracy:  98.429596\ntest_loss:  0.9305, test_acc:  97.402794\nEpoch 126 - train loss:  0.9207, accuracy:  98.406946\ntest_loss:  0.9290, test_acc:  97.599094\nEpoch 127 - train loss:  0.9198, accuracy:  98.527746\ntest_loss:  0.9285, test_acc:  97.583994\nEpoch 128 - train loss:  0.9201, accuracy:  98.512646\ntest_loss:  0.9265, test_acc:  97.818045\nEpoch 129 - train loss:  0.9223, accuracy:  98.271046\ntest_loss:  0.9320, test_acc:  97.229143\nEpoch 130 - train loss:  0.9199, accuracy:  98.542846\ntest_loss:  0.9258, test_acc:  97.938845\nEpoch 131 - train loss:  0.9191, accuracy:  98.610797\ntest_loss:  0.9301, test_acc:  97.485844\nEpoch 132 - train loss:  0.9188, accuracy:  98.625897\ntest_loss:  0.9247, test_acc:  97.991695\nEpoch 133 - train loss:  0.9189, accuracy:  98.588146\ntest_loss:  0.9268, test_acc:  97.780294\nEpoch 134 - train loss:  0.9209, accuracy:  98.376746\ntest_loss:  0.9265, test_acc:  97.893545\nEpoch 135 - train loss:  0.9192, accuracy:  98.595696\ntest_loss:  0.9274, test_acc:  97.719894\nEpoch 136 - train loss:  0.9190, accuracy:  98.618347\ntest_loss:  0.9283, test_acc:  97.644394\nEpoch 137 - train loss:  0.9205, accuracy:  98.444696\ntest_loss:  0.9251, test_acc:  97.938845\nEpoch 138 - train loss:  0.9182, accuracy:  98.686297\ntest_loss:  0.9253, test_acc:  97.938845\nEpoch 139 - train loss:  0.9187, accuracy:  98.618347\ntest_loss:  0.9277, test_acc:  97.704794\nEpoch 140 - train loss:  0.9193, accuracy:  98.580596\ntest_loss:  0.9257, test_acc:  97.923745\nEpoch 141 - train loss:  0.9185, accuracy:  98.625897\ntest_loss:  0.9323, test_acc:  97.214043\nEpoch 142 - train loss:  0.9196, accuracy:  98.535296\ntest_loss:  0.9267, test_acc:  97.810495\nEpoch 143 - train loss:  0.9180, accuracy:  98.716497\ntest_loss:  0.9341, test_acc:  97.063043\nEpoch 144 - train loss:  0.9194, accuracy:  98.550396\ntest_loss:  0.9269, test_acc:  97.795394\nEpoch 145 - train loss:  0.9179, accuracy:  98.731597\ntest_loss:  0.9249, test_acc:  98.052095\nEpoch 146 - train loss:  0.9172, accuracy:  98.769347\ntest_loss:  0.9295, test_acc:  97.523594\nEpoch 147 - train loss:  0.9181, accuracy:  98.693847\ntest_loss:  0.9266, test_acc:  97.750094\nEpoch 148 - train loss:  0.9171, accuracy:  98.784447\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 149 - train loss:  0.9184, accuracy:  98.633447\ntest_loss:  0.9325, test_acc:  97.221593\nEpoch 150 - train loss:  0.9196, accuracy:  98.557946\ntest_loss:  0.9277, test_acc:  97.682144\nEpoch 151 - train loss:  0.9175, accuracy:  98.754247\ntest_loss:  0.9260, test_acc:  97.863345\nEpoch 152 - train loss:  0.9175, accuracy:  98.754247\ntest_loss:  0.9298, test_acc:  97.485844\nEpoch 153 - train loss:  0.9173, accuracy:  98.761797\ntest_loss:  0.9251, test_acc:  97.946395\nEpoch 154 - train loss:  0.9185, accuracy:  98.663647\ntest_loss:  0.9256, test_acc:  97.901095\nEpoch 155 - train loss:  0.9174, accuracy:  98.754247\ntest_loss:  0.9258, test_acc:  97.916195\nEpoch 156 - train loss:  0.9171, accuracy:  98.791997\ntest_loss:  0.9266, test_acc:  97.787844\nEpoch 157 - train loss:  0.9181, accuracy:  98.648547\ntest_loss:  0.9262, test_acc:  97.863345\nEpoch 158 - train loss:  0.9164, accuracy:  98.859947\ntest_loss:  0.9272, test_acc:  97.757644\nEpoch 159 - train loss:  0.9169, accuracy:  98.799547\ntest_loss:  0.9243, test_acc:  98.059645\nEpoch 160 - train loss:  0.9163, accuracy:  98.875047\ntest_loss:  0.9268, test_acc:  97.825595\nEpoch 161 - train loss:  0.9197, accuracy:  98.497546\ntest_loss:  0.9266, test_acc:  97.840695\nEpoch 162 - train loss:  0.9184, accuracy:  98.648547\ntest_loss:  0.9283, test_acc:  97.644394\nEpoch 163 - train loss:  0.9174, accuracy:  98.739147\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 164 - train loss:  0.9158, accuracy:  98.935447\ntest_loss:  0.9255, test_acc:  97.931295\nEpoch 165 - train loss:  0.9171, accuracy:  98.776897\ntest_loss:  0.9261, test_acc:  97.848245\nEpoch 166 - train loss:  0.9174, accuracy:  98.784447\ntest_loss:  0.9272, test_acc:  97.780294\nEpoch 167 - train loss:  0.9189, accuracy:  98.573046\ntest_loss:  0.9280, test_acc:  97.674594\nEpoch 168 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9242, test_acc:  98.067195\nEpoch 169 - train loss:  0.9173, accuracy:  98.754247\ntest_loss:  0.9255, test_acc:  97.916195\nEpoch 170 - train loss:  0.9173, accuracy:  98.746697\ntest_loss:  0.9254, test_acc:  97.923745\nEpoch 171 - train loss:  0.9160, accuracy:  98.912797\ntest_loss:  0.9260, test_acc:  97.870895\nEpoch 172 - train loss:  0.9163, accuracy:  98.859947\ntest_loss:  0.9256, test_acc:  97.916195\nEpoch 173 - train loss:  0.9167, accuracy:  98.837297\ntest_loss:  0.9250, test_acc:  97.961495\nEpoch 174 - train loss:  0.9166, accuracy:  98.837297\ntest_loss:  0.9279, test_acc:  97.689694\nEpoch 175 - train loss:  0.9165, accuracy:  98.822197\ntest_loss:  0.9264, test_acc:  97.840695\nEpoch 176 - train loss:  0.9162, accuracy:  98.867497\ntest_loss:  0.9245, test_acc:  98.014345\nEpoch 177 - train loss:  0.9163, accuracy:  98.875047\ntest_loss:  0.9240, test_acc:  98.052095\nEpoch 178 - train loss:  0.9173, accuracy:  98.784447\ntest_loss:  0.9249, test_acc:  98.044545\nEpoch 179 - train loss:  0.9178, accuracy:  98.708947\ntest_loss:  0.9232, test_acc:  98.150245\nEpoch 180 - train loss:  0.9158, accuracy:  98.912797\ntest_loss:  0.9252, test_acc:  97.961495\nEpoch 181 - train loss:  0.9158, accuracy:  98.912797\ntest_loss:  0.9235, test_acc:  98.104945\nEpoch 182 - train loss:  0.9151, accuracy:  99.003398\ntest_loss:  0.9236, test_acc:  98.135145\nEpoch 183 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9259, test_acc:  97.893545\nEpoch 184 - train loss:  0.9161, accuracy:  98.867497\ntest_loss:  0.9263, test_acc:  97.840695\nEpoch 185 - train loss:  0.9176, accuracy:  98.739147\ntest_loss:  0.9257, test_acc:  97.931295\nEpoch 186 - train loss:  0.9176, accuracy:  98.731597\ntest_loss:  0.9242, test_acc:  98.067195\nEpoch 187 - train loss:  0.9161, accuracy:  98.897697\ntest_loss:  0.9234, test_acc:  98.127595\nEpoch 188 - train loss:  0.9148, accuracy:  99.026048\ntest_loss:  0.9252, test_acc:  97.961495\nEpoch 189 - train loss:  0.9162, accuracy:  98.882597\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 190 - train loss:  0.9166, accuracy:  98.822197\ntest_loss:  0.9242, test_acc:  98.052095\nEpoch 191 - train loss:  0.9168, accuracy:  98.807097\ntest_loss:  0.9251, test_acc:  97.961495\nEpoch 192 - train loss:  0.9174, accuracy:  98.746697\ntest_loss:  0.9238, test_acc:  98.059645\nEpoch 193 - train loss:  0.9160, accuracy:  98.890147\ntest_loss:  0.9230, test_acc:  98.203096\nEpoch 194 - train loss:  0.9163, accuracy:  98.867497\ntest_loss:  0.9272, test_acc:  97.734994\nEpoch 195 - train loss:  0.9174, accuracy:  98.739147\ntest_loss:  0.9277, test_acc:  97.712344\nEpoch 196 - train loss:  0.9176, accuracy:  98.731597\ntest_loss:  0.9241, test_acc:  98.052095\nEpoch 197 - train loss:  0.9165, accuracy:  98.844847\ntest_loss:  0.9381, test_acc:  96.670442\nEpoch 198 - train loss:  0.9169, accuracy:  98.776897\ntest_loss:  0.9241, test_acc:  98.082295\nEpoch 199 - train loss:  0.9158, accuracy:  98.927897\ntest_loss:  0.9225, test_acc:  98.240846\nEpoch 200 - train loss:  0.9169, accuracy:  98.791997\ntest_loss:  0.9239, test_acc:  98.104945\nEpoch 201 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9236, test_acc:  98.127595\nEpoch 202 - train loss:  0.9152, accuracy:  98.958097\ntest_loss:  0.9238, test_acc:  98.089845\nEpoch 203 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9261, test_acc:  97.870895\nEpoch 204 - train loss:  0.9147, accuracy:  99.018498\ntest_loss:  0.9226, test_acc:  98.187995\nEpoch 205 - train loss:  0.9154, accuracy:  98.942997\ntest_loss:  0.9235, test_acc:  98.127595\nEpoch 206 - train loss:  0.9172, accuracy:  98.754247\ntest_loss:  0.9244, test_acc:  98.044545\nEpoch 207 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9235, test_acc:  98.120045\nEpoch 208 - train loss:  0.9154, accuracy:  98.958097\ntest_loss:  0.9269, test_acc:  97.780294\nEpoch 209 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9222, test_acc:  98.263496\nEpoch 210 - train loss:  0.9149, accuracy:  98.995847\ntest_loss:  0.9241, test_acc:  98.082295\nEpoch 211 - train loss:  0.9154, accuracy:  98.927897\ntest_loss:  0.9245, test_acc:  98.014345\nEpoch 212 - train loss:  0.9170, accuracy:  98.799547\ntest_loss:  0.9282, test_acc:  97.606644\nEpoch 213 - train loss:  0.9161, accuracy:  98.875047\ntest_loss:  0.9255, test_acc:  97.961495\nEpoch 214 - train loss:  0.9157, accuracy:  98.920347\ntest_loss:  0.9260, test_acc:  97.870895\nEpoch 215 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9244, test_acc:  98.029445\nEpoch 216 - train loss:  0.9154, accuracy:  98.958097\ntest_loss:  0.9263, test_acc:  97.818045\nEpoch 217 - train loss:  0.9152, accuracy:  98.973197\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 218 - train loss:  0.9158, accuracy:  98.905247\ntest_loss:  0.9245, test_acc:  98.036995\nEpoch 219 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9237, test_acc:  98.150245\nEpoch 220 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9248, test_acc:  98.029445\nEpoch 221 - train loss:  0.9151, accuracy:  98.988297\ntest_loss:  0.9231, test_acc:  98.172895\nEpoch 222 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9227, test_acc:  98.225746\nEpoch 223 - train loss:  0.9149, accuracy:  99.010948\ntest_loss:  0.9266, test_acc:  97.833145\nEpoch 224 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9268, test_acc:  97.780294\nEpoch 225 - train loss:  0.9150, accuracy:  98.973197\ntest_loss:  0.9238, test_acc:  98.104945\nEpoch 226 - train loss:  0.9151, accuracy:  98.973197\ntest_loss:  0.9262, test_acc:  97.840695\nEpoch 227 - train loss:  0.9168, accuracy:  98.822197\ntest_loss:  0.9252, test_acc:  97.953945\nEpoch 228 - train loss:  0.9157, accuracy:  98.927897\ntest_loss:  0.9254, test_acc:  97.916195\nEpoch 229 - train loss:  0.9170, accuracy:  98.784447\ntest_loss:  0.9260, test_acc:  97.863345\nEpoch 230 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9238, test_acc:  98.097395\nEpoch 231 - train loss:  0.9149, accuracy:  99.003398\ntest_loss:  0.9245, test_acc:  97.999245\nEpoch 232 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9225, test_acc:  98.233296\nEpoch 233 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 234 - train loss:  0.9161, accuracy:  98.890147\ntest_loss:  0.9250, test_acc:  97.991695\nEpoch 235 - train loss:  0.9167, accuracy:  98.829747\ntest_loss:  0.9232, test_acc:  98.165345\nEpoch 236 - train loss:  0.9164, accuracy:  98.867497\ntest_loss:  0.9255, test_acc:  97.916195\nEpoch 237 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 238 - train loss:  0.9147, accuracy:  99.026048\ntest_loss:  0.9234, test_acc:  98.104945\nEpoch 239 - train loss:  0.9148, accuracy:  98.980747\ntest_loss:  0.9228, test_acc:  98.203096\nEpoch 240 - train loss:  0.9160, accuracy:  98.875047\ntest_loss:  0.9242, test_acc:  98.052095\nEpoch 241 - train loss:  0.9185, accuracy:  98.625897\ntest_loss:  0.9235, test_acc:  98.104945\nEpoch 242 - train loss:  0.9151, accuracy:  98.973197\ntest_loss:  0.9230, test_acc:  98.180445\nEpoch 243 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9234, test_acc:  98.150245\nEpoch 244 - train loss:  0.9152, accuracy:  98.950547\ntest_loss:  0.9263, test_acc:  97.833145\nEpoch 245 - train loss:  0.9166, accuracy:  98.822197\ntest_loss:  0.9240, test_acc:  98.052095\nEpoch 246 - train loss:  0.9153, accuracy:  98.942997\ntest_loss:  0.9231, test_acc:  98.157795\nEpoch 247 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 248 - train loss:  0.9156, accuracy:  98.912797\ntest_loss:  0.9243, test_acc:  98.036995\nEpoch 249 - train loss:  0.9150, accuracy:  98.980747\ntest_loss:  0.9250, test_acc:  97.953945\nEpoch 250 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 251 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9240, test_acc:  98.059645\nEpoch 252 - train loss:  0.9150, accuracy:  98.988297\ntest_loss:  0.9244, test_acc:  97.999245\nEpoch 253 - train loss:  0.9156, accuracy:  98.920347\ntest_loss:  0.9247, test_acc:  97.991695\nEpoch 254 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9235, test_acc:  98.112495\nEpoch 255 - train loss:  0.9150, accuracy:  98.995847\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 256 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9242, test_acc:  98.044545\nEpoch 257 - train loss:  0.9148, accuracy:  98.995847\ntest_loss:  0.9239, test_acc:  98.074745\nEpoch 258 - train loss:  0.9159, accuracy:  98.905247\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 259 - train loss:  0.9141, accuracy:  99.086448\ntest_loss:  0.9239, test_acc:  98.052095\nEpoch 260 - train loss:  0.9158, accuracy:  98.905247\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 261 - train loss:  0.9145, accuracy:  99.026048\ntest_loss:  0.9230, test_acc:  98.150245\nEpoch 262 - train loss:  0.9141, accuracy:  99.078898\ntest_loss:  0.9314, test_acc:  97.289543\nEpoch 263 - train loss:  0.9155, accuracy:  98.950547\ntest_loss:  0.9237, test_acc:  98.089845\nEpoch 264 - train loss:  0.9150, accuracy:  99.003398\ntest_loss:  0.9246, test_acc:  98.044545\nEpoch 265 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9234, test_acc:  98.120045\nEpoch 266 - train loss:  0.9148, accuracy:  99.010948\ntest_loss:  0.9233, test_acc:  98.127595\nEpoch 267 - train loss:  0.9140, accuracy:  99.086448\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 268 - train loss:  0.9142, accuracy:  99.063798\ntest_loss:  0.9235, test_acc:  98.097395\nEpoch 269 - train loss:  0.9161, accuracy:  98.867497\ntest_loss:  0.9222, test_acc:  98.263496\nEpoch 270 - train loss:  0.9150, accuracy:  98.988297\ntest_loss:  0.9245, test_acc:  98.006795\nEpoch 271 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 272 - train loss:  0.9148, accuracy:  99.010948\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 273 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9222, test_acc:  98.271046\nEpoch 274 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9238, test_acc:  98.074745\nEpoch 275 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 276 - train loss:  0.9143, accuracy:  99.041148\ntest_loss:  0.9232, test_acc:  98.150245\nEpoch 277 - train loss:  0.9138, accuracy:  99.101548\ntest_loss:  0.9227, test_acc:  98.203096\nEpoch 278 - train loss:  0.9150, accuracy:  98.980747\ntest_loss:  0.9253, test_acc:  97.931295\nEpoch 279 - train loss:  0.9153, accuracy:  98.942997\ntest_loss:  0.9239, test_acc:  98.082295\nEpoch 280 - train loss:  0.9150, accuracy:  98.995847\ntest_loss:  0.9239, test_acc:  98.089845\nEpoch 281 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9235, test_acc:  98.112495\nEpoch 282 - train loss:  0.9159, accuracy:  98.890147\ntest_loss:  0.9233, test_acc:  98.127595\nEpoch 283 - train loss:  0.9140, accuracy:  99.093998\ntest_loss:  0.9228, test_acc:  98.187995\nEpoch 284 - train loss:  0.9137, accuracy:  99.116648\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 285 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9227, test_acc:  98.187995\nEpoch 286 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 287 - train loss:  0.9183, accuracy:  98.648547\ntest_loss:  0.9256, test_acc:  97.931295\nEpoch 288 - train loss:  0.9152, accuracy:  98.942997\ntest_loss:  0.9239, test_acc:  98.089845\nEpoch 289 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9234, test_acc:  98.135145\nEpoch 290 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9235, test_acc:  98.120045\nEpoch 291 - train loss:  0.9138, accuracy:  99.109098\ntest_loss:  0.9234, test_acc:  98.165345\nEpoch 292 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 293 - train loss:  0.9133, accuracy:  99.154398\ntest_loss:  0.9229, test_acc:  98.180445\nEpoch 294 - train loss:  0.9136, accuracy:  99.116648\ntest_loss:  0.9312, test_acc:  97.342393\nEpoch 295 - train loss:  0.9160, accuracy:  98.890147\ntest_loss:  0.9279, test_acc:  97.659494\nEpoch 296 - train loss:  0.9184, accuracy:  98.633447\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 297 - train loss:  0.9151, accuracy:  98.965647\ntest_loss:  0.9251, test_acc:  97.953945\nEpoch 298 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9232, test_acc:  98.187995\nEpoch 299 - train loss:  0.9158, accuracy:  98.890147\ntest_loss:  0.9231, test_acc:  98.150245\nEpoch 300 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9238, test_acc:  98.104945\nEpoch 301 - train loss:  0.9143, accuracy:  99.056248\ntest_loss:  0.9230, test_acc:  98.172895\nEpoch 302 - train loss:  0.9165, accuracy:  98.844847\ntest_loss:  0.9236, test_acc:  98.142695\nEpoch 303 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9222, test_acc:  98.255946\nEpoch 304 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9234, test_acc:  98.180445\nEpoch 305 - train loss:  0.9141, accuracy:  99.063798\ntest_loss:  0.9244, test_acc:  98.021895\nEpoch 306 - train loss:  0.9142, accuracy:  99.056248\ntest_loss:  0.9224, test_acc:  98.255946\nEpoch 307 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9245, test_acc:  98.021895\nEpoch 308 - train loss:  0.9140, accuracy:  99.071348\ntest_loss:  0.9220, test_acc:  98.278596\nEpoch 309 - train loss:  0.9134, accuracy:  99.146848\ntest_loss:  0.9224, test_acc:  98.271046\nEpoch 310 - train loss:  0.9137, accuracy:  99.109098\ntest_loss:  0.9229, test_acc:  98.187995\nEpoch 311 - train loss:  0.9137, accuracy:  99.109098\ntest_loss:  0.9244, test_acc:  98.036995\nEpoch 312 - train loss:  0.9139, accuracy:  99.101548\ntest_loss:  0.9222, test_acc:  98.255946\nEpoch 313 - train loss:  0.9151, accuracy:  98.958097\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 314 - train loss:  0.9143, accuracy:  99.048698\ntest_loss:  0.9238, test_acc:  98.089845\nEpoch 315 - train loss:  0.9151, accuracy:  98.988297\ntest_loss:  0.9223, test_acc:  98.255946\nEpoch 316 - train loss:  0.9132, accuracy:  99.161948\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 317 - train loss:  0.9142, accuracy:  99.063798\ntest_loss:  0.9236, test_acc:  98.112495\nEpoch 318 - train loss:  0.9151, accuracy:  98.965647\ntest_loss:  0.9237, test_acc:  98.089845\nEpoch 319 - train loss:  0.9147, accuracy:  99.003398\ntest_loss:  0.9239, test_acc:  98.104945\nEpoch 320 - train loss:  0.9154, accuracy:  98.927897\ntest_loss:  0.9236, test_acc:  98.127595\nEpoch 321 - train loss:  0.9159, accuracy:  98.897697\ntest_loss:  0.9229, test_acc:  98.195545\nEpoch 322 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9256, test_acc:  97.901095\nEpoch 323 - train loss:  0.9135, accuracy:  99.131748\ntest_loss:  0.9227, test_acc:  98.225746\nEpoch 324 - train loss:  0.9154, accuracy:  98.942997\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 325 - train loss:  0.9146, accuracy:  99.041148\ntest_loss:  0.9227, test_acc:  98.203096\nEpoch 326 - train loss:  0.9141, accuracy:  99.086448\ntest_loss:  0.9225, test_acc:  98.225746\nEpoch 327 - train loss:  0.9149, accuracy:  98.965647\ntest_loss:  0.9247, test_acc:  97.999245\nEpoch 328 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9252, test_acc:  97.953945\nEpoch 329 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9226, test_acc:  98.187995\nEpoch 330 - train loss:  0.9140, accuracy:  99.071348\ntest_loss:  0.9237, test_acc:  98.157795\nEpoch 331 - train loss:  0.9138, accuracy:  99.109098\ntest_loss:  0.9226, test_acc:  98.203096\nEpoch 332 - train loss:  0.9138, accuracy:  99.093998\ntest_loss:  0.9232, test_acc:  98.157795\nEpoch 333 - train loss:  0.9155, accuracy:  98.912797\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 334 - train loss:  0.9140, accuracy:  99.093998\ntest_loss:  0.9244, test_acc:  98.029445\nEpoch 335 - train loss:  0.9130, accuracy:  99.192148\ntest_loss:  0.9231, test_acc:  98.172895\nEpoch 336 - train loss:  0.9145, accuracy:  99.018498\ntest_loss:  0.9250, test_acc:  97.961495\nEpoch 337 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9285, test_acc:  97.621744\nEpoch 338 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9232, test_acc:  98.157795\nEpoch 339 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9236, test_acc:  98.104945\nEpoch 340 - train loss:  0.9134, accuracy:  99.146848\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 341 - train loss:  0.9152, accuracy:  98.965647\ntest_loss:  0.9231, test_acc:  98.157795\nEpoch 342 - train loss:  0.9147, accuracy:  99.033598\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 343 - train loss:  0.9139, accuracy:  99.109098\ntest_loss:  0.9253, test_acc:  97.938845\nEpoch 344 - train loss:  0.9136, accuracy:  99.124198\ntest_loss:  0.9223, test_acc:  98.248396\nEpoch 345 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9255, test_acc:  97.938845\nEpoch 346 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 347 - train loss:  0.9159, accuracy:  98.905247\ntest_loss:  0.9227, test_acc:  98.210646\nEpoch 348 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9341, test_acc:  97.032843\nEpoch 349 - train loss:  0.9142, accuracy:  99.041148\ntest_loss:  0.9227, test_acc:  98.195545\nEpoch 350 - train loss:  0.9133, accuracy:  99.146848\ntest_loss:  0.9225, test_acc:  98.225746\nEpoch 351 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9224, test_acc:  98.233296\nEpoch 352 - train loss:  0.9133, accuracy:  99.154398\ntest_loss:  0.9230, test_acc:  98.195545\nEpoch 353 - train "
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/414 [00:00<?, ?it/s]/anaconda/envs/SyftEnv/lib/python3.9/site-packages/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  grad = getattr(obj, \"grad\", None)\n100%|| 414/414 [01:05<00:00,  6.31it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [01:02<00:00,  6.66it/s]\n100%|| 414/414 [01:49<00:00,  3.78it/s]\n100%|| 414/414 [01:09<00:00,  5.99it/s]\n100%|| 414/414 [01:49<00:00,  3.78it/s]\n100%|| 414/414 [01:00<00:00,  6.81it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:58<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:58<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:05<00:00,  6.28it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.63it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.63it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.62it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.62it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.62it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:10<00:00,  5.88it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [01:06<00:00,  6.18it/s]\n100%|| 414/414 [01:50<00:00,  3.76it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:45<00:00,  3.91it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.04it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:58<00:00,  7.11it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:04<00:00,  6.43it/s]\n100%|| 414/414 [01:08<00:00,  6.02it/s]\n100%|| 414/414 [01:49<00:00,  3.77it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:37<00:00,  4.23it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:58<00:00,  7.03it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:58<00:00,  7.11it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.09it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.52it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:59<00:00,  7.01it/s]\n100%|| 414/414 [01:03<00:00,  6.51it/s]\n100%|| 414/414 [00:58<00:00,  7.11it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:58<00:00,  7.07it/s]\n100%|| 414/414 [01:22<00:00,  5.03it/s]\n100%|| 414/414 [01:09<00:00,  5.95it/s]\n100%|| 414/414 [01:53<00:00,  3.65it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:31<00:00,  4.50it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:06<00:00,  6.25it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.07it/s]\n100%|| 414/414 [01:03<00:00,  6.50it/s]\n100%|| 414/414 [00:58<00:00,  7.10it/s]\n100%|| 414/414 [01:04<00:00,  6.46it/s]\n100%|| 414/414 [00:58<00:00,  7.09it/s]\n100%|| 414/414 [01:03<00:00,  6.50it/s]\n100%|| 414/414 [00:58<00:00,  7.11it/s]\n100%|| 414/414 [01:03<00:00,  6.52it/s]\n100%|| 414/414 [00:58<00:00,  7.10it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:58<00:00,  7.11it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.10it/s]\n100%|| 414/414 [01:52<00:00,  3.68it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:50<00:00,  3.74it/s]\n100%|| 414/414 [01:04<00:00,  6.38it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:06<00:00,  6.25it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [01:49<00:00,  3.77it/s]\n100%|| 414/414 [01:08<00:00,  6.02it/s]\n100%|| 414/414 [01:49<00:00,  3.78it/s]\n100%|| 414/414 [00:59<00:00,  6.97it/s]\n100%|| 414/414 [01:02<00:00,  6.61it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:59<00:00,  7.01it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.51it/s]\n100%|| 414/414 [00:58<00:00,  7.14it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.13it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [01:08<00:00,  6.04it/s]\n100%|| 414/414 [01:49<00:00,  3.77it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:43<00:00,  3.99it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:58<00:00,  7.02it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:58<00:00,  7.04it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:13<00:00,  5.64it/s]\n100%|| 414/414 [01:08<00:00,  6.00it/s]\n100%|| 414/414 [01:49<00:00,  3.77it/s]\n100%|| 414/414 [01:09<00:00,  6.00it/s]\n100%|| 414/414 [01:29<00:00,  4.63it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:05<00:00,  6.28it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:58<00:00,  7.09it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:02<00:00,  6.59it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:26<00:00,  4.77it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:52<00:00,  3.69it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:17<00:00,  5.34it/s]\n100%|| 414/414 [00:58<00:00,  7.02it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.52it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.60it/s]\n100%|| 414/414 [00:58<00:00,  7.10it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.52it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.12it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.52it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:45<00:00,  3.93it/s]\n100%|| 414/414 [01:08<00:00,  6.01it/s]\n100%|| 414/414 [01:50<00:00,  3.75it/s]\n100%|| 414/414 [01:07<00:00,  6.11it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.58it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [01:00<00:00,  6.80it/s]\n100%|| 414/414 [01:50<00:00,  3.76it/s]\n100%|| 414/414 [01:08<00:00,  6.03it/s]\n100%|| 414/414 [01:51<00:00,  3.70it/s]\n100%|| 414/414 [01:01<00:00,  6.72it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:06<00:00,  6.24it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:02<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.57it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.48it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.47it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [01:07<00:00,  6.18it/s]\n100%|| 414/414 [01:50<00:00,  3.73it/s]\n100%|| 414/414 [01:09<00:00,  5.95it/s]\n100%|| 414/414 [01:47<00:00,  3.86it/s]\n100%|| 414/414 [00:57<00:00,  7.15it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:58<00:00,  7.14it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.55it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.19it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.56it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.53it/s]\n100%|| 414/414 [00:57<00:00,  7.17it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.16it/s]\n100%|| 414/414 [01:03<00:00,  6.54it/s]\n100%|| 414/414 [00:57<00:00,  7.18it/s]\n100%|| 414/414 [01:16<00:00,  5.38it/s]\n100%|| 414/414 [01:08<00:00,  6.03it/s]\n100%|| 414/414 [01:53<00:00,  3.66it/s]\n100%|| 414/414 [01:09<00:00,  5.95it/s]\n 73%|  | 302/414 [01:08<00:16,  6.61it/s]"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631695917428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "syftenv",
      "language": "python",
      "display_name": "syft"
    },
    "kernel_info": {
      "name": "syftenv"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "870a257bdc5888c6c86cab99e489c6f2724cdfe1684d5990b9d7489b2d46bf07"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}