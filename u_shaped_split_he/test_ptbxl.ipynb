{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Server Runs the Testing Process on the Plain Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_path: /home/dk/Desktop/projects/split-learning-1D-HE\n",
      "torch version: 1.10.0+cu102\n",
      "tenseal version: 0.3.10\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('dark_background')\n",
    "from pathlib import Path\n",
    "\n",
    "project_path = Path.cwd().parent\n",
    "print(f'project_path: {project_path}')\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'tenseal version: {ts.__version__}')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'device: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('device: cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBXL(Dataset):\n",
    "    \"\"\"\n",
    "    The class used by the client to \n",
    "    load the PTBXL dataset\n",
    "\n",
    "    Args:\n",
    "        Dataset ([type]): [description]\n",
    "    \"\"\"\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(project_path/'data/train_ptbxl.hdf5', 'r') as hdf:\n",
    "                self.x = hdf['X_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(project_path/'data/test_ptbxl.hdf5', 'r') as hdf:\n",
    "                self.x = hdf['X_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])\n",
    "\n",
    "batch_size = 4\n",
    "test_dataset = PTBXL(train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dk/Desktop/projects/split-learning-1D-HE/u_shaped_split_he/test_ptbxl.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dk/Desktop/projects/split-learning-1D-HE/u_shaped_split_he/test_ptbxl.ipynb#ch0000005?line=0'>1</a>\u001b[0m client \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./weights/trained_client_ptbxl_4096.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dk/Desktop/projects/split-learning-1D-HE/u_shaped_split_he/test_ptbxl.ipynb#ch0000005?line=1'>2</a>\u001b[0m server \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mweights/trained_server_ptbxl_4096.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dk/Desktop/projects/split-learning-1D-HE/u_shaped_split_he/test_ptbxl.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mECGModel\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=604'>605</a>\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=605'>606</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=606'>607</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=607'>608</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=879'>880</a>\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=880'>881</a>\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=881'>882</a>\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=883'>884</a>\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=885'>886</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:857\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=854'>855</a>\u001b[0m data_type, key, location, size \u001b[39m=\u001b[39m data\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=855'>856</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=856'>857</a>\u001b[0m     load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=857'>858</a>\u001b[0m storage \u001b[39m=\u001b[39m loaded_storages[key]\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=858'>859</a>\u001b[0m \u001b[39mreturn\u001b[39;00m storage\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:846\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=842'>843</a>\u001b[0m dtype \u001b[39m=\u001b[39m data_type(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=844'>845</a>\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, size, dtype)\u001b[39m.\u001b[39mstorage()\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=845'>846</a>\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m restore_location(storage, location)\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=172'>173</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=173'>174</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=174'>175</a>\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=175'>176</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=176'>177</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:151\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=148'>149</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=149'>150</a>\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=150'>151</a>\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=151'>152</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=152'>153</a>\u001b[0m             storage_type \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39mcuda, \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py:135\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=131'>132</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=133'>134</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=134'>135</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=135'>136</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=136'>137</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=137'>138</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=138'>139</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=139'>140</a>\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    <a href='file:///home/dk/miniconda3/envs/privSecAI/lib/python3.8/site-packages/torch/serialization.py?line=140'>141</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "client = torch.load('./weights/trained_client_ptbxl_4096.pth')\n",
    "server = torch.load('weights/trained_server_ptbxl_4096.pth')\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=12, \n",
    "                                out_channels=16, \n",
    "                                kernel_size=7, \n",
    "                                padding=3,\n",
    "                                stride=1)  # 16 x 1000\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 16 x 500\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, \n",
    "                                out_channels=8, \n",
    "                                kernel_size=5, \n",
    "                                padding=2)  # 8 x 500\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 8 x 250\n",
    "        \n",
    "        self.linear = nn.Linear(in_features=8*250,\n",
    "                                out_features=5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.load_weights()\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.conv1.weight.data = client[\"conv1.weight\"]\n",
    "        self.conv1.bias.data = client[\"conv1.bias\"]\n",
    "        self.conv2.weight.data = client[\"conv2.weight\"]\n",
    "        self.conv2.bias.data = client[\"conv2.bias\"]\n",
    "        self.linear.weight.data = server[\"W\"]\n",
    "        self.linear.bias.data = server[\"b\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 8*250)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = ECGModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: NVIDIA GeForce RTX 2060\n",
      "test_loss: 1.2454, test_acc: 65.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def test(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for _, batch in enumerate(test_loader):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss += loss.item()\n",
    "            correct += torch.sum(y_hat.argmax(dim=1) == y).item()\n",
    "            total += len(y)\n",
    "    print(f\"test_loss: {(test_loss/len(test_loader)):.4f}, \"\n",
    "          f\"test_acc: {((correct/total)*100):.2f}\")\n",
    "\n",
    "test(model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e85e1ad9491ad1c682eddae450c0709b489a0cca29d103fde5874c05d9a030a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('privSecAI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
