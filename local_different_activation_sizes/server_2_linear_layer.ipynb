{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.8.1+cu102\n",
      "tenseal version: 0.3.5\n",
      "project_path: /home/dk/Desktop/split-learning-1D-HE\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from icecream import ic\n",
    "ic.configureOutput(includeContext=True)\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'tenseal version: {ts.__version__}')\n",
    "\n",
    "project_path = Path.cwd().parent\n",
    "print(f'project_path: {project_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    \"\"\"The class used by the client to load the dataset\n",
    "\n",
    "    Args:\n",
    "        Dataset ([type]): [description]\n",
    "    \"\"\"\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(project_path/'data/train_ecg.hdf5', 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(project_path/'data/test_ecg.hdf5', 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: NVIDIA GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "lr = 0.001\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'device: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def train(model, save_weight_path: str):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = list()\n",
    "    train_accs = list()\n",
    "    train_times = list()\n",
    "\n",
    "    test_losses = list()\n",
    "    test_accs = list()\n",
    "    test_times = list()\n",
    "\n",
    "    best_test_acc = 0  # best test accuracy \n",
    "\n",
    "    for e in range(epoch):\n",
    "        train_start = time.time()\n",
    "        print(\"Epoch {} - \".format(e+1), end='')\n",
    "\n",
    "        # train\n",
    "        train_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x, label = batch  # get feature and label from a batch\n",
    "            x, label = x.to(device), label.to(device)  # send to device\n",
    "            optimizer.zero_grad()  # init all grads to zero\n",
    "            output = model(x)  # forward propagation\n",
    "            loss = criterion(output, label)  # calculate loss\n",
    "            loss.backward()  # backward propagation\n",
    "            optimizer.step()  # weight update\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            correct += torch.sum(output.argmax(dim=1) == label).item()\n",
    "            total += len(label)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accs.append(correct / total)\n",
    "        train_end = time.time()\n",
    "        train_times.append(train_end-train_start)\n",
    "        print(\"loss: {:.4f}, acc: {:.2f}%\".format(train_losses[-1], train_accs[-1]*100), end=' / ')\n",
    "    \n",
    "        # test\n",
    "        test_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            correct, total = 0, 0\n",
    "            for _, batch in enumerate(test_loader):\n",
    "                x, label = batch\n",
    "                x, label = x.to(device), label.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, label)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                correct += torch.sum(output.argmax(dim=1) == label).item()\n",
    "                total += len(label)\n",
    "            test_losses.append(test_loss / len(test_loader))\n",
    "            test_acc = correct / total\n",
    "            test_accs.append(test_acc)\n",
    "        test_end = time.time()\n",
    "        test_times.append(test_end-test_start)\n",
    "        print(\"test_loss: {:.4f}, test_acc: {:.2f}%\".format(test_losses[-1], test_accs[-1]*100))\n",
    "        if test_accs[-1] > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(ecgnet.state_dict(), save_weight_path)  # save trained weights\n",
    "            print(f\"found new best test accuracy: {test_acc*100:.2f}%, save model\")\n",
    "\n",
    "    return train_losses, train_accs, train_times, test_losses, test_accs, test_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: 512 (activation maps length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 1.1628, acc: 74.79% / test_loss: 1.0431, test_acc: 86.99%\n",
      "found new best test accuracy: 86.99%, save model\n",
      "Epoch 2 - loss: 1.0341, acc: 87.33% / test_loss: 0.9923, test_acc: 91.57%\n",
      "found new best test accuracy: 91.57%, save model\n",
      "Epoch 3 - loss: 0.9953, acc: 91.06% / test_loss: 0.9877, test_acc: 91.84%\n",
      "found new best test accuracy: 91.84%, save model\n",
      "Epoch 4 - loss: 0.9921, acc: 91.30% / test_loss: 0.9706, test_acc: 93.47%\n",
      "found new best test accuracy: 93.47%, save model\n",
      "Epoch 5 - loss: 0.9823, acc: 92.34% / test_loss: 0.9688, test_acc: 93.67%\n",
      "found new best test accuracy: 93.67%, save model\n",
      "Epoch 6 - loss: 0.9781, acc: 92.71% / test_loss: 0.9681, test_acc: 93.70%\n",
      "found new best test accuracy: 93.70%, save model\n",
      "Epoch 7 - loss: 0.9742, acc: 93.07% / test_loss: 0.9668, test_acc: 93.91%\n",
      "found new best test accuracy: 93.91%, save model\n",
      "Epoch 8 - loss: 0.9740, acc: 93.18% / test_loss: 0.9658, test_acc: 93.89%\n",
      "Epoch 9 - loss: 0.9709, acc: 93.37% / test_loss: 0.9639, test_acc: 94.12%\n",
      "found new best test accuracy: 94.12%, save model\n",
      "Epoch 10 - loss: 0.9723, acc: 93.27% / test_loss: 0.9632, test_acc: 94.22%\n",
      "found new best test accuracy: 94.22%, save model\n"
     ]
    }
   ],
   "source": [
    "class ECGConv1D512(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGConv1D512, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 16 = 512\n",
    "\n",
    "        self.linear1 = nn.Linear(512, 128)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(128, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "ecgnet = ECGConv1D512()\n",
    "train_losses, train_accs, train_times, \\\n",
    "        test_losses, test_accs, test_times = train(ecgnet.to(device),\n",
    "                                                'weights/trained_weight_512_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 1.2078, acc: 70.23% / test_loss: 1.0692, test_acc: 84.57%\n",
      "found new best test accuracy: 84.57%, save model\n",
      "Epoch 2 - loss: 1.0606, acc: 84.72% / test_loss: 1.0276, test_acc: 88.05%\n",
      "found new best test accuracy: 88.05%, save model\n",
      "Epoch 3 - loss: 1.0407, acc: 86.52% / test_loss: 1.0249, test_acc: 88.09%\n",
      "found new best test accuracy: 88.09%, save model\n",
      "Epoch 4 - loss: 1.0349, acc: 86.98% / test_loss: 1.0215, test_acc: 88.34%\n",
      "found new best test accuracy: 88.34%, save model\n",
      "Epoch 5 - loss: 1.0279, acc: 87.58% / test_loss: 1.0143, test_acc: 88.95%\n",
      "found new best test accuracy: 88.95%, save model\n",
      "Epoch 6 - loss: 1.0255, acc: 87.93% / test_loss: 1.0089, test_acc: 89.45%\n",
      "found new best test accuracy: 89.45%, save model\n",
      "Epoch 7 - loss: 1.0225, acc: 88.15% / test_loss: 1.0098, test_acc: 89.39%\n",
      "Epoch 8 - loss: 1.0226, acc: 88.12% / test_loss: 1.0093, test_acc: 89.35%\n",
      "Epoch 9 - loss: 1.0226, acc: 88.14% / test_loss: 1.0085, test_acc: 89.42%\n",
      "Epoch 10 - loss: 1.0196, acc: 88.44% / test_loss: 1.0083, test_acc: 89.55%\n",
      "found new best test accuracy: 89.55%, save model\n"
     ]
    }
   ],
   "source": [
    "class ECGConv1D256(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGConv1D256, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 8, 5, padding=2)  # 64 x 8\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 8 = 256\n",
    "\n",
    "        self.linear1 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(128, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "ecgnet = ECGConv1D256()\n",
    "train_losses, train_accs, train_times, \\\n",
    "        test_losses, test_accs, test_times = train(ecgnet.to(device), \n",
    "                            'weights/trained_weight_256_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 1.2370, acc: 67.47% / test_loss: 1.0895, test_acc: 82.45%\n",
      "found new best test accuracy: 82.45%, save model\n",
      "Epoch 2 - loss: 1.0658, acc: 84.18% / test_loss: 1.0363, test_acc: 86.91%\n",
      "found new best test accuracy: 86.91%, save model\n",
      "Epoch 3 - loss: 1.0456, acc: 86.04% / test_loss: 1.0274, test_acc: 87.83%\n",
      "found new best test accuracy: 87.83%, save model\n",
      "Epoch 4 - loss: 1.0349, acc: 87.01% / test_loss: 1.0239, test_acc: 88.05%\n",
      "found new best test accuracy: 88.05%, save model\n",
      "Epoch 5 - loss: 1.0311, acc: 87.33% / test_loss: 1.0134, test_acc: 89.02%\n",
      "found new best test accuracy: 89.02%, save model\n",
      "Epoch 6 - loss: 1.0270, acc: 87.72% / test_loss: 1.0119, test_acc: 89.22%\n",
      "found new best test accuracy: 89.22%, save model\n",
      "Epoch 7 - loss: 1.0239, acc: 87.97% / test_loss: 1.0130, test_acc: 89.11%\n",
      "Epoch 8 - loss: 1.0238, acc: 87.95% / test_loss: 1.0110, test_acc: 89.27%\n",
      "found new best test accuracy: 89.27%, save model\n",
      "Epoch 9 - loss: 1.0201, acc: 88.35% / test_loss: 1.0099, test_acc: 89.29%\n",
      "found new best test accuracy: 89.29%, save model\n",
      "Epoch 10 - loss: 1.0207, acc: 88.34% / test_loss: 1.0078, test_acc: 89.52%\n",
      "found new best test accuracy: 89.52%, save model\n"
     ]
    }
   ],
   "source": [
    "class ECGConv1D128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGConv1D128, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 4, 5, padding=2)  # 64 x 4\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 4 = 128\n",
    "\n",
    "        self.linear1 = nn.Linear(128, 128)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(128, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "ecgnet = ECGConv1D128()\n",
    "train_losses, train_accs, train_times, \\\n",
    "        test_losses, test_accs, test_times = train(ecgnet.to(device), \n",
    "                            'weights/trained_weight_128_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 1.2298, acc: 67.66% / test_loss: 1.0946, test_acc: 81.53%\n",
      "found new best test accuracy: 81.53%, save model\n",
      "Epoch 2 - loss: 1.1001, acc: 80.45% / test_loss: 1.0754, test_acc: 82.83%\n",
      "found new best test accuracy: 82.83%, save model\n",
      "Epoch 3 - loss: 1.0759, acc: 82.96% / test_loss: 1.0295, test_acc: 87.75%\n",
      "found new best test accuracy: 87.75%, save model\n",
      "Epoch 4 - loss: 1.0419, acc: 86.42% / test_loss: 1.0185, test_acc: 88.68%\n",
      "found new best test accuracy: 88.68%, save model\n",
      "Epoch 5 - loss: 1.0331, acc: 87.26% / test_loss: 1.0162, test_acc: 88.85%\n",
      "found new best test accuracy: 88.85%, save model\n",
      "Epoch 6 - loss: 1.0287, acc: 87.61% / test_loss: 1.0158, test_acc: 88.95%\n",
      "found new best test accuracy: 88.95%, save model\n",
      "Epoch 7 - loss: 1.0252, acc: 87.97% / test_loss: 1.0121, test_acc: 89.14%\n",
      "found new best test accuracy: 89.14%, save model\n",
      "Epoch 8 - loss: 1.0230, acc: 88.04% / test_loss: 1.0148, test_acc: 88.86%\n",
      "Epoch 9 - loss: 1.0213, acc: 88.21% / test_loss: 1.0143, test_acc: 88.92%\n",
      "Epoch 10 - loss: 1.0211, acc: 88.27% / test_loss: 1.0137, test_acc: 89.08%\n"
     ]
    }
   ],
   "source": [
    "class ECGConv1D64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGConv1D64, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 2, 5, padding=2)  # 64 x 2\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 2 = 64\n",
    "\n",
    "        self.linear1 = nn.Linear(64, 128)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(128, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "ecgnet = ECGConv1D64()\n",
    "train_losses, train_accs, train_times, \\\n",
    "        test_losses, test_accs, test_times = train(ecgnet.to(device),\n",
    "                                'weights/trained_weight_64_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fb056718432581df00ec0ea1d8474ad391dc3f52021963853b762465b19daea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('privsecai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
