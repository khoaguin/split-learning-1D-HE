{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECG Split 1D-CNN Client Side"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code is the client part of ECG split 1D-CNN model for a **single** client and a server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import required packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from typing import List\n",
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import tenseal as ts\n",
    "from tenseal.enc_context import Context\n",
    "from tenseal.tensors.ckksvector import CKKSVector\n",
    "from tenseal.tensors.ckkstensor import CKKSTensor\n",
    "from tenseal.tensors.plaintensor import PlainTensor\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'tenseal version: {ts.__version__}')\n",
    "\n",
    "project_path = Path.cwd().parent.parent\n",
    "print(f'project_path: {project_path}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch version: 1.8.1+cu102\n",
      "tenseal version: 0.3.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Socket initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "host = 'localhost'\n",
    "port = 10080\n",
    "max_recv = 4096\n",
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions to send and receive messages through sockets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    return recvall(sock, msglen)\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define ECG dataset class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# paths to files and directories\n",
    "data_dir = 'data'  # used to be 'mitdb'\n",
    "train_name = 'train_ecg.hdf5'\n",
    "test_name = 'test_ecg.hdf5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(project_path/data_dir/train_name, 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(project_path/data_dir/test_name, 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set batch size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dry_run = True # break after 2 batches for 2 epoch, set batch size to be 2\n",
    "if dry_run:\n",
    "    batch_size = 2\n",
    "    epoch = 2\n",
    "else:\n",
    "    batch_size = 32\n",
    "    epoch = 400"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make train and test dataset batch generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "len(train_dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13245"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for i, b in enumerate(train_loader):\n",
    "    ic(b[0].shape, b[1])\n",
    "    if i == 1: break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| b[0].shape: torch.Size([2, 1, 128]), b[1]: tensor([2, 4])\n",
      "ic| b[0].shape: torch.Size([2, 1, 128]), b[1]: tensor([2, 4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Total number of batches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "total_batch = len(train_loader)\n",
    "print(f'total_batch: {total_batch}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total_batch: 6623\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making TenSeal context"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The client makes the context to homomorphically encrypt and decrypt the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def context(poly_modulus_degree: int, \n",
    "            coeff_mod_bit_sizes: List[int], \n",
    "            glob_scale: int) -> Context:\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS, \n",
    "        poly_modulus_degree=poly_modulus_degree, \n",
    "        coeff_mod_bit_sizes=coeff_mod_bit_sizes\n",
    "    )\n",
    "    context.global_scale = glob_scale\n",
    "    # context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "context = context(4096, [40, 20, 40], pow(2, 20))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ic(context.has_galois_keys())\n",
    "ic(context.has_secret_key())\n",
    "ic(context.has_relin_keys())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| context.has_galois_keys(): False\n",
      "ic| context.has_secret_key(): True\n",
      "ic| context.has_relin_keys(): True\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define ECG client model\n",
    "Client side has only **2 convolutional layers**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class EcgClient(nn.Module):\n",
    "    # will be sent to the client\n",
    "    def __init__(self, context: Context):\n",
    "        super(EcgClient, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        \n",
    "        self.load_init_weights()\n",
    "        self.context = context\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> CKKSTensor:\n",
    "        x = self.conv1(x)  # [batch_size, 16, 128]\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)  # [batch_size, 16, 64]\n",
    "        x = self.conv2(x)  # [batch_size, 16, 64]\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 32 * 16)  # [batch_size, 16, 32]\n",
    "        enc_x: CKKSTensor = ts.ckks_tensor(self.context, x.tolist())  # [batch_size, 512]\n",
    "        return enc_x\n",
    "    \n",
    "    def load_init_weights(self):\n",
    "        checkpoint = torch.load(\"init_weight.pth\")\n",
    "        self.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
    "        self.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
    "        self.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
    "        self.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\" \n",
    "        Calculates the gradients\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_params(self):\n",
    "        \"\"\"\n",
    "        Update the parameters based on the gradients calculated in backward()\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {torch.cuda.get_device_name(0)}')\n",
    "ecg_client = EcgClient(context=context)\n",
    "ecg_client.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device: NVIDIA GeForce GTX 1070 Ti\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EcgClient(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Send the `batch_size`, `total_batch`, and the `epoch` to the server"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "msg = {'batch_size': batch_size,\n",
    "       'total_batch': total_batch,\n",
    "       'epoch': epoch}\n",
    "send_msg(sock=s, msg=pickle.dumps(msg))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'total_batch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17493/2565651307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m msg = {'batch_size': batch_size,\n\u001b[0;32m----> 2\u001b[0;31m        \u001b[0;34m'total_batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m        'epoch': epoch}\n\u001b[1;32m      4\u001b[0m \u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_batch' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set random seed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set some parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "# we will define our own update_params() function\n",
    "# optimizer = Adam(ecg_client.parameters(), lr=lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and testing loop (client)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "train_losses = list()\n",
    "train_accs = list()\n",
    "test_losses = list()\n",
    "test_accs = list()\n",
    "best_test_acc = 0  # best test accuracy\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(\"Epoch {} - \".format(e+1), end='')\n",
    "    \n",
    "    # training loop\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x, y_gt = batch  # get the input data and ground-truth output in the batch\n",
    "        x, y_gt = x.to(device), y_gt.to(device)  # put to cuda or cpu\n",
    "        enc_activ: CKKSTensor = ecg_client(x)  # [batch_size, 512]\n",
    "        enc_activ_bytes: bytes = enc_activ.serialize()  # converting into a byte tream\n",
    "        # the client sends the encrypted activation maps to the server\n",
    "        send_msg(sock=s, msg=enc_activ_bytes)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Finished Training!')\n",
    "print('Result is on the server side.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training!\n",
      "Result is on the server side.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimentations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = torch.tensor([[1,2], [3,4]], requires_grad=True, dtype=torch.float32)\n",
    "y = 2*x\n",
    "y.retain_grad()\n",
    "a = y.mean()\n",
    "\n",
    "ic(x,y,a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| x: tensor([[1., 2.],\n",
      "               [3., 4.]], requires_grad=True)\n",
      "    y: tensor([[2., 4.],\n",
      "               [6., 8.]], grad_fn=<MulBackward0>)\n",
      "    a: tensor(5., grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [3., 4.]], requires_grad=True),\n",
       " tensor([[2., 4.],\n",
       "         [6., 8.]], grad_fn=<MulBackward0>),\n",
       " tensor(5., grad_fn=<MeanBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchviz import make_dot\n",
    "make_dot(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"216pt\"\n viewBox=\"0.00 0.00 109.00 216.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 212)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-212 105,-212 105,4 -4,4\"/>\n<!-- 140578249954944 -->\n<g id=\"node1\" class=\"node\">\n<title>140578249954944</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"80,-31 21,-31 21,0 80,0 80,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n</g>\n<!-- 140578250346752 -->\n<g id=\"node2\" class=\"node\">\n<title>140578250346752</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140578250346752&#45;&gt;140578249954944 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140578250346752&#45;&gt;140578249954944</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 140578250346848 -->\n<g id=\"node3\" class=\"node\">\n<title>140578250346848</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140578250346848&#45;&gt;140578250346752 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140578250346848&#45;&gt;140578250346752</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 140578631709312 -->\n<g id=\"node4\" class=\"node\">\n<title>140578631709312</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-208 21,-208 21,-177 80,-177 80,-208\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n</g>\n<!-- 140578631709312&#45;&gt;140578250346848 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140578631709312&#45;&gt;140578250346848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.92C50.5,-169.22 50.5,-159.69 50.5,-151.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.25 50.5,-141.25 47,-151.25 54,-151.25\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fdaecacd1f0>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "make_dot(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n<!-- 140578250400192 -->\n<g id=\"node1\" class=\"node\">\n<title>140578250400192</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140578281060240 -->\n<g id=\"node2\" class=\"node\">\n<title>140578281060240</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-86 3,-86 3,-67 98,-67 98,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140578281060240&#45;&gt;140578250400192 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140578281060240&#45;&gt;140578250400192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 140578281013696 -->\n<g id=\"node3\" class=\"node\">\n<title>140578281013696</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140578281013696&#45;&gt;140578281060240 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140578281013696&#45;&gt;140578281060240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 140578281013984 -->\n<g id=\"node4\" class=\"node\">\n<title>140578281013984</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140578281013984&#45;&gt;140578281013696 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140578281013984&#45;&gt;140578281013696</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 140578250287616 -->\n<g id=\"node5\" class=\"node\">\n<title>140578250287616</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-263 21,-263 21,-232 80,-232 80,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n</g>\n<!-- 140578250287616&#45;&gt;140578281013984 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140578250287616&#45;&gt;140578281013984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fdaecacd910>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ic(y.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| y.grad: tensor([[0.2500, 0.2500],\n",
      "                    [0.2500, 0.2500]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500],\n",
       "        [0.2500, 0.2500]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ic(x.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| x.grad: tensor([[0.5000, 0.5000],\n",
      "                    [0.5000, 0.5000]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a2 = a.clone().detach().requires_grad_(True)\n",
    "pickle.dumps(a2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95}\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x0ctorch._utils\\x94\\x8c\\x12_rebuild_tensor_v2\\x94\\x93\\x94(\\x8c\\rtorch.storage\\x94\\x8c\\x10_load_from_bytes\\x94\\x93\\x94C\\xff\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nFloatStorage\\nq\\x01X\\x0e\\x00\\x00\\x0094019819879440q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\x01Ntq\\x04Q.\\x80\\x02]q\\x00X\\x0e\\x00\\x00\\x0094019819879440q\\x01a.\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa0@\\x94\\x85\\x94R\\x94K\\x00))\\x88\\x8c\\x0bcollections\\x94\\x8c\\x0bOrderedDict\\x94\\x93\\x94)R\\x94t\\x94R\\x94.'"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('privsecai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "interpreter": {
   "hash": "9a6a5787b9bb005a7f5e8899bec1bce39ba8d948a4a7b9b2f0130e20a30245b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}