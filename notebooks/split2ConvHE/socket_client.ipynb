{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ECG Split 1D-CNN Client Side"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code is the server part of ECG split 1D-CNN model for **single** client and a server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import required packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from typing import List\n",
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import tenseal as ts\n",
    "from tenseal.tensors.ckksvector import CKKSVector\n",
    "from tenseal.enc_context import Context\n",
    "\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'tenseal version: {ts.__version__}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch version: 1.8.1+cu102\n",
      "tenseal version: 0.3.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define ECG dataset class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "project_path = Path.cwd().parent.parent\n",
    "print(f'project_path: {project_path}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "project_path: /home/dk/Desktop/split-learning-1D-HE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# paths to files and directories\n",
    "data_dir = 'data'  # used to be 'mitdb'\n",
    "train_name = 'train_ecg.hdf5'\n",
    "test_name = 'test_ecg.hdf5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(project_path/data_dir/train_name, 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(project_path/data_dir/test_name, 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set batch size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "batch_size = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make train and test dataset batch generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for i, b in enumerate(train_loader):\n",
    "    ic(b[0].shape, b[1])\n",
    "    if i == 1: break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| b[0].shape: torch.Size([32, 1, 128])\n",
      "    b[1]: tensor([2, 4, 2, 4, 2, 1, 1, 1, 2, 1, 0, 0, 2, 4, 3, 1, 2, 4, 1, 0, 1, 0, 4, 2,\n",
      "                  4, 3, 0, 1, 2, 4, 4, 2])\n",
      "ic| b[0].shape: torch.Size([32, 1, 128])\n",
      "    b[1]: tensor([0, 4, 3, 4, 2, 0, 1, 4, 1, 0, 3, 4, 2, 4, 1, 0, 2, 0, 0, 2, 0, 1, 1, 0,\n",
      "                  2, 4, 4, 2, 4, 4, 1, 4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Total number of batches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "total_batch = len(train_loader)\n",
    "print(total_batch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "414\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making TenSeal context"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The client makes the context to homomorphically encrypt and decrypt the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def context(poly_modulus_degree: int, \n",
    "            coeff_mod_bit_sizes: List[int], \n",
    "            glob_scale: int) -> Context:\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS, \n",
    "        poly_modulus_degree=poly_modulus_degree, \n",
    "        coeff_mod_bit_sizes=coeff_mod_bit_sizes\n",
    "    )\n",
    "    context.global_scale = glob_scale\n",
    "    context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "context = context(8192, [60, 40, 40, 60], pow(2, 40))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define ECG client model\n",
    "Client side has only **2 convolutional layers**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class EcgClient(nn.Module):\n",
    "    # will be sent to the client\n",
    "    def __init__(self, context: Context):\n",
    "        super(EcgClient, self).__init__()\n",
    "        self.conv1 = self.torch_ref.nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = self.torch_ref.nn.LeakyReLU()\n",
    "        self.pool1 = self.torch_ref.nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = self.torch_ref.nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = self.torch_ref.nn.LeakyReLU()\n",
    "        self.pool2 = self.torch_ref.nn.MaxPool1d(2)  # 32 x 16\n",
    "        \n",
    "        self.load_init_weights()\n",
    "        self.context = context\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        # x is a syft's TensorPointer. x.get() returns torch.Tensor of size [1, 512]\n",
    "        enc_x: CKKSTensor = self.encrypt_activations(x)  # enc_x is a list of 512 elements\n",
    "        return enc_x\n",
    "    \n",
    "    def load_init_weights(self):\n",
    "        checkpoint = torch.load(\"init_weight.pth\")\n",
    "        self.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
    "        self.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
    "        self.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
    "        self.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
    "    \n",
    "    def encrypt_activations(self, x: torch.Tensor):\n",
    "        enc_x: CKKSVector = ts.ckks_vector(self.context, x.tolist()[0])\n",
    "        return enc_x\n",
    "\n",
    "ecg_client = EcgClient(torch_ref=torch, context=context)        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.get_device_name(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070 Ti'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set random seed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assign intial weight as same as non-split model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "ecg_client = EcgClient()\n",
    "checkpoint = torch.load(\"init_weight.pth\")\n",
    "ecg_client.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
    "ecg_client.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
    "ecg_client.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
    "ecg_client.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
    "ecg_client.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EcgClient(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the server side."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "epoch = 400\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = Adam(ecg_client.parameters(), lr=lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Socket initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Required socket functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    return recvall(sock, msglen)\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set host address and port number"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "host = 'localhost'\n",
    "port = 10080\n",
    "max_recv = 4096"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open the client socket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "type(s)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "socket.socket"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real training process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "dry_run = True # break after 2 batches for 2 epoch\n",
    "\n",
    "train_losses = list()\n",
    "train_accs = list()\n",
    "test_losses = list()\n",
    "test_accs = list()\n",
    "best_test_acc = 0  # best test accuracy\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(\"Epoch {} - \".format(e+1), end='')\n",
    "    \n",
    "    # training loop\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x, y_gt = batch\n",
    "        x, y_gt = x.to(device), y_gt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = ecg_client(x)\n",
    "        \n",
    "        ic(y_hat)\n",
    "        if dry_run:\n",
    "            if i == 1: break\n",
    "    \n",
    "    if dry_run:\n",
    "        if e == 2: break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| y_hat: tensor([[0.1132, 0.1128, 0.0665,  ..., 0.0355, 0.0208, 0.0751],\n",
      "                   [0.1149, 0.1061, 0.0750,  ..., 0.0932, 0.0821, 0.1289],\n",
      "                   [0.1143, 0.1103, 0.0829,  ..., 0.0584, 0.0451, 0.0943],\n",
      "                   ...,\n",
      "                   [0.1159, 0.1033, 0.0660,  ..., 0.0716, 0.0796, 0.1377],\n",
      "                   [0.1165, 0.1005, 0.0622,  ..., 0.1024, 0.0983, 0.1450],\n",
      "                   [0.1145, 0.1098, 0.0829,  ..., 0.0214, 0.0144, 0.0655]],\n",
      "                  device='cuda:0', grad_fn=<ViewBackward>)\n",
      "ic| y_hat: tensor([[ 1.1821e-01,  9.4653e-02,  5.2847e-02,  ...,  5.0661e-02,\n",
      "                     3.8753e-02,  9.4769e-02],\n",
      "                   [ 1.2001e-01,  1.0305e-01,  7.0538e-02,  ..., -1.1005e-05,\n",
      "                    -1.2015e-04,  2.3481e-02],\n",
      "                   [ 1.1315e-01,  1.1298e-01,  8.3798e-02,  ...,  4.6220e-02,\n",
      "                     4.3631e-02,  1.0562e-01],\n",
      "                   ...,\n",
      "                   [ 1.1760e-01,  1.1810e-01,  9.9960e-02,  ...,  9.2215e-03,\n",
      "                     1.5684e-03,  4.3523e-02],\n",
      "                   [ 1.1557e-01,  1.0518e-01,  7.1905e-02,  ...,  3.3013e-02,\n",
      "                     2.1351e-02,  7.5075e-02],\n",
      "                   [ 1.1511e-01,  1.0516e-01,  7.2215e-02,  ...,  9.6666e-02,\n",
      "                     8.4138e-02,  1.2988e-01]], device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| y_hat: tensor([[0.1132, 0.1128, 0.0665,  ..., 0.0355, 0.0208, 0.0751],\n",
      "                   [0.1149, 0.1061, 0.0750,  ..., 0.0932, 0.0821, 0.1289],\n",
      "                   [0.1143, 0.1103, 0.0829,  ..., 0.0584, 0.0451, 0.0943],\n",
      "                   ...,\n",
      "                   [0.1159, 0.1033, 0.0660,  ..., 0.0716, 0.0796, 0.1377],\n",
      "                   [0.1165, 0.1005, 0.0622,  ..., 0.1024, 0.0983, 0.1450],\n",
      "                   [0.1145, 0.1098, 0.0829,  ..., 0.0214, 0.0144, 0.0655]],\n",
      "                  device='cuda:0', grad_fn=<ViewBackward>)\n",
      "ic| y_hat: tensor([[ 1.1821e-01,  9.4653e-02,  5.2847e-02,  ...,  5.0661e-02,\n",
      "                     3.8753e-02,  9.4769e-02],\n",
      "                   [ 1.2001e-01,  1.0305e-01,  7.0538e-02,  ..., -1.1005e-05,\n",
      "                    -1.2015e-04,  2.3481e-02],\n",
      "                   [ 1.1315e-01,  1.1298e-01,  8.3798e-02,  ...,  4.6220e-02,\n",
      "                     4.3631e-02,  1.0562e-01],\n",
      "                   ...,\n",
      "                   [ 1.1760e-01,  1.1810e-01,  9.9960e-02,  ...,  9.2215e-03,\n",
      "                     1.5684e-03,  4.3523e-02],\n",
      "                   [ 1.1557e-01,  1.0518e-01,  7.1905e-02,  ...,  3.3013e-02,\n",
      "                     2.1351e-02,  7.5075e-02],\n",
      "                   [ 1.1511e-01,  1.0516e-01,  7.2215e-02,  ...,  9.6666e-02,\n",
      "                     8.4138e-02,  1.2988e-01]], device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3 - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| y_hat: tensor([[0.1132, 0.1128, 0.0665,  ..., 0.0355, 0.0208, 0.0751],\n",
      "                   [0.1149, 0.1061, 0.0750,  ..., 0.0932, 0.0821, 0.1289],\n",
      "                   [0.1143, 0.1103, 0.0829,  ..., 0.0584, 0.0451, 0.0943],\n",
      "                   ...,\n",
      "                   [0.1159, 0.1033, 0.0660,  ..., 0.0716, 0.0796, 0.1377],\n",
      "                   [0.1165, 0.1005, 0.0622,  ..., 0.1024, 0.0983, 0.1450],\n",
      "                   [0.1145, 0.1098, 0.0829,  ..., 0.0214, 0.0144, 0.0655]],\n",
      "                  device='cuda:0', grad_fn=<ViewBackward>)\n",
      "ic| y_hat: tensor([[ 1.1821e-01,  9.4653e-02,  5.2847e-02,  ...,  5.0661e-02,\n",
      "                     3.8753e-02,  9.4769e-02],\n",
      "                   [ 1.2001e-01,  1.0305e-01,  7.0538e-02,  ..., -1.1005e-05,\n",
      "                    -1.2015e-04,  2.3481e-02],\n",
      "                   [ 1.1315e-01,  1.1298e-01,  8.3798e-02,  ...,  4.6220e-02,\n",
      "                     4.3631e-02,  1.0562e-01],\n",
      "                   ...,\n",
      "                   [ 1.1760e-01,  1.1810e-01,  9.9960e-02,  ...,  9.2215e-03,\n",
      "                     1.5684e-03,  4.3523e-02],\n",
      "                   [ 1.1557e-01,  1.0518e-01,  7.1905e-02,  ...,  3.3013e-02,\n",
      "                     2.1351e-02,  7.5075e-02],\n",
      "                   [ 1.1511e-01,  1.0516e-01,  7.2215e-02,  ...,  9.6666e-02,\n",
      "                     8.4138e-02,  1.2988e-01]], device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print('Finished Training!')\n",
    "print('Result is on the server side.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training!\n",
      "Result is on the server side.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('privsecai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "interpreter": {
   "hash": "9a6a5787b9bb005a7f5e8899bec1bce39ba8d948a4a7b9b2f0130e20a30245b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}