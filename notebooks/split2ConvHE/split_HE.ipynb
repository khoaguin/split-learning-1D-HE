{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training split 1D CNN on homomorphic encrypted ECG data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Package versions:  \n",
        "`torch`: 1.8.1+cu102  \n",
        "`pysyft`: 0.5.0  \n",
        "`tenseal`: 0.3.5  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from pathlib import Path\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from icecream import ic\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import syft as sy\n",
        "from syft.core.node.vm.vm import VirtualMachine\n",
        "from syft.core.node.vm.client import VirtualMachineClient\n",
        "from syft.ast.module import Module\n",
        "from syft.core.remote_dataloader import RemoteDataLoader\n",
        "from syft.core.remote_dataloader import RemoteDataset\n",
        "\n",
        "import tenseal as ts\n",
        "from tenseal.tensors.ckksvector import CKKSVector\n",
        "from tenseal.enc_context import Context\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'syft version: {sy.__version__}')\n",
        "print(f'tenseal version: {ts.__version__}')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch version: 1.8.1+cu102\nsyft version: 0.5.0\ntenseal version: 0.3.5\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1632467718061
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Files and Directories"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = Path.cwd().parent.parent\n",
        "print(f'project_path: {project_path}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "project_path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/teslak80-56gbram/code/Users/dkn.work/split-learning-he\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1632467718458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to files and directories\n",
        "data_dir = 'data'  # used to be 'mitdb'\n",
        "train_name = 'train_ecg.hdf5'\n",
        "test_name = 'test_ecg.hdf5'\n",
        "dry_run = True  # load less data (50 examples)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467718705
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the client and server"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "server: VirtualMachine = sy.VirtualMachine(name=\"server\")\n",
        "client: VirtualMachineClient = server.get_root_client()\n",
        "remote_torch: Module = client.torch\n",
        "remote_torch"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Module:\n\t.Tensor -> <syft.ast.klass.Class object at 0x7ffb10d8a5e0>\n\t.BFloat16Tensor -> <syft.ast.klass.Class object at 0x7ffb10d8a640>\n\t.BoolTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a6a0>\n\t.ByteTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a700>\n\t.CharTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a760>\n\t.DoubleTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a7c0>\n\t.FloatTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a820>\n\t.HalfTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a880>\n\t.IntTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a8e0>\n\t.LongTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a940>\n\t.ShortTensor -> <syft.ast.klass.Class object at 0x7ffb10d8a9a0>\n\t.nn -> Module:\n\t\t.Parameter -> <syft.ast.klass.Class object at 0x7ffb10d8aac0>\n\t\t.Module -> <syft.ast.klass.Class object at 0x7ffb10bbafa0>\n\t\t.Conv2d -> <syft.ast.klass.Class object at 0x7ffb10bc04c0>\n\t\t.Dropout2d -> <syft.ast.klass.Class object at 0x7ffb10bc08e0>\n\t\t.Linear -> <syft.ast.klass.Class object at 0x7ffb10bc0c40>\n\t\t.functional -> Module:\n\t\t\t.relu -> <syft.ast.callable.Callable object at 0x7ffb10b44580>\n\t\t\t.gelu -> <syft.ast.callable.Callable object at 0x7ffb10b445e0>\n\t\t\t.max_pool2d -> <syft.ast.callable.Callable object at 0x7ffb10b44640>\n\t\t\t.log_softmax -> <syft.ast.callable.Callable object at 0x7ffb10b446a0>\n\t\t\t.cosine_embedding_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e460>\n\t\t\t.ctc_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e4c0>\n\t\t\t.hinge_embedding_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e580>\n\t\t\t.l1_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e5e0>\n\t\t\t.margin_ranking_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e6a0>\n\t\t\t.mse_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e700>\n\t\t\t.multi_margin_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e7c0>\n\t\t\t.multilabel_margin_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e880>\n\t\t\t.multilabel_soft_margin_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e940>\n\t\t\t.nll_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4e9a0>\n\t\t\t.cross_entropy -> <syft.ast.callable.Callable object at 0x7ffb10b4ea60>\n\t\t\t.poisson_nll_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4eb20>\n\t\t\t.smooth_l1_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4ebe0>\n\t\t\t.soft_margin_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4eca0>\n\t\t\t.triplet_margin_loss -> <syft.ast.callable.Callable object at 0x7ffb10b4ed60>\n\n\t\t.Sequential -> <syft.ast.klass.Class object at 0x7ffb10b4e0a0>\n\t\t.AdaptiveLogSoftmaxWithLoss -> <syft.ast.klass.Class object at 0x7ffb10b4ee20>\n\t\t.BCELoss -> <syft.ast.klass.Class object at 0x7ffb10b4efa0>\n\t\t.BCEWithLogitsLoss -> <syft.ast.klass.Class object at 0x7ffb10b500a0>\n\t\t.CTCLoss -> <syft.ast.klass.Class object at 0x7ffb10b501c0>\n\t\t.CrossEntropyLoss -> <syft.ast.klass.Class object at 0x7ffb10b50280>\n\t\t.CosineEmbeddingLoss -> <syft.ast.klass.Class object at 0x7ffb10b503a0>\n\t\t.HingeEmbeddingLoss -> <syft.ast.klass.Class object at 0x7ffb10b504c0>\n\t\t.KLDivLoss -> <syft.ast.klass.Class object at 0x7ffb10b505e0>\n\t\t.L1Loss -> <syft.ast.klass.Class object at 0x7ffb10b506a0>\n\t\t.MSELoss -> <syft.ast.klass.Class object at 0x7ffb10b50760>\n\t\t.MarginRankingLoss -> <syft.ast.klass.Class object at 0x7ffb10b50820>\n\t\t.MultiLabelMarginLoss -> <syft.ast.klass.Class object at 0x7ffb10b50940>\n\t\t.MultiLabelSoftMarginLoss -> <syft.ast.klass.Class object at 0x7ffb10b50ac0>\n\t\t.MultiMarginLoss -> <syft.ast.klass.Class object at 0x7ffb10b50be0>\n\t\t.NLLLoss -> <syft.ast.klass.Class object at 0x7ffb10b50d00>\n\t\t.NLLLoss2d -> <syft.ast.klass.Class object at 0x7ffb10b50dc0>\n\t\t.PoissonNLLLoss -> <syft.ast.klass.Class object at 0x7ffb10b50e80>\n\t\t.SmoothL1Loss -> <syft.ast.klass.Class object at 0x7ffb10b50fa0>\n\t\t.SoftMarginLoss -> <syft.ast.klass.Class object at 0x7ffb10b560a0>\n\t\t.TripletMarginLoss -> <syft.ast.klass.Class object at 0x7ffb10b561c0>\n\t\t.AdaptiveAvgPool1d -> <syft.ast.klass.Class object at 0x7ffb10b562e0>\n\t\t.AdaptiveAvgPool2d -> <syft.ast.klass.Class object at 0x7ffb10b56940>\n\t\t.AdaptiveAvgPool3d -> <syft.ast.klass.Class object at 0x7ffb10b56fa0>\n\t\t.AdaptiveMaxPool1d -> <syft.ast.klass.Class object at 0x7ffb10b5b640>\n\t\t.AdaptiveMaxPool2d -> <syft.ast.klass.Class object at 0x7ffb10b5bca0>\n\t\t.AdaptiveMaxPool3d -> <syft.ast.klass.Class object at 0x7ffb10b5c340>\n\t\t.AlphaDropout -> <syft.ast.klass.Class object at 0x7ffb10b5c9a0>\n\t\t.AvgPool1d -> <syft.ast.klass.Class object at 0x7ffb10b5cf40>\n\t\t.AvgPool2d -> <syft.ast.klass.Class object at 0x7ffb10b5f400>\n\t\t.AvgPool3d -> <syft.ast.klass.Class object at 0x7ffb10b5f880>\n\t\t.BatchNorm1d -> <syft.ast.klass.Class object at 0x7ffb10b5fd00>\n\t\t.BatchNorm2d -> <syft.ast.klass.Class object at 0x7ffb10b641c0>\n\t\t.BatchNorm3d -> <syft.ast.klass.Class object at 0x7ffb10b64640>\n\t\t.Bilinear -> <syft.ast.klass.Class object at 0x7ffb10b64ac0>\n\t\t.CELU -> <syft.ast.klass.Class object at 0x7ffb10b64f40>\n\t\t.ConstantPad1d -> <syft.ast.klass.Class object at 0x7ffb10b663a0>\n\t\t.ConstantPad2d -> <syft.ast.klass.Class object at 0x7ffb10b66940>\n\t\t.ConstantPad3d -> <syft.ast.klass.Class object at 0x7ffb10b66ee0>\n\t\t.Container -> <syft.ast.klass.Class object at 0x7ffb10b6a4c0>\n\t\t.Conv1d -> <syft.ast.klass.Class object at 0x7ffb10b6a940>\n\t\t.Conv3d -> <syft.ast.klass.Class object at 0x7ffb10b6ad60>\n\t\t.ConvTranspose1d -> <syft.ast.klass.Class object at 0x7ffb10b701c0>\n\t\t.ConvTranspose2d -> <syft.ast.klass.Class object at 0x7ffb10b707c0>\n\t\t.ConvTranspose3d -> <syft.ast.klass.Class object at 0x7ffb10b70dc0>\n\t\t.CosineSimilarity -> <syft.ast.klass.Class object at 0x7ffb10b73400>\n\t\t.CrossMapLRN2d -> <syft.ast.klass.Class object at 0x7ffb10b73a00>\n\t\t.DataParallel -> <syft.ast.klass.Class object at 0x7ffb10b73fa0>\n\t\t.Dropout -> <syft.ast.klass.Class object at 0x7ffb10b75580>\n\t\t.Dropout3d -> <syft.ast.klass.Class object at 0x7ffb10b75b20>\n\t\t.ELU -> <syft.ast.klass.Class object at 0x7ffb10b75fa0>\n\t\t.Embedding -> <syft.ast.klass.Class object at 0x7ffb10b7a3a0>\n\t\t.EmbeddingBag -> <syft.ast.klass.Class object at 0x7ffb10b7a820>\n\t\t.FeatureAlphaDropout -> <syft.ast.klass.Class object at 0x7ffb10b7adc0>\n\t\t.Flatten -> <syft.ast.klass.Class object at 0x7ffb10b7c520>\n\t\t.Fold -> <syft.ast.klass.Class object at 0x7ffb10b7c9a0>\n\t\t.FractionalMaxPool2d -> <syft.ast.klass.Class object at 0x7ffb10b7cdc0>\n\t\t.FractionalMaxPool3d -> <syft.ast.klass.Class object at 0x7ffb10b81520>\n\t\t.GELU -> <syft.ast.klass.Class object at 0x7ffb10b81c40>\n\t\t.GLU -> <syft.ast.klass.Class object at 0x7ffb10b040a0>\n\t\t.GRU -> <syft.ast.klass.Class object at 0x7ffb10b04460>\n\t\t.GRUCell -> <syft.ast.klass.Class object at 0x7ffb10b04820>\n\t\t.GroupNorm -> <syft.ast.klass.Class object at 0x7ffb10b04ca0>\n\t\t.Hardshrink -> <syft.ast.klass.Class object at 0x7ffb10b09160>\n\t\t.Hardsigmoid -> <syft.ast.klass.Class object at 0x7ffb10b095e0>\n\t\t.Hardswish -> <syft.ast.klass.Class object at 0x7ffb10b099a0>\n\t\t.Hardtanh -> <syft.ast.klass.Class object at 0x7ffb10b09d60>\n\t\t.Identity -> <syft.ast.klass.Class object at 0x7ffb10b0e220>\n\t\t.InstanceNorm1d -> <syft.ast.klass.Class object at 0x7ffb10b0e6a0>\n\t\t.InstanceNorm2d -> <syft.ast.klass.Class object at 0x7ffb10b0eca0>\n\t\t.InstanceNorm3d -> <syft.ast.klass.Class object at 0x7ffb10b112e0>\n\t\t.LPPool1d -> <syft.ast.klass.Class object at 0x7ffb10b118e0>\n\t\t.LPPool2d -> <syft.ast.klass.Class object at 0x7ffb10b11d60>\n\t\t.LSTM -> <syft.ast.klass.Class object at 0x7ffb10b15220>\n\t\t.LSTMCell -> <syft.ast.klass.Class object at 0x7ffb10b15640>\n\t\t.LayerNorm -> <syft.ast.klass.Class object at 0x7ffb10b15ac0>\n\t\t.LeakyReLU -> <syft.ast.klass.Class object at 0x7ffb10b15f40>\n\t\t.LocalResponseNorm -> <syft.ast.klass.Class object at 0x7ffb10b18400>\n\t\t.LogSigmoid -> <syft.ast.klass.Class object at 0x7ffb10b18a60>\n\t\t.LogSoftmax -> <syft.ast.klass.Class object at 0x7ffb10b18ee0>\n\t\t.MaxPool1d -> <syft.ast.klass.Class object at 0x7ffb10b1d3a0>\n\t\t.MaxPool2d -> <syft.ast.klass.Class object at 0x7ffb10b1d820>\n\t\t.MaxPool3d -> <syft.ast.klass.Class object at 0x7ffb10b1dca0>\n\t\t.MaxUnpool1d -> <syft.ast.klass.Class object at 0x7ffb10b21160>\n\t\t.MaxUnpool2d -> <syft.ast.klass.Class object at 0x7ffb10b215e0>\n\t\t.MaxUnpool3d -> <syft.ast.klass.Class object at 0x7ffb10b21a60>\n\t\t.ModuleDict -> <syft.ast.klass.Class object at 0x7ffb10b21ee0>\n\t\t.ModuleList -> <syft.ast.klass.Class object at 0x7ffb10b253a0>\n\t\t.MultiheadAttention -> <syft.ast.klass.Class object at 0x7ffb10b258e0>\n\t\t.PReLU -> <syft.ast.klass.Class object at 0x7ffb10b25fa0>\n\t\t.PairwiseDistance -> <syft.ast.klass.Class object at 0x7ffb10b26400>\n\t\t.PixelShuffle -> <syft.ast.klass.Class object at 0x7ffb10b26a00>\n\t\t.RNN -> <syft.ast.klass.Class object at 0x7ffb10b26fa0>\n\t\t.RNNBase -> <syft.ast.klass.Class object at 0x7ffb10b2b3a0>\n\t\t.RNNCell -> <syft.ast.klass.Class object at 0x7ffb10b2b820>\n\t\t.RNNCellBase -> <syft.ast.klass.Class object at 0x7ffb10b2bca0>\n\t\t.RReLU -> <syft.ast.klass.Class object at 0x7ffb10b32160>\n\t\t.ReLU -> <syft.ast.klass.Class object at 0x7ffb10b32580>\n\t\t.ReLU6 -> <syft.ast.klass.Class object at 0x7ffb10b329a0>\n\t\t.ReflectionPad1d -> <syft.ast.klass.Class object at 0x7ffb10b32dc0>\n\t\t.ReflectionPad2d -> <syft.ast.klass.Class object at 0x7ffb10b34400>\n\t\t.ReplicationPad1d -> <syft.ast.klass.Class object at 0x7ffb10b34a00>\n\t\t.ReplicationPad2d -> <syft.ast.klass.Class object at 0x7ffb10b37040>\n\t\t.ReplicationPad3d -> <syft.ast.klass.Class object at 0x7ffb10b37640>\n\t\t.SELU -> <syft.ast.klass.Class object at 0x7ffb10b37c40>\n\t\t.Sigmoid -> <syft.ast.klass.Class object at 0x7ffb10b3a220>\n\t\t.Softmax -> <syft.ast.klass.Class object at 0x7ffb10b3a6a0>\n\t\t.Softmax2d -> <syft.ast.klass.Class object at 0x7ffb10b3ab20>\n\t\t.Softmin -> <syft.ast.klass.Class object at 0x7ffb10b3afa0>\n\t\t.Softplus -> <syft.ast.klass.Class object at 0x7ffb10b3f460>\n\t\t.Softshrink -> <syft.ast.klass.Class object at 0x7ffb10b3f8e0>\n\t\t.Softsign -> <syft.ast.klass.Class object at 0x7ffb10b3fd60>\n\t\t.SyncBatchNorm -> <syft.ast.klass.Class object at 0x7ffb10b41220>\n\t\t.Tanh -> <syft.ast.klass.Class object at 0x7ffb10b417c0>\n\t\t.Tanhshrink -> <syft.ast.klass.Class object at 0x7ffb10b41be0>\n\t\t.Threshold -> <syft.ast.klass.Class object at 0x7ffb10ac70a0>\n\t\t.Transformer -> <syft.ast.klass.Class object at 0x7ffb10ac7520>\n\t\t.TransformerDecoder -> <syft.ast.klass.Class object at 0x7ffb10ac79a0>\n\t\t.TransformerDecoderLayer -> <syft.ast.klass.Class object at 0x7ffb10aca100>\n\t\t.TransformerEncoder -> <syft.ast.klass.Class object at 0x7ffb10aca760>\n\t\t.TransformerEncoderLayer -> <syft.ast.klass.Class object at 0x7ffb10acae80>\n\t\t.Unfold -> <syft.ast.klass.Class object at 0x7ffb10acd520>\n\t\t.Upsample -> <syft.ast.klass.Class object at 0x7ffb10acd940>\n\t\t.UpsamplingBilinear2d -> <syft.ast.klass.Class object at 0x7ffb10acddc0>\n\t\t.UpsamplingNearest2d -> <syft.ast.klass.Class object at 0x7ffb10ad24c0>\n\t\t.ZeroPad2d -> <syft.ast.klass.Class object at 0x7ffb10ad2be0>\n\n\t.return_types -> Module:\n\t\t.cummax -> <syft.ast.klass.Class object at 0x7ffb10c40880>\n\t\t.cummin -> <syft.ast.klass.Class object at 0x7ffb10c408e0>\n\t\t.eig -> <syft.ast.klass.Class object at 0x7ffb10c40940>\n\t\t.kthvalue -> <syft.ast.klass.Class object at 0x7ffb10c409a0>\n\t\t.lstsq -> <syft.ast.klass.Class object at 0x7ffb10c40a00>\n\t\t.slogdet -> <syft.ast.klass.Class object at 0x7ffb10c40a60>\n\t\t.qr -> <syft.ast.klass.Class object at 0x7ffb10c40ac0>\n\t\t.mode -> <syft.ast.klass.Class object at 0x7ffb10c40b20>\n\t\t.solve -> <syft.ast.klass.Class object at 0x7ffb10c40b80>\n\t\t.sort -> <syft.ast.klass.Class object at 0x7ffb10c40be0>\n\t\t.symeig -> <syft.ast.klass.Class object at 0x7ffb10c40c40>\n\t\t.topk -> <syft.ast.klass.Class object at 0x7ffb10c40ca0>\n\t\t.triangular_solve -> <syft.ast.klass.Class object at 0x7ffb10c40d60>\n\t\t.svd -> <syft.ast.klass.Class object at 0x7ffb10c40dc0>\n\t\t.geqrf -> <syft.ast.klass.Class object at 0x7ffb10c40e20>\n\t\t.median -> <syft.ast.klass.Class object at 0x7ffb10c40e80>\n\t\t.max -> <syft.ast.klass.Class object at 0x7ffb10c40ee0>\n\t\t.min -> <syft.ast.klass.Class object at 0x7ffb10c40f40>\n\n\t.Size -> <syft.ast.klass.Class object at 0x7ffb10b9c040>\n\t.set_grad_enabled -> <syft.ast.klass.Class object at 0x7ffb10b9c340>\n\t.zeros -> <syft.ast.callable.Callable object at 0x7ffb10b9c3a0>\n\t.randn -> <syft.ast.callable.Callable object at 0x7ffb10b9c400>\n\t.ones_like -> <syft.ast.callable.Callable object at 0x7ffb10b9c460>\n\t.arange -> <syft.ast.callable.Callable object at 0x7ffb10b9c580>\n\t.abs_ -> <syft.ast.callable.Callable object at 0x7ffb10b9c5e0>\n\t.abs -> <syft.ast.callable.Callable object at 0x7ffb10b9c640>\n\t.acos_ -> <syft.ast.callable.Callable object at 0x7ffb10b9c6a0>\n\t.acos -> <syft.ast.callable.Callable object at 0x7ffb10b9c700>\n\t.add -> <syft.ast.callable.Callable object at 0x7ffb10b9c760>\n\t.addbmm -> <syft.ast.callable.Callable object at 0x7ffb10b9c7c0>\n\t.addcdiv -> <syft.ast.callable.Callable object at 0x7ffb10b9c820>\n\t.addcmul -> <syft.ast.callable.Callable object at 0x7ffb10b9c880>\n\t.addmm -> <syft.ast.callable.Callable object at 0x7ffb10b9c8e0>\n\t.addmv_ -> <syft.ast.callable.Callable object at 0x7ffb10b9c940>\n\t.addmv -> <syft.ast.callable.Callable object at 0x7ffb10b9c9a0>\n\t.addr -> <syft.ast.callable.Callable object at 0x7ffb10b9ca00>\n\t.all -> <syft.ast.callable.Callable object at 0x7ffb10b9ca60>\n\t.allclose -> <syft.ast.callable.Callable object at 0x7ffb10b9cac0>\n\t.angle -> <syft.ast.callable.Callable object at 0x7ffb10b9cb20>\n\t.any -> <syft.ast.callable.Callable object at 0x7ffb10b9cb80>\n\t.argmax -> <syft.ast.callable.Callable object at 0x7ffb10b9cbe0>\n\t.argmin -> <syft.ast.callable.Callable object at 0x7ffb10b9cc40>\n\t.argsort -> <syft.ast.callable.Callable object at 0x7ffb10b9cca0>\n\t.as_strided_ -> <syft.ast.callable.Callable object at 0x7ffb10b9cd00>\n\t.as_strided -> <syft.ast.callable.Callable object at 0x7ffb10b9cd60>\n\t.asin_ -> <syft.ast.callable.Callable object at 0x7ffb10b9cdc0>\n\t.asin -> <syft.ast.callable.Callable object at 0x7ffb10b9ce20>\n\t.atan_ -> <syft.ast.callable.Callable object at 0x7ffb10b9ce80>\n\t.atan -> <syft.ast.callable.Callable object at 0x7ffb10b9cee0>\n\t.atan2 -> <syft.ast.callable.Callable object at 0x7ffb10b9cf40>\n\t.baddbmm -> <syft.ast.callable.Callable object at 0x7ffb10b9cfa0>\n\t.bernoulli -> <syft.ast.callable.Callable object at 0x7ffb10ba0040>\n\t.bitwise_and -> <syft.ast.callable.Callable object at 0x7ffb10ba00a0>\n\t.bitwise_not -> <syft.ast.callable.Callable object at 0x7ffb10ba0100>\n\t.bitwise_or -> <syft.ast.callable.Callable object at 0x7ffb10ba0160>\n\t.bitwise_xor -> <syft.ast.callable.Callable object at 0x7ffb10ba01c0>\n\t.bmm -> <syft.ast.callable.Callable object at 0x7ffb10ba0220>\n\t.cat -> <syft.ast.callable.Callable object at 0x7ffb10ba0280>\n\t.ceil_ -> <syft.ast.callable.Callable object at 0x7ffb10ba02e0>\n\t.ceil -> <syft.ast.callable.Callable object at 0x7ffb10ba0340>\n\t.cholesky_inverse -> <syft.ast.callable.Callable object at 0x7ffb10ba03a0>\n\t.cholesky_solve -> <syft.ast.callable.Callable object at 0x7ffb10ba0400>\n\t.cholesky -> <syft.ast.callable.Callable object at 0x7ffb10ba0460>\n\t.chunk -> <syft.ast.callable.Callable object at 0x7ffb10ba04c0>\n\t.clamp_ -> <syft.ast.callable.Callable object at 0x7ffb10ba0520>\n\t.clamp_max_ -> <syft.ast.callable.Callable object at 0x7ffb10ba0580>\n\t.clamp_max -> <syft.ast.callable.Callable object at 0x7ffb10ba05e0>\n\t.clamp_min_ -> <syft.ast.callable.Callable object at 0x7ffb10ba0640>\n\t.clamp_min -> <syft.ast.callable.Callable object at 0x7ffb10ba06a0>\n\t.clamp -> <syft.ast.callable.Callable object at 0x7ffb10ba0700>\n\t.clone -> <syft.ast.callable.Callable object at 0x7ffb10ba0760>\n\t.conj -> <syft.ast.callable.Callable object at 0x7ffb10ba07c0>\n\t.cos_ -> <syft.ast.callable.Callable object at 0x7ffb10ba0820>\n\t.cos -> <syft.ast.callable.Callable object at 0x7ffb10ba0880>\n\t.cosh_ -> <syft.ast.callable.Callable object at 0x7ffb10ba08e0>\n\t.cosh -> <syft.ast.callable.Callable object at 0x7ffb10ba0940>\n\t.cross -> <syft.ast.callable.Callable object at 0x7ffb10ba09a0>\n\t.cummax -> <syft.ast.callable.Callable object at 0x7ffb10ba0a00>\n\t.cummin -> <syft.ast.callable.Callable object at 0x7ffb10ba0a60>\n\t.cumprod -> <syft.ast.callable.Callable object at 0x7ffb10ba0ac0>\n\t.cumsum -> <syft.ast.callable.Callable object at 0x7ffb10ba0b20>\n\t.dequantize -> <syft.ast.callable.Callable object at 0x7ffb10ba0b80>\n\t.det -> <syft.ast.callable.Callable object at 0x7ffb10ba0be0>\n\t.detach -> <syft.ast.callable.Callable object at 0x7ffb10ba0c40>\n\t.diag_embed -> <syft.ast.callable.Callable object at 0x7ffb10ba0ca0>\n\t.diag -> <syft.ast.callable.Callable object at 0x7ffb10ba0d00>\n\t.diagflat -> <syft.ast.callable.Callable object at 0x7ffb10ba0d60>\n\t.diagonal -> <syft.ast.callable.Callable object at 0x7ffb10ba0dc0>\n\t.digamma -> <syft.ast.callable.Callable object at 0x7ffb10ba0e20>\n\t.dist -> <syft.ast.callable.Callable object at 0x7ffb10ba0e80>\n\t.div -> <syft.ast.callable.Callable object at 0x7ffb10ba0ee0>\n\t.dot -> <syft.ast.callable.Callable object at 0x7ffb10ba0f40>\n\t.eig -> <syft.ast.callable.Callable object at 0x7ffb10ba0fa0>\n\t.eq -> <syft.ast.callable.Callable object at 0x7ffb10ba4040>\n\t.equal -> <syft.ast.callable.Callable object at 0x7ffb10ba40a0>\n\t.erf_ -> <syft.ast.callable.Callable object at 0x7ffb10ba4100>\n\t.erf -> <syft.ast.callable.Callable object at 0x7ffb10ba4160>\n\t.erfc_ -> <syft.ast.callable.Callable object at 0x7ffb10ba41c0>\n\t.erfc -> <syft.ast.callable.Callable object at 0x7ffb10ba4220>\n\t.erfinv -> <syft.ast.callable.Callable object at 0x7ffb10ba4280>\n\t.exp_ -> <syft.ast.callable.Callable object at 0x7ffb10ba42e0>\n\t.exp -> <syft.ast.callable.Callable object at 0x7ffb10ba4340>\n\t.expm1_ -> <syft.ast.callable.Callable object at 0x7ffb10ba43a0>\n\t.expm1 -> <syft.ast.callable.Callable object at 0x7ffb10ba4400>\n\t.fft -> Module:\n\n\t.fill_ -> <syft.ast.callable.Callable object at 0x7ffb10ba44c0>\n\t.flatten -> <syft.ast.callable.Callable object at 0x7ffb10ba4520>\n\t.flip -> <syft.ast.callable.Callable object at 0x7ffb10ba4580>\n\t.floor_ -> <syft.ast.callable.Callable object at 0x7ffb10ba45e0>\n\t.floor_divide -> <syft.ast.callable.Callable object at 0x7ffb10ba4640>\n\t.floor -> <syft.ast.callable.Callable object at 0x7ffb10ba46a0>\n\t.fmod -> <syft.ast.callable.Callable object at 0x7ffb10ba4700>\n\t.frac_ -> <syft.ast.callable.Callable object at 0x7ffb10ba4760>\n\t.frac -> <syft.ast.callable.Callable object at 0x7ffb10ba47c0>\n\t.from_numpy -> <syft.ast.callable.Callable object at 0x7ffb10ba4820>\n\t.gather -> <syft.ast.callable.Callable object at 0x7ffb10ba4880>\n\t.ge -> <syft.ast.callable.Callable object at 0x7ffb10ba48e0>\n\t.geqrf -> <syft.ast.callable.Callable object at 0x7ffb10ba4940>\n\t.ger -> <syft.ast.callable.Callable object at 0x7ffb10ba49a0>\n\t.get_device -> <syft.ast.callable.Callable object at 0x7ffb10ba4a00>\n\t.gt -> <syft.ast.callable.Callable object at 0x7ffb10ba4a60>\n\t.hardshrink -> <syft.ast.callable.Callable object at 0x7ffb10ba4ac0>\n\t.histc -> <syft.ast.callable.Callable object at 0x7ffb10ba4b20>\n\t.index_add -> <syft.ast.callable.Callable object at 0x7ffb10ba4b80>\n\t.index_copy -> <syft.ast.callable.Callable object at 0x7ffb10ba4be0>\n\t.index_fill -> <syft.ast.callable.Callable object at 0x7ffb10ba4c40>\n\t.index_put_ -> <syft.ast.callable.Callable object at 0x7ffb10ba4ca0>\n\t.index_put -> <syft.ast.callable.Callable object at 0x7ffb10ba4d00>\n\t.index_select -> <syft.ast.callable.Callable object at 0x7ffb10ba4d60>\n\t.int_repr -> <syft.ast.callable.Callable object at 0x7ffb10ba4dc0>\n\t.inverse -> <syft.ast.callable.Callable object at 0x7ffb10ba4e20>\n\t.is_complex -> <syft.ast.callable.Callable object at 0x7ffb10ba4e80>\n\t.is_distributed -> <syft.ast.callable.Callable object at 0x7ffb10ba4ee0>\n\t.is_floating_point -> <syft.ast.callable.Callable object at 0x7ffb10ba4f40>\n\t.is_nonzero -> <syft.ast.callable.Callable object at 0x7ffb10ba4fa0>\n\t.is_same_size -> <syft.ast.callable.Callable object at 0x7ffb10ba9040>\n\t.is_signed -> <syft.ast.callable.Callable object at 0x7ffb10ba90a0>\n\t.isclose -> <syft.ast.callable.Callable object at 0x7ffb10ba9100>\n\t.kthvalue -> <syft.ast.callable.Callable object at 0x7ffb10ba9160>\n\t.le -> <syft.ast.callable.Callable object at 0x7ffb10ba91c0>\n\t.lerp -> <syft.ast.callable.Callable object at 0x7ffb10ba9220>\n\t.lgamma -> <syft.ast.callable.Callable object at 0x7ffb10ba9280>\n\t.log_ -> <syft.ast.callable.Callable object at 0x7ffb10ba92e0>\n\t.log_softmax -> <syft.ast.callable.Callable object at 0x7ffb10ba9340>\n\t.log -> <syft.ast.callable.Callable object at 0x7ffb10ba93a0>\n\t.log10_ -> <syft.ast.callable.Callable object at 0x7ffb10ba9400>\n\t.log10 -> <syft.ast.callable.Callable object at 0x7ffb10ba9460>\n\t.log1p_ -> <syft.ast.callable.Callable object at 0x7ffb10ba94c0>\n\t.log1p -> <syft.ast.callable.Callable object at 0x7ffb10ba9520>\n\t.log2_ -> <syft.ast.callable.Callable object at 0x7ffb10ba9580>\n\t.log2 -> <syft.ast.callable.Callable object at 0x7ffb10ba95e0>\n\t.logdet -> <syft.ast.callable.Callable object at 0x7ffb10ba9640>\n\t.logical_and -> <syft.ast.callable.Callable object at 0x7ffb10ba96a0>\n\t.logical_not -> <syft.ast.callable.Callable object at 0x7ffb10ba9700>\n\t.logical_or -> <syft.ast.callable.Callable object at 0x7ffb10ba9760>\n\t.logical_xor -> <syft.ast.callable.Callable object at 0x7ffb10ba97c0>\n\t.logsumexp -> <syft.ast.callable.Callable object at 0x7ffb10ba9820>\n\t.lstsq -> <syft.ast.callable.Callable object at 0x7ffb10ba9880>\n\t.lt -> <syft.ast.callable.Callable object at 0x7ffb10ba98e0>\n\t.lu_solve -> <syft.ast.callable.Callable object at 0x7ffb10ba9940>\n\t.lu -> <syft.ast.callable.Callable object at 0x7ffb10ba99a0>\n\t.masked_fill -> <syft.ast.callable.Callable object at 0x7ffb10ba9a00>\n\t.masked_scatter -> <syft.ast.callable.Callable object at 0x7ffb10ba9a60>\n\t.masked_select -> <syft.ast.callable.Callable object at 0x7ffb10ba9ac0>\n\t.matmul -> <syft.ast.callable.Callable object at 0x7ffb10ba9b20>\n\t.matrix_power -> <syft.ast.callable.Callable object at 0x7ffb10ba9b80>\n\t.mean -> <syft.ast.callable.Callable object at 0x7ffb10ba9be0>\n\t.mm -> <syft.ast.callable.Callable object at 0x7ffb10ba9c40>\n\t.mode -> <syft.ast.callable.Callable object at 0x7ffb10ba9ca0>\n\t.mul -> <syft.ast.callable.Callable object at 0x7ffb10ba9d00>\n\t.multinomial -> <syft.ast.callable.Callable object at 0x7ffb10ba9d60>\n\t.mv -> <syft.ast.callable.Callable object at 0x7ffb10ba9dc0>\n\t.mvlgamma -> <syft.ast.callable.Callable object at 0x7ffb10ba9e20>\n\t.narrow -> <syft.ast.callable.Callable object at 0x7ffb10ba9e80>\n\t.ne -> <syft.ast.callable.Callable object at 0x7ffb10ba9ee0>\n\t.neg_ -> <syft.ast.callable.Callable object at 0x7ffb10ba9f40>\n\t.neg -> <syft.ast.callable.Callable object at 0x7ffb10ba9fa0>\n\t.nonzero -> <syft.ast.callable.Callable object at 0x7ffb10bad040>\n\t.norm -> <syft.ast.callable.Callable object at 0x7ffb10bad0a0>\n\t.orgqr -> <syft.ast.callable.Callable object at 0x7ffb10bad100>\n\t.ormqr -> <syft.ast.callable.Callable object at 0x7ffb10bad160>\n\t.pinverse -> <syft.ast.callable.Callable object at 0x7ffb10bad1c0>\n\t.polygamma -> <syft.ast.callable.Callable object at 0x7ffb10bad220>\n\t.pow -> <syft.ast.callable.Callable object at 0x7ffb10bad280>\n\t.prelu -> <syft.ast.callable.Callable object at 0x7ffb10bad2e0>\n\t.q_per_channel_axis -> <syft.ast.callable.Callable object at 0x7ffb10bad340>\n\t.q_per_channel_scales -> <syft.ast.callable.Callable object at 0x7ffb10bad3a0>\n\t.q_per_channel_zero_points -> <syft.ast.callable.Callable object at 0x7ffb10bad400>\n\t.q_scale -> <syft.ast.callable.Callable object at 0x7ffb10bad460>\n\t.q_zero_point -> <syft.ast.callable.Callable object at 0x7ffb10bad4c0>\n\t.qr -> <syft.ast.callable.Callable object at 0x7ffb10bad520>\n\t.reciprocal_ -> <syft.ast.callable.Callable object at 0x7ffb10bad580>\n\t.reciprocal -> <syft.ast.callable.Callable object at 0x7ffb10bad5e0>\n\t.relu_ -> <syft.ast.callable.Callable object at 0x7ffb10bad640>\n\t.relu -> <syft.ast.callable.Callable object at 0x7ffb10bad6a0>\n\t.remainder -> <syft.ast.callable.Callable object at 0x7ffb10bad700>\n\t.renorm -> <syft.ast.callable.Callable object at 0x7ffb10bad760>\n\t.repeat_interleave -> <syft.ast.callable.Callable object at 0x7ffb10bad7c0>\n\t.reshape -> <syft.ast.callable.Callable object at 0x7ffb10bad820>\n\t.resize_as_ -> <syft.ast.callable.Callable object at 0x7ffb10bad880>\n\t.roll -> <syft.ast.callable.Callable object at 0x7ffb10bad8e0>\n\t.rot90 -> <syft.ast.callable.Callable object at 0x7ffb10bad940>\n\t.round_ -> <syft.ast.callable.Callable object at 0x7ffb10bad9a0>\n\t.round -> <syft.ast.callable.Callable object at 0x7ffb10bada00>\n\t.rsqrt_ -> <syft.ast.callable.Callable object at 0x7ffb10bada60>\n\t.rsqrt -> <syft.ast.callable.Callable object at 0x7ffb10badac0>\n\t.scatter_add -> <syft.ast.callable.Callable object at 0x7ffb10badb20>\n\t.scatter -> <syft.ast.callable.Callable object at 0x7ffb10badb80>\n\t.select -> <syft.ast.callable.Callable object at 0x7ffb10badbe0>\n\t.sigmoid_ -> <syft.ast.callable.Callable object at 0x7ffb10badc40>\n\t.sigmoid -> <syft.ast.callable.Callable object at 0x7ffb10badca0>\n\t.sign -> <syft.ast.callable.Callable object at 0x7ffb10badd00>\n\t.sin_ -> <syft.ast.callable.Callable object at 0x7ffb10badd60>\n\t.sin -> <syft.ast.callable.Callable object at 0x7ffb10baddc0>\n\t.sinh_ -> <syft.ast.callable.Callable object at 0x7ffb10bade20>\n\t.sinh -> <syft.ast.callable.Callable object at 0x7ffb10bade80>\n\t.slogdet -> <syft.ast.callable.Callable object at 0x7ffb10badee0>\n\t.softmax -> <syft.ast.callable.Callable object at 0x7ffb10badf40>\n\t.solve -> <syft.ast.callable.Callable object at 0x7ffb10badfa0>\n\t.sort -> <syft.ast.callable.Callable object at 0x7ffb10bb1040>\n\t.split_with_sizes -> <syft.ast.callable.Callable object at 0x7ffb10bb10a0>\n\t.split -> <syft.ast.callable.Callable object at 0x7ffb10bb1100>\n\t.sqrt_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1160>\n\t.sqrt -> <syft.ast.callable.Callable object at 0x7ffb10bb11c0>\n\t.square_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1220>\n\t.square -> <syft.ast.callable.Callable object at 0x7ffb10bb1280>\n\t.squeeze -> <syft.ast.callable.Callable object at 0x7ffb10bb12e0>\n\t.stack -> <syft.ast.callable.Callable object at 0x7ffb10bb1340>\n\t.std -> <syft.ast.callable.Callable object at 0x7ffb10bb13a0>\n\t.stft -> <syft.ast.callable.Callable object at 0x7ffb10bb1400>\n\t.sub -> <syft.ast.callable.Callable object at 0x7ffb10bb1460>\n\t.sum -> <syft.ast.callable.Callable object at 0x7ffb10bb14c0>\n\t.svd -> <syft.ast.callable.Callable object at 0x7ffb10bb1520>\n\t.symeig -> <syft.ast.callable.Callable object at 0x7ffb10bb1580>\n\t.t -> <syft.ast.callable.Callable object at 0x7ffb10bb15e0>\n\t.take -> <syft.ast.callable.Callable object at 0x7ffb10bb1640>\n\t.tan_ -> <syft.ast.callable.Callable object at 0x7ffb10bb16a0>\n\t.tan -> <syft.ast.callable.Callable object at 0x7ffb10bb1700>\n\t.tanh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1760>\n\t.tanh -> <syft.ast.callable.Callable object at 0x7ffb10bb17c0>\n\t.topk -> <syft.ast.callable.Callable object at 0x7ffb10bb1820>\n\t.trace -> <syft.ast.callable.Callable object at 0x7ffb10bb1880>\n\t.transpose -> <syft.ast.callable.Callable object at 0x7ffb10bb18e0>\n\t.triangular_solve -> <syft.ast.callable.Callable object at 0x7ffb10bb1940>\n\t.tril -> <syft.ast.callable.Callable object at 0x7ffb10bb19a0>\n\t.triu -> <syft.ast.callable.Callable object at 0x7ffb10bb1a00>\n\t.true_divide -> <syft.ast.callable.Callable object at 0x7ffb10bb1a60>\n\t.trunc_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1ac0>\n\t.trunc -> <syft.ast.callable.Callable object at 0x7ffb10bb1b20>\n\t.unique_consecutive -> <syft.ast.callable.Callable object at 0x7ffb10bb1b80>\n\t.unique -> <syft.ast.callable.Callable object at 0x7ffb10bb1be0>\n\t.unsqueeze -> <syft.ast.callable.Callable object at 0x7ffb10bb1c40>\n\t.var -> <syft.ast.callable.Callable object at 0x7ffb10bb1ca0>\n\t.unsafe_chunk -> <syft.ast.callable.Callable object at 0x7ffb10bb1d00>\n\t.absolute -> <syft.ast.callable.Callable object at 0x7ffb10bb1d60>\n\t.acosh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1dc0>\n\t.acosh -> <syft.ast.callable.Callable object at 0x7ffb10bb1e20>\n\t.asinh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1e80>\n\t.asinh -> <syft.ast.callable.Callable object at 0x7ffb10bb1ee0>\n\t.atanh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb1f40>\n\t.atanh -> <syft.ast.callable.Callable object at 0x7ffb10bb1fa0>\n\t.deg2rad_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5040>\n\t.deg2rad -> <syft.ast.callable.Callable object at 0x7ffb10bb50a0>\n\t.fliplr -> <syft.ast.callable.Callable object at 0x7ffb10bb5100>\n\t.flipud -> <syft.ast.callable.Callable object at 0x7ffb10bb5160>\n\t.isfinite -> <syft.ast.callable.Callable object at 0x7ffb10bb51c0>\n\t.isinf -> <syft.ast.callable.Callable object at 0x7ffb10bb5220>\n\t.isnan -> <syft.ast.callable.Callable object at 0x7ffb10bb5280>\n\t.logaddexp -> <syft.ast.callable.Callable object at 0x7ffb10bb52e0>\n\t.logaddexp2 -> <syft.ast.callable.Callable object at 0x7ffb10bb5340>\n\t.logcumsumexp -> <syft.ast.callable.Callable object at 0x7ffb10bb53a0>\n\t.rad2deg_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5400>\n\t.rad2deg -> <syft.ast.callable.Callable object at 0x7ffb10bb5460>\n\t.istft -> <syft.ast.callable.Callable object at 0x7ffb10bb54c0>\n\t.amax -> <syft.ast.callable.Callable object at 0x7ffb10bb5520>\n\t.amin -> <syft.ast.callable.Callable object at 0x7ffb10bb5580>\n\t.arccos -> <syft.ast.callable.Callable object at 0x7ffb10bb55e0>\n\t.arccos_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5640>\n\t.arccosh -> <syft.ast.callable.Callable object at 0x7ffb10bb56a0>\n\t.arccosh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5700>\n\t.arcsin -> <syft.ast.callable.Callable object at 0x7ffb10bb5760>\n\t.arcsin_ -> <syft.ast.callable.Callable object at 0x7ffb10bb57c0>\n\t.arcsinh -> <syft.ast.callable.Callable object at 0x7ffb10bb5820>\n\t.arcsinh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5880>\n\t.arctan -> <syft.ast.callable.Callable object at 0x7ffb10bb58e0>\n\t.arctan_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5940>\n\t.arctanh -> <syft.ast.callable.Callable object at 0x7ffb10bb59a0>\n\t.arctanh_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5a00>\n\t.clip -> <syft.ast.callable.Callable object at 0x7ffb10bb5a60>\n\t.clip_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5ac0>\n\t.count_nonzero -> <syft.ast.callable.Callable object at 0x7ffb10bb5b20>\n\t.divide -> <syft.ast.callable.Callable object at 0x7ffb10bb5b80>\n\t.exp2 -> <syft.ast.callable.Callable object at 0x7ffb10bb5be0>\n\t.exp2_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5c40>\n\t.fix -> <syft.ast.callable.Callable object at 0x7ffb10bb5ca0>\n\t.fix_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5d00>\n\t.gcd -> <syft.ast.callable.Callable object at 0x7ffb10bb5d60>\n\t.gcd_ -> <syft.ast.callable.Callable object at 0x7ffb10bb5dc0>\n\t.greater -> <syft.ast.callable.Callable object at 0x7ffb10bb5e20>\n\t.greater_equal -> <syft.ast.callable.Callable object at 0x7ffb10bb5e80>\n\t.heaviside -> <syft.ast.callable.Callable object at 0x7ffb10bb5ee0>\n\t.hypot -> <syft.ast.callable.Callable object at 0x7ffb10bb5f40>\n\t.i0 -> <syft.ast.callable.Callable object at 0x7ffb10bb5fa0>\n\t.i0_ -> <syft.ast.callable.Callable object at 0x7ffb10bba040>\n\t.isneginf -> <syft.ast.callable.Callable object at 0x7ffb10bba0a0>\n\t.isposinf -> <syft.ast.callable.Callable object at 0x7ffb10bba100>\n\t.isreal -> <syft.ast.callable.Callable object at 0x7ffb10bba160>\n\t.lcm -> <syft.ast.callable.Callable object at 0x7ffb10bba1c0>\n\t.lcm_ -> <syft.ast.callable.Callable object at 0x7ffb10bba220>\n\t.less -> <syft.ast.callable.Callable object at 0x7ffb10bba280>\n\t.less_equal -> <syft.ast.callable.Callable object at 0x7ffb10bba2e0>\n\t.logit -> <syft.ast.callable.Callable object at 0x7ffb10bba340>\n\t.logit_ -> <syft.ast.callable.Callable object at 0x7ffb10bba3a0>\n\t.maximum -> <syft.ast.callable.Callable object at 0x7ffb10bba400>\n\t.minimum -> <syft.ast.callable.Callable object at 0x7ffb10bba460>\n\t.matrix_exp -> <syft.ast.callable.Callable object at 0x7ffb10bba4c0>\n\t.multiply -> <syft.ast.callable.Callable object at 0x7ffb10bba520>\n\t.nanquantile -> <syft.ast.callable.Callable object at 0x7ffb10bba580>\n\t.nansum -> <syft.ast.callable.Callable object at 0x7ffb10bba5e0>\n\t.negative -> <syft.ast.callable.Callable object at 0x7ffb10bba640>\n\t.negative_ -> <syft.ast.callable.Callable object at 0x7ffb10bba6a0>\n\t.nextafter -> <syft.ast.callable.Callable object at 0x7ffb10bba700>\n\t.outer -> <syft.ast.callable.Callable object at 0x7ffb10bba760>\n\t.quantile -> <syft.ast.callable.Callable object at 0x7ffb10bba7c0>\n\t.sgn -> <syft.ast.callable.Callable object at 0x7ffb10bba820>\n\t.signbit -> <syft.ast.callable.Callable object at 0x7ffb10bba880>\n\t.subtract -> <syft.ast.callable.Callable object at 0x7ffb10bba8e0>\n\t.unsafe_split -> <syft.ast.callable.Callable object at 0x7ffb10bba940>\n\t.vdot -> <syft.ast.callable.Callable object at 0x7ffb10bba9a0>\n\t.movedim -> <syft.ast.callable.Callable object at 0x7ffb10bbaa00>\n\t.unsafe_split_with_sizes -> <syft.ast.callable.Callable object at 0x7ffb10bbaa60>\n\t.cuda -> Module:\n\t\t.is_available -> <syft.ast.callable.Callable object at 0x7ffb10bbab20>\n\n\t.device -> <syft.ast.klass.Class object at 0x7ffb10bbab80>\n\t.random -> Module:\n\t\t.initial_seed -> <syft.ast.callable.Callable object at 0x7ffb10bbad00>\n\n\t.zeros_like -> <syft.ast.callable.Callable object at 0x7ffb10bbad60>\n\t.manual_seed -> <syft.ast.callable.Callable object at 0x7ffb10bbadc0>\n\t.Generator -> <syft.ast.klass.Class object at 0x7ffb10bbae20>\n\t.utils -> Module:\n\t\t.data -> Module:\n\t\t\t.DataLoader -> <syft.ast.klass.Class object at 0x7ffb10b44160>\n\t\t\t.dataloader -> Module:\n\t\t\t\t._SingleProcessDataLoaderIter -> <syft.ast.klass.Class object at 0x7ffb10b443a0>\n\n\n\n\t.optim -> Module:\n\t\t.ASGD -> <syft.ast.klass.Class object at 0x7ffb10b44760>\n\t\t.Adadelta -> <syft.ast.klass.Class object at 0x7ffb10b448e0>\n\t\t.Adagrad -> <syft.ast.klass.Class object at 0x7ffb10b44a60>\n\t\t.Adam -> <syft.ast.klass.Class object at 0x7ffb10b44be0>\n\t\t.AdamW -> <syft.ast.klass.Class object at 0x7ffb10b44d60>\n\t\t.Adamax -> <syft.ast.klass.Class object at 0x7ffb10b44ee0>\n\t\t.LBFGS -> <syft.ast.klass.Class object at 0x7ffb10b490a0>\n\t\t.Optimizer -> <syft.ast.klass.Class object at 0x7ffb10b49220>\n\t\t.RMSprop -> <syft.ast.klass.Class object at 0x7ffb10b49400>\n\t\t.Rprop -> <syft.ast.klass.Class object at 0x7ffb10b49580>\n\t\t.SGD -> <syft.ast.klass.Class object at 0x7ffb10b49700>\n\t\t.SparseAdam -> <syft.ast.klass.Class object at 0x7ffb10b49880>\n\t\t.lr_scheduler -> Module:\n\t\t\t.StepLR -> <syft.ast.klass.Class object at 0x7ffb10b49b20>\n\n\n\t.no_grad -> <syft.ast.klass.Class object at 0x7ffb10b49d00>\n\t.autograd -> Module:\n\t\t.grad_mode -> Module:\n\t\t\t.no_grad -> <syft.ast.klass.Class object at 0x7ffb10b49e80>\n\n\n\t.distributions -> Module:\n\t\t.Categorical -> <syft.ast.klass.Class object at 0x7ffb10ad4100>\n\n\t.kron -> <syft.ast.callable.Callable object at 0x7ffb10ad46a0>\n\t.msort -> <syft.ast.callable.Callable object at 0x7ffb10ad47c0>\n\t.row_stack -> <syft.ast.callable.Callable object at 0x7ffb10ad4820>\n\t.moveaxis -> <syft.ast.callable.Callable object at 0x7ffb10ad4b20>\n\t.tensor_split -> <syft.ast.callable.Callable object at 0x7ffb10ad4c40>\n\t.tile -> <syft.ast.callable.Callable object at 0x7ffb10ad4d60>\n\t.fmin -> <syft.ast.callable.Callable object at 0x7ffb10ad4f40>\n\t.ldexp -> <syft.ast.callable.Callable object at 0x7ffb10ad4fa0>\n\t.igamma -> <syft.ast.callable.Callable object at 0x7ffb10ad8100>\n\t.float_power -> <syft.ast.callable.Callable object at 0x7ffb10ad85e0>\n\t.xlogy -> <syft.ast.callable.Callable object at 0x7ffb10ad8700>\n\t.copysign -> <syft.ast.callable.Callable object at 0x7ffb10ad8760>\n\t.nanmedian -> <syft.ast.callable.Callable object at 0x7ffb10ad87c0>\n\t.igammac -> <syft.ast.callable.Callable object at 0x7ffb10ad8820>\n\t.diff -> <syft.ast.callable.Callable object at 0x7ffb10ad8940>\n\t.sinc -> <syft.ast.callable.Callable object at 0x7ffb10ad8a60>\n\t.column_stack -> <syft.ast.callable.Callable object at 0x7ffb10ad8c40>\n\t.pixel_unshuffle -> <syft.ast.callable.Callable object at 0x7ffb10ad8d60>\n\t.swapaxes -> <syft.ast.callable.Callable object at 0x7ffb10add040>\n\t.nan_to_num -> <syft.ast.callable.Callable object at 0x7ffb10add0a0>\n\t.inner -> <syft.ast.callable.Callable object at 0x7ffb10add100>\n\t.fmax -> <syft.ast.callable.Callable object at 0x7ffb10add160>\n\t.ravel -> <syft.ast.callable.Callable object at 0x7ffb10add4c0>\n\t.broadcast_to -> <syft.ast.callable.Callable object at 0x7ffb10add520>\n\t.swapdims -> <syft.ast.callable.Callable object at 0x7ffb10add700>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467719078
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Client: preparing the dataset (only for training now)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class ECG(Dataset):\n",
        "    # The class used to load the ECG dataset\n",
        "    def __init__(self, mode='train'):\n",
        "        if mode == 'train':\n",
        "            with h5py.File(project_path/data_dir/train_name, 'r') as hdf:\n",
        "                if dry_run:\n",
        "                    self.x = torch.tensor(hdf['x_train'][:50], dtype=torch.float)\n",
        "                    self._y = torch.tensor(hdf['y_train'][:50])\n",
        "                else:\n",
        "                    self.x = torch.tensor(hdf['x_train'][:], dtype=torch.float)\n",
        "                    self._y = torch.tensor(hdf['y_train'][:])\n",
        "        elif mode == 'test':\n",
        "            with h5py.File(project_path/data_dir/test_name, 'r') as hdf:\n",
        "                if dry_run:\n",
        "                    self.x = torch.tensor(hdf['x_test'][:], dtype=torch.float)\n",
        "                    self._y = torch.tensor(hdf['y_test'][:50])\n",
        "                else:\n",
        "                    self.x = torch.tensor(hdf['x_test'][:50], dtype=torch.float)\n",
        "                    self._y = torch.tensor(hdf['y_test'][:])\n",
        "        else:\n",
        "            raise ValueError('Argument of mode should be train or test')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx]  # only returns the input data this time\n",
        "    \n",
        "    def encrypt_y(self, context: Context):\n",
        "        encrypted_y: List[CKKSVector] = [ts.ckks_vector(context, [y.tolist()]) for y in self._y]\n",
        "        return encrypted_y\n",
        "\n",
        "train_dataset = ECG(mode='train')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467719365
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a tenseal context to encrypt the ground-truth output"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "poly_mod_degree = 4096\n",
        "coeff_mod_bit_sizes = [40, 20, 40]\n",
        "# create TenSEALContext\n",
        "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "# scale of ciphertext to use\n",
        "context.global_scale = 2 ** 20\n",
        "# this key is needed for doing dot-product operations\n",
        "context.generate_galois_keys()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1632467719808
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train_y: List = train_dataset.encrypt_y(context)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1632467720231
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The client creates the Dataset object and save it in a `.pt` file. If using `duet`, he can send the string path to the server using `sy.lib.python.String(string_path).send(duet, pointable=True, tags=[\"data\"])`. From the `.pt` file, the server can point to the dataset, but he needs to ask for permissions if he wants to access the data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(train_dataset, \"train_dataset.pt\")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1632467720600
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: creating the remote dataset and dataloader for the train dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_rds = RemoteDataset(path='train_dataset.pt', data_type=\"torch_tensor\")\n",
        "train_rds"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "<class 'syft.core.remote_dataloader.remote_dataloader.RemoteDataset'>: torch_tensor"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467721104
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the remote dataset, the server constructs the data loader. Then the server uses `.send`\n",
        "to create a pointer to do remote data loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to use batch_size 1 (for now) because of training on encrypted data\n",
        "train_rdl = RemoteDataLoader(remote_dataset=train_rds, batch_size=1)\n",
        "train_rdl_ptr = train_rdl.send(client)\n",
        "ic(train_rdl, train_rdl_ptr)\n",
        "# call create_dataset to create the real Dataset object on remote side\n",
        "train_rdl_ptr.load_dataset()\n",
        "# call create_dataloader to create the real DataLoader object on remote side\n",
        "train_rdl_ptr.create_dataloader()\n",
        "ic(len(train_rdl_ptr))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| train_rdl: <syft.core.remote_dataloader.remote_dataloader.RemoteDataLoader object at 0x7ffbce730d90>\n    train_rdl_ptr: <syft.proxy.syft.core.remote_dataloader.RemoteDataLoaderPointer object at 0x7ffb10963430>\nic| len(train_rdl_ptr): 50\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "50"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467721598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's play with the remote dataloader and tenseal encrypted vectors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "# create TenSEALContext\n",
        "context2 = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "context2.global_scale = 2 ** 21\n",
        "context2.generate_galois_keys()"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1632467722246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, b in enumerate(zip(train_rdl_ptr, enc_train_y)):\n",
        "    if i<2:\n",
        "        x, enc_y = b[0], b[1]\n",
        "        ic(x, x.get_copy().shape, enc_y, enc_y.decrypt(secret_key=context.secret_key()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| x: <syft.proxy.syft.lib.misc.union.FloatIntStringTensorParameterUnionPointer object at 0x7ffbce730130>\n    x.get_copy().shape: torch.Size([1, 1, 128])\n    enc_y: <tenseal.tensors.ckksvector.CKKSVector object at 0x7ffb109655e0>\n    enc_y.decrypt(secret_key=context.secret_key()): [2.0012173519956242]\nic| x: <syft.proxy.syft.lib.misc.union.FloatIntStringTensorParameterUnionPointer object at 0x7ffb11f16e80>\n    x.get_copy().shape: torch.Size([1, 1, 128])\n    enc_y: <tenseal.tensors.ckksvector.CKKSVector object at 0x7ffb10965ee0>\n    enc_y.decrypt(secret_key=context.secret_key()): [3.999889134066677]\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1632467722731
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we decrypt with a wrong context key?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for i, b in enumerate(zip(train_rdl_ptr, enc_train_y)):\n",
        "    if i<2:\n",
        "        x, enc_y = b[0], b[1]\n",
        "        try:\n",
        "            ic(x, \n",
        "                x.get_copy().shape, \n",
        "                enc_y, \n",
        "                enc_y.decrypt(secret_key=context2.secret_key()))\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "secret key is not valid for encryption parameters\nsecret key is not valid for encryption parameters\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1632467772264
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: define the spit neural network used to train on the ECG dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Client's side contains conv layers, trained on plaintext input data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EcgClient(sy.Module):\n",
        "    # will be sent to the client\n",
        "    def __init__(self, torch_ref, context: Context):\n",
        "        super(EcgClient, self).__init__(torch_ref=torch_ref)\n",
        "        self.conv1 = self.torch_ref.nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
        "        self.relu1 = self.torch_ref.nn.LeakyReLU()\n",
        "        self.pool1 = self.torch_ref.nn.MaxPool1d(2)  # 64 x 16\n",
        "        self.conv2 = self.torch_ref.nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
        "        self.relu2 = self.torch_ref.nn.LeakyReLU()\n",
        "        self.pool2 = self.torch_ref.nn.MaxPool1d(2)  # 32 x 16\n",
        "        \n",
        "        self.load_init_weights()\n",
        "        self.context = context\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 32 * 16)\n",
        "        # x is a syft's TensorPointer. x.get() returns torch.Tensor of size [1, 512]\n",
        "        enc_x = self.encrypt_activations(x.get())  # enc_x is a list of 512 elements\n",
        "        return enc_x\n",
        "    \n",
        "    def load_init_weights(self):\n",
        "        checkpoint = torch.load(\"init_weight.pth\")\n",
        "        self.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
        "        self.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
        "        self.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
        "        self.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
        "    \n",
        "    def encrypt_activations(self, x: torch.Tensor):\n",
        "        enc_x: CKKSVector = ts.ckks_vector(self.context, x.tolist()[0])\n",
        "        return enc_x\n",
        "\n",
        "ecg_client = EcgClient(torch_ref=torch, context=context)\n",
        "ecg_client_ptr = ecg_client.send(client)\n",
        "        "
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1632467776458
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to do a forward pass on the client's model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"init_weight.pth\")\n",
        "linear3_weight = checkpoint[\"linear3.weight\"]  # torch.Tensor size [128, 512]\n",
        "linear3_bias = checkpoint[\"linear3.bias\"]  # torch.Tensor size [128]\n",
        "linear4_weight = checkpoint[\"linear4.weight\"]  # torch.Tensor size [5, 128]\n",
        "linear4_bias = checkpoint[\"linear4.bias\"]  # torch.Tensor size [5]"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1632467779243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, b in enumerate(zip(train_rdl_ptr, enc_train_y)):\n",
        "    if i==0:\n",
        "        x_ptr, enc_y = b[0], b[1]\n",
        "        # ic(x_ptr, x_ptr.get_copy().shape, enc_y)\n",
        "        enc_activs: CKKSVector = ecg_client_ptr(x_ptr)\n",
        "        ic(enc_activs.size())\n",
        "        ic(enc_y.size())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/SyftEnv/lib/python3.9/site-packages/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  grad = getattr(obj, \"grad\", None)\nic| enc_activs.size(): 512\nic| enc_y.size(): 1\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1632467902735
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Server's side contains fully connected layers, trained on HE activation maps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EcgServer(sy.Module):\n",
        "    def __init__(self, torch_ref):\n",
        "        super(EcgServer, self).__init__(torch_ref=torch_ref)\n",
        "        self.linear3 = nn.Linear(32 * 16, 128)\n",
        "        self.relu3 = nn.LeakyReLU() \n",
        "        self.linear4 = nn.Linear(128, 5)\n",
        "        self.softmax4 = nn.Softmax(dim=1)\n",
        "\n",
        "        checkpoint = torch.load(\"init_weight.pth\")\n",
        "        self.linear3_weight = checkpoint[\"linear3.weight\"]  # torch.Tensor size [128, 512]\n",
        "        self.linear3_bias = checkpoint[\"linear3.bias\"]  # torch.Tensor size [128]\n",
        "        self.linear4_weight = checkpoint[\"linear4.weight\"]  # torch.Tensor size [5, 128]\n",
        "        self.linear4_bias = checkpoint[\"linear4.bias\"]  # torch.Tensor size [5]\n",
        "    \n",
        "    @staticmethod\n",
        "    def approx_leaky_relu(enc_x):\n",
        "        # 2.368475785867e-19*x**5 - 0.000252624921308674*x**4 - \n",
        "        # 2.90138283768708e-17*x**3 + 0.0660873211772537*x**2 + \n",
        "        # 0.500000000000001*x + 0.862730150341736\n",
        "        return enc_x.polyval([2.368475785867e-19, \n",
        "                              -0.000252624921308674, \n",
        "                              2.90138283768708e-17, \n",
        "                              0.0660873211772537,\n",
        "                              0.500000000000001,\n",
        "                              0.862730150341736])\n",
        "\n",
        "    def approx_softmax():\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, x: CKKSVector):\n",
        "        x = self.linear3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.linear4(x)\n",
        "        x = self.softmax4(x)\n",
        "        return x\n",
        "\n",
        "    def load_init_weights(self):\n",
        "        checkpoint = torch.load(\"init_weight.pth\")\n",
        "        self.linear3.weight.data = checkpoint[\"linear3.weight\"]\n",
        "        ic(self.linear3.weight.data.T.shape)\n",
        "        self.linear3.bias.data = checkpoint[\"linear3.bias\"]\n",
        "        ic(self.linear3.bias.data.shape)\n",
        "        self.linear4.weight.data = checkpoint[\"linear4.weight\"]\n",
        "        self.linear4.bias.data = checkpoint[\"linear4.bias\"]"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1631728164329
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_server = EcgServer(torch_ref=torch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ic| self.linear3_weight.shape: torch.Size([128, 512])\n    self.linear3_bias.shape: torch.Size([128])\n    self.linear4_weight.shape: torch.Size([5, 128])\n    self.linear4_bias.shape: torch.Size([5])\n"
        }
      ],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server: training process"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some hyper-parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = 414  # 32*414=13248. We have 13245 data samples\n",
        "\n",
        "epoch = 400\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "\n",
        "optim_client = remote_torch.optim.Adam(params=ecg_client_ptr.parameters(), lr=lr)\n",
        "optim_server = torch.optim.Adam(params=ecg_server.parameters(), lr=lr)\n",
        "\n",
        "seed = 0  # the meaning of life\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "remote_torch.manual_seed(seed)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1631728168564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training (with CPU)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = list()\n",
        "train_accs = list()\n",
        "test_losses = list()\n",
        "test_accs = list()\n",
        "best_test_acc = 0  # best test accuracy\n",
        "for e in range(epoch):\n",
        "    print(f\"Epoch {e+1} - train \", end='')\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for i, batch in enumerate(tqdm(train_rdl_ptr)):\n",
        "        x_ptr, y_gt_ptr = batch[0], batch[1]\n",
        "        # ic(x.get_copy(), y.get_copy())\n",
        "        # initialize all gradients to zero\n",
        "        optim_server.zero_grad()\n",
        "        optim_client.zero_grad()\n",
        "        # compute and get the activation signals from the first half of the network\n",
        "        activs_ptr = ecg_client_ptr(x_ptr)\n",
        "        # the server still gets access to plain activation signals\n",
        "        activs = activs_ptr.clone().get(request_block=True)\n",
        "        # the server continues the forward pass on the activation maps\n",
        "        y_hat = ecg_server(activs)\n",
        "        # the server asks to access ground truths in plain text\n",
        "        y_gt = y_gt_ptr.get_copy()\n",
        "        # calculates cross-entropy loss\n",
        "        loss = criterion(y_hat, y_gt)\n",
        "        train_loss += loss.item()\n",
        "        correct += torch.sum(y_hat.argmax(dim=1) == y_gt).item()\n",
        "        # backward propagation (calculating gradients of the loss w.r.t the weights)\n",
        "        loss.backward()\n",
        "        # send the gradients to the client\n",
        "        client_grad_ptr = activs.grad.clone().send(client)\n",
        "        # update the gradients of the client's model\n",
        "        activs_ptr.backward(client_grad_ptr)\n",
        "        # update the weights based on the gradients\n",
        "        optim_client.step()\n",
        "        optim_server.step()\n",
        "        total += len(y_gt)\n",
        "\n",
        "    train_losses.append(train_loss / total_batch)\n",
        "    train_accs.append(correct / total)\n",
        "\n",
        "    print(f'loss: {train_losses[-1]: .4f}, accuracy: {train_accs[-1]*100: 2f}')\n",
        "\n",
        "    # testing\n",
        "    with torch.no_grad():  \n",
        "        test_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for i, batch in enumerate(tqdm(test_rdl_ptr)):\n",
        "            x_ptr, y_gt_ptr = batch[0], batch[1]\n",
        "            # forward pass\n",
        "            activs_ptr = ecg_client_ptr(x_ptr)\n",
        "            activs = activs_ptr.clone().get(request_block=True)\n",
        "            y_hat = ecg_server(activs)\n",
        "            # the server asks to access ground truths in plain text\n",
        "            y_gt = y_gt_ptr.get_copy()\n",
        "            # calculate test loss\n",
        "            loss = criterion(y_hat, y_gt)\n",
        "            test_loss += loss.item()\n",
        "            correct += torch.sum(y_hat.argmax(dim=1) == y_gt).item()\n",
        "            total += len(y_gt)\n",
        "\n",
        "        test_losses.append(test_loss / total_batch)\n",
        "        test_accs.append(correct / total)\n",
        "        print(f'test_loss: {test_losses[-1]: .4f}, test_acc: {test_accs[-1]*100: 2f}')\n",
        "        \n",
        "    if test_accs[-1] > best_test_acc:\n",
        "        best_test_acc = test_accs[-1]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1 - train loss:  1.3243, accuracy:  59.041148\ntest_loss:  1.1502, test_acc:  78.391846\nEpoch 2 - train loss:  1.0875, accuracy:  83.057758\ntest_loss:  1.0550, test_acc:  85.730464\nEpoch 3 - train loss:  1.0533, accuracy:  85.654964\ntest_loss:  1.0352, test_acc:  87.180068\nEpoch 4 - train loss:  1.0423, accuracy:  86.621367\ntest_loss:  1.0261, test_acc:  88.070970\nEpoch 5 - train loss:  1.0350, accuracy:  87.240468\ntest_loss:  1.0218, test_acc:  88.478671\nEpoch 6 - train loss:  1.0306, accuracy:  87.580219\ntest_loss:  1.0184, test_acc:  88.682522\nEpoch 7 - train loss:  1.0270, accuracy:  87.889770\ntest_loss:  1.0208, test_acc:  88.614572\nEpoch 8 - train loss:  1.0258, accuracy:  87.950170\ntest_loss:  1.0208, test_acc:  88.493771\nEpoch 9 - train loss:  1.0245, accuracy:  88.101170\ntest_loss:  1.0184, test_acc:  88.659872\nEpoch 10 - train loss:  1.0216, accuracy:  88.289921\ntest_loss:  1.0123, test_acc:  89.188373\nEpoch 11 - train loss:  1.0219, accuracy:  88.244621\ntest_loss:  1.0139, test_acc:  89.014723\nEpoch 12 - train loss:  1.0201, accuracy:  88.463571\ntest_loss:  1.0134, test_acc:  89.158173\nEpoch 13 - train loss:  1.0198, accuracy:  88.463571\ntest_loss:  1.0107, test_acc:  89.294073\nEpoch 14 - train loss:  1.0178, accuracy:  88.599471\ntest_loss:  1.0084, test_acc:  89.445074\nEpoch 15 - train loss:  1.0166, accuracy:  88.735372\ntest_loss:  1.0092, test_acc:  89.497924\nEpoch 16 - train loss:  1.0128, accuracy:  89.135523\ntest_loss:  1.0077, test_acc:  89.558324\nEpoch 17 - train loss:  1.0123, accuracy:  89.097773\ntest_loss:  1.0078, test_acc:  89.596074\nEpoch 18 - train loss:  1.0118, accuracy:  89.263873\ntest_loss:  1.0129, test_acc:  89.165723\nEpoch 19 - train loss:  1.0115, accuracy:  89.188373\ntest_loss:  1.0074, test_acc:  89.626274\nEpoch 20 - train loss:  1.0117, accuracy:  89.173273\ntest_loss:  1.0052, test_acc:  89.799924\nEpoch 21 - train loss:  1.0096, accuracy:  89.437524\ntest_loss:  1.0028, test_acc:  90.026425\nEpoch 22 - train loss:  1.0085, accuracy:  89.475274\ntest_loss:  1.0040, test_acc:  89.935825\nEpoch 23 - train loss:  1.0083, accuracy:  89.513024\ntest_loss:  1.0047, test_acc:  89.867875\nEpoch 24 - train loss:  1.0081, accuracy:  89.558324\ntest_loss:  1.0063, test_acc:  89.769724\nEpoch 25 - train loss:  1.0087, accuracy:  89.452624\ntest_loss:  1.0046, test_acc:  89.830125\nEpoch 26 - train loss:  1.0078, accuracy:  89.573424\ntest_loss:  1.0044, test_acc:  89.860325\nEpoch 27 - train loss:  1.0063, accuracy:  89.724424\ntest_loss:  1.0036, test_acc:  90.026425\nEpoch 28 - train loss:  1.0071, accuracy:  89.603624\ntest_loss:  1.0052, test_acc:  89.845225\nEpoch 29 - train loss:  1.0057, accuracy:  89.724424\ntest_loss:  1.0023, test_acc:  90.018875\nEpoch 30 - train loss:  1.0064, accuracy:  89.679124\ntest_loss:  1.0018, test_acc:  90.169875\nEpoch 31 - train loss:  1.0051, accuracy:  89.754624\ntest_loss:  1.0017, test_acc:  90.132125\nEpoch 32 - train loss:  1.0055, accuracy:  89.754624\ntest_loss:  1.0011, test_acc:  90.117025\nEpoch 33 - train loss:  1.0046, accuracy:  89.799924\ntest_loss:  1.0043, test_acc:  89.943375\nEpoch 34 - train loss:  1.0046, accuracy:  89.875425\ntest_loss:  1.0011, test_acc:  90.200076\nEpoch 35 - train loss:  1.0063, accuracy:  89.656474\ntest_loss:  1.0058, test_acc:  89.845225\nEpoch 36 - train loss:  1.0056, accuracy:  89.694224\ntest_loss:  1.0006, test_acc:  90.154775\nEpoch 37 - train loss:  1.0052, accuracy:  89.754624\ntest_loss:  1.0024, test_acc:  90.003775\nEpoch 38 - train loss:  1.0032, accuracy:  89.928275\ntest_loss:  0.9985, test_acc:  90.403926\nEpoch 39 - train loss:  1.0044, accuracy:  89.815025\ntest_loss:  0.9990, test_acc:  90.335976\nEpoch 40 - train loss:  1.0024, accuracy:  90.018875\ntest_loss:  0.9981, test_acc:  90.419026\nEpoch 41 - train loss:  1.0027, accuracy:  90.003775\ntest_loss:  1.0003, test_acc:  90.230276\nEpoch 42 - train loss:  1.0022, accuracy:  90.018875\ntest_loss:  0.9989, test_acc:  90.320876\nEpoch 43 - train loss:  1.0007, accuracy:  90.139675\ntest_loss:  0.9968, test_acc:  90.554926\nEpoch 44 - train loss:  1.0018, accuracy:  90.064175\ntest_loss:  0.9996, test_acc:  90.222726\nEpoch 45 - train loss:  1.0023, accuracy:  89.996225\ntest_loss:  0.9964, test_acc:  90.547376\nEpoch 46 - train loss:  1.0008, accuracy:  90.154775\ntest_loss:  0.9974, test_acc:  90.441676\nEpoch 47 - train loss:  1.0010, accuracy:  90.139675\ntest_loss:  0.9990, test_acc:  90.320876\nEpoch 48 - train loss:  1.0006, accuracy:  90.177425\ntest_loss:  0.9985, test_acc:  90.381276\nEpoch 49 - train loss:  1.0000, accuracy:  90.215176\ntest_loss:  0.9965, test_acc:  90.562476\nEpoch 50 - train loss:  0.9993, accuracy:  90.298226\ntest_loss:  0.9970, test_acc:  90.524726\nEpoch 51 - train loss:  0.9992, accuracy:  90.252926\ntest_loss:  0.9963, test_acc:  90.562476\nEpoch 52 - train loss:  0.9984, accuracy:  90.358626\ntest_loss:  0.9964, test_acc:  90.479426\nEpoch 53 - train loss:  0.9998, accuracy:  90.230276\ntest_loss:  0.9974, test_acc:  90.449226\nEpoch 54 - train loss:  0.9992, accuracy:  90.283126\ntest_loss:  0.9969, test_acc:  90.449226\nEpoch 55 - train loss:  0.9990, accuracy:  90.320876\ntest_loss:  0.9963, test_acc:  90.554926\nEpoch 56 - train loss:  0.9993, accuracy:  90.268026\ntest_loss:  0.9956, test_acc:  90.622877\nEpoch 57 - train loss:  0.9976, accuracy:  90.403926\ntest_loss:  0.9961, test_acc:  90.577576\nEpoch 58 - train loss:  0.9996, accuracy:  90.215176\ntest_loss:  0.9961, test_acc:  90.577576\nEpoch 59 - train loss:  0.9983, accuracy:  90.373726\ntest_loss:  0.9948, test_acc:  90.683277\nEpoch 60 - train loss:  0.9964, accuracy:  90.532276\ntest_loss:  0.9945, test_acc:  90.683277\nEpoch 61 - train loss:  0.9955, accuracy:  90.607777\ntest_loss:  0.9941, test_acc:  90.766327\nEpoch 62 - train loss:  0.9967, accuracy:  90.539826\ntest_loss:  0.9971, test_acc:  90.539826\nEpoch 63 - train loss:  0.9978, accuracy:  90.441676\ntest_loss:  0.9981, test_acc:  90.464326\nEpoch 64 - train loss:  0.9977, accuracy:  90.411476\ntest_loss:  0.9954, test_acc:  90.705927\nEpoch 65 - train loss:  0.9956, accuracy:  90.645527\ntest_loss:  0.9938, test_acc:  90.841827\nEpoch 66 - train loss:  0.9957, accuracy:  90.630427\ntest_loss:  0.9935, test_acc:  90.804077\nEpoch 67 - train loss:  0.9952, accuracy:  90.637977\ntest_loss:  0.9941, test_acc:  90.743677\nEpoch 68 - train loss:  0.9954, accuracy:  90.660627\ntest_loss:  0.9938, test_acc:  90.773877\nEpoch 69 - train loss:  0.9959, accuracy:  90.562476\ntest_loss:  0.9942, test_acc:  90.743677\nEpoch 70 - train loss:  0.9956, accuracy:  90.570026\ntest_loss:  0.9935, test_acc:  90.804077\nEpoch 71 - train loss:  0.9936, accuracy:  90.788977\ntest_loss:  0.9931, test_acc:  90.872027\nEpoch 72 - train loss:  0.9920, accuracy:  90.939977\ntest_loss:  0.9926, test_acc:  90.909777\nEpoch 73 - train loss:  0.9927, accuracy:  90.872027\ntest_loss:  0.9923, test_acc:  90.932427\nEpoch 74 - train loss:  0.9926, accuracy:  90.909777\ntest_loss:  0.9945, test_acc:  90.758777\nEpoch 75 - train loss:  0.9925, accuracy:  90.932427\ntest_loss:  0.9920, test_acc:  90.977727\nEpoch 76 - train loss:  0.9935, accuracy:  90.811627\ntest_loss:  0.9946, test_acc:  90.705927\nEpoch 77 - train loss:  0.9921, accuracy:  90.962627\ntest_loss:  0.9906, test_acc:  91.106078\nEpoch 78 - train loss:  0.9894, accuracy:  91.257078\ntest_loss:  0.9952, test_acc:  90.660627\nEpoch 79 - train loss:  0.9862, accuracy:  91.536429\ntest_loss:  0.9889, test_acc:  91.234428\nEpoch 80 - train loss:  0.9835, accuracy:  91.793129\ntest_loss:  0.9820, test_acc:  92.034730\nEpoch 81 - train loss:  0.9808, accuracy:  92.072480\ntest_loss:  0.9818, test_acc:  91.981880\nEpoch 82 - train loss:  0.9783, accuracy:  92.359381\ntest_loss:  0.9805, test_acc:  92.110230\nEpoch 83 - train loss:  0.9772, accuracy:  92.442431\ntest_loss:  0.9797, test_acc:  92.155530\nEpoch 84 - train loss:  0.9788, accuracy:  92.246131\ntest_loss:  0.9795, test_acc:  92.253681\nEpoch 85 - train loss:  0.9767, accuracy:  92.517931\ntest_loss:  0.9791, test_acc:  92.246131\nEpoch 86 - train loss:  0.9763, accuracy:  92.533031\ntest_loss:  0.9780, test_acc:  92.397131\nEpoch 87 - train loss:  0.9766, accuracy:  92.510381\ntest_loss:  0.9782, test_acc:  92.321631\nEpoch 88 - train loss:  0.9743, accuracy:  92.721782\ntest_loss:  0.9774, test_acc:  92.374481\nEpoch 89 - train loss:  0.9747, accuracy:  92.699132\ntest_loss:  0.9774, test_acc:  92.412231\nEpoch 90 - train loss:  0.9737, accuracy:  92.835032\ntest_loss:  0.9770, test_acc:  92.419781\nEpoch 91 - train loss:  0.9734, accuracy:  92.835032\ntest_loss:  0.9783, test_acc:  92.374481\nEpoch 92 - train loss:  0.9746, accuracy:  92.691582\ntest_loss:  0.9769, test_acc:  92.449981\nEpoch 93 - train loss:  0.9362, accuracy:  96.896942\ntest_loss:  0.9383, test_acc:  96.776142\nEpoch 94 - train loss:  0.9315, accuracy:  97.387693\ntest_loss:  0.9379, test_acc:  96.776142\nEpoch 95 - train loss:  0.9292, accuracy:  97.636844\ntest_loss:  0.9373, test_acc:  96.791242\nEpoch 96 - train loss:  0.9293, accuracy:  97.606644\ntest_loss:  0.9354, test_acc:  96.957342\nEpoch 97 - train loss:  0.9290, accuracy:  97.629294\ntest_loss:  0.9347, test_acc:  97.032843\nEpoch 98 - train loss:  0.9302, accuracy:  97.508494\ntest_loss:  0.9361, test_acc:  96.874292\nEpoch 99 - train loss:  0.9284, accuracy:  97.667044\ntest_loss:  0.9335, test_acc:  97.063043\nEpoch 100 - train loss:  0.9253, accuracy:  97.991695\ntest_loss:  0.9312, test_acc:  97.395243\nEpoch 101 - train loss:  0.9241, accuracy:  98.120045\ntest_loss:  0.9362, test_acc:  96.896942\nEpoch 102 - train loss:  0.9246, accuracy:  98.067195\ntest_loss:  0.9309, test_acc:  97.417894\nEpoch 103 - train loss:  0.9233, accuracy:  98.195545\ntest_loss:  0.9310, test_acc:  97.395243\nEpoch 104 - train loss:  0.9251, accuracy:  97.976595\ntest_loss:  0.9345, test_acc:  97.055493\nEpoch 105 - train loss:  0.9242, accuracy:  98.112495\ntest_loss:  0.9309, test_acc:  97.380143\nEpoch 106 - train loss:  0.9229, accuracy:  98.240846\ntest_loss:  0.9305, test_acc:  97.463194\nEpoch 107 - train loss:  0.9233, accuracy:  98.210646\ntest_loss:  0.9353, test_acc:  96.934692\nEpoch 108 - train loss:  0.9252, accuracy:  98.006795\ntest_loss:  0.9380, test_acc:  96.700642\nEpoch 109 - train loss:  0.9274, accuracy:  97.780294\ntest_loss:  0.9339, test_acc:  97.123443\nEpoch 110 - train loss:  0.9269, accuracy:  97.757644\ntest_loss:  0.9330, test_acc:  97.153643\nEpoch 111 - train loss:  0.9241, accuracy:  98.135145\ntest_loss:  0.9286, test_acc:  97.621744\nEpoch 112 - train loss:  0.9223, accuracy:  98.286146\ntest_loss:  0.9293, test_acc:  97.568894\nEpoch 113 - train loss:  0.9224, accuracy:  98.263496\ntest_loss:  0.9328, test_acc:  97.183843\nEpoch 114 - train loss:  0.9232, accuracy:  98.195545\ntest_loss:  0.9294, test_acc:  97.546244\nEpoch 115 - train loss:  0.9229, accuracy:  98.233296\ntest_loss:  0.9322, test_acc:  97.266893\nEpoch 116 - train loss:  0.9239, accuracy:  98.067195\ntest_loss:  0.9348, test_acc:  97.047943\nEpoch 117 - train loss:  0.9216, accuracy:  98.346546\ntest_loss:  0.9306, test_acc:  97.372593\nEpoch 118 - train loss:  0.9220, accuracy:  98.308796\ntest_loss:  0.9304, test_acc:  97.455644\nEpoch 119 - train loss:  0.9243, accuracy:  98.067195\ntest_loss:  0.9284, test_acc:  97.644394\nEpoch 120 - train loss:  0.9221, accuracy:  98.301246\ntest_loss:  0.9309, test_acc:  97.380143\nEpoch 121 - train loss:  0.9220, accuracy:  98.316346\ntest_loss:  0.9301, test_acc:  97.493394\nEpoch 122 - train loss:  0.9215, accuracy:  98.391846\ntest_loss:  0.9305, test_acc:  97.410344\nEpoch 123 - train loss:  0.9215, accuracy:  98.376746\ntest_loss:  0.9363, test_acc:  96.851642\nEpoch 124 - train loss:  0.9216, accuracy:  98.346546\ntest_loss:  0.9286, test_acc:  97.538694\nEpoch 125 - train loss:  0.9207, accuracy:  98.429596\ntest_loss:  0.9305, test_acc:  97.402794\nEpoch 126 - train loss:  0.9207, accuracy:  98.406946\ntest_loss:  0.9290, test_acc:  97.599094\nEpoch 127 - train loss:  0.9198, accuracy:  98.527746\ntest_loss:  0.9285, test_acc:  97.583994\nEpoch 128 - train loss:  0.9201, accuracy:  98.512646\ntest_loss:  0.9265, test_acc:  97.818045\nEpoch 129 - train loss:  0.9223, accuracy:  98.271046\ntest_loss:  0.9320, test_acc:  97.229143\nEpoch 130 - train loss:  0.9199, accuracy:  98.542846\ntest_loss:  0.9258, test_acc:  97.938845\nEpoch 131 - train loss:  0.9191, accuracy:  98.610797\ntest_loss:  0.9301, test_acc:  97.485844\nEpoch 132 - train loss:  0.9188, accuracy:  98.625897\ntest_loss:  0.9247, test_acc:  97.991695\nEpoch 133 - train loss:  0.9189, accuracy:  98.588146\ntest_loss:  0.9268, test_acc:  97.780294\nEpoch 134 - train loss:  0.9209, accuracy:  98.376746\ntest_loss:  0.9265, test_acc:  97.893545\nEpoch 135 - train loss:  0.9192, accuracy:  98.595696\ntest_loss:  0.9274, test_acc:  97.719894\nEpoch 136 - train loss:  0.9190, accuracy:  98.618347\ntest_loss:  0.9283, test_acc:  97.644394\nEpoch 137 - train loss:  0.9205, accuracy:  98.444696\ntest_loss:  0.9251, test_acc:  97.938845\nEpoch 138 - train loss:  0.9182, accuracy:  98.686297\ntest_loss:  0.9253, test_acc:  97.938845\nEpoch 139 - train loss:  0.9187, accuracy:  98.618347\ntest_loss:  0.9277, test_acc:  97.704794\nEpoch 140 - train loss:  0.9193, accuracy:  98.580596\ntest_loss:  0.9257, test_acc:  97.923745\nEpoch 141 - train loss:  0.9185, accuracy:  98.625897\ntest_loss:  0.9323, test_acc:  97.214043\nEpoch 142 - train loss:  0.9196, accuracy:  98.535296\ntest_loss:  0.9267, test_acc:  97.810495\nEpoch 143 - train loss:  0.9180, accuracy:  98.716497\ntest_loss:  0.9341, test_acc:  97.063043\nEpoch 144 - train loss:  0.9194, accuracy:  98.550396\ntest_loss:  0.9269, test_acc:  97.795394\nEpoch 145 - train loss:  0.9179, accuracy:  98.731597\ntest_loss:  0.9249, test_acc:  98.052095\nEpoch 146 - train loss:  0.9172, accuracy:  98.769347\ntest_loss:  0.9295, test_acc:  97.523594\nEpoch 147 - train loss:  0.9181, accuracy:  98.693847\ntest_loss:  0.9266, test_acc:  97.750094\nEpoch 148 - train loss:  0.9171, accuracy:  98.784447\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 149 - train loss:  0.9184, accuracy:  98.633447\ntest_loss:  0.9325, test_acc:  97.221593\nEpoch 150 - train loss:  0.9196, accuracy:  98.557946\ntest_loss:  0.9277, test_acc:  97.682144\nEpoch 151 - train loss:  0.9175, accuracy:  98.754247\ntest_loss:  0.9260, test_acc:  97.863345\nEpoch 152 - train loss:  0.9175, accuracy:  98.754247\ntest_loss:  0.9298, test_acc:  97.485844\nEpoch 153 - train loss:  0.9173, accuracy:  98.761797\ntest_loss:  0.9251, test_acc:  97.946395\nEpoch 154 - train loss:  0.9185, accuracy:  98.663647\ntest_loss:  0.9256, test_acc:  97.901095\nEpoch 155 - train loss:  0.9174, accuracy:  98.754247\ntest_loss:  0.9258, test_acc:  97.916195\nEpoch 156 - train loss:  0.9171, accuracy:  98.791997\ntest_loss:  0.9266, test_acc:  97.787844\nEpoch 157 - train loss:  0.9181, accuracy:  98.648547\ntest_loss:  0.9262, test_acc:  97.863345\nEpoch 158 - train loss:  0.9164, accuracy:  98.859947\ntest_loss:  0.9272, test_acc:  97.757644\nEpoch 159 - train loss:  0.9169, accuracy:  98.799547\ntest_loss:  0.9243, test_acc:  98.059645\nEpoch 160 - train loss:  0.9163, accuracy:  98.875047\ntest_loss:  0.9268, test_acc:  97.825595\nEpoch 161 - train loss:  0.9197, accuracy:  98.497546\ntest_loss:  0.9266, test_acc:  97.840695\nEpoch 162 - train loss:  0.9184, accuracy:  98.648547\ntest_loss:  0.9283, test_acc:  97.644394\nEpoch 163 - train loss:  0.9174, accuracy:  98.739147\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 164 - train loss:  0.9158, accuracy:  98.935447\ntest_loss:  0.9255, test_acc:  97.931295\nEpoch 165 - train loss:  0.9171, accuracy:  98.776897\ntest_loss:  0.9261, test_acc:  97.848245\nEpoch 166 - train loss:  0.9174, accuracy:  98.784447\ntest_loss:  0.9272, test_acc:  97.780294\nEpoch 167 - train loss:  0.9189, accuracy:  98.573046\ntest_loss:  0.9280, test_acc:  97.674594\nEpoch 168 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9242, test_acc:  98.067195\nEpoch 169 - train loss:  0.9173, accuracy:  98.754247\ntest_loss:  0.9255, test_acc:  97.916195\nEpoch 170 - train loss:  0.9173, accuracy:  98.746697\ntest_loss:  0.9254, test_acc:  97.923745\nEpoch 171 - train loss:  0.9160, accuracy:  98.912797\ntest_loss:  0.9260, test_acc:  97.870895\nEpoch 172 - train loss:  0.9163, accuracy:  98.859947\ntest_loss:  0.9256, test_acc:  97.916195\nEpoch 173 - train loss:  0.9167, accuracy:  98.837297\ntest_loss:  0.9250, test_acc:  97.961495\nEpoch 174 - train loss:  0.9166, accuracy:  98.837297\ntest_loss:  0.9279, test_acc:  97.689694\nEpoch 175 - train loss:  0.9165, accuracy:  98.822197\ntest_loss:  0.9264, test_acc:  97.840695\nEpoch 176 - train loss:  0.9162, accuracy:  98.867497\ntest_loss:  0.9245, test_acc:  98.014345\nEpoch 177 - train loss:  0.9163, accuracy:  98.875047\ntest_loss:  0.9240, test_acc:  98.052095\nEpoch 178 - train loss:  0.9173, accuracy:  98.784447\ntest_loss:  0.9249, test_acc:  98.044545\nEpoch 179 - train loss:  0.9178, accuracy:  98.708947\ntest_loss:  0.9232, test_acc:  98.150245\nEpoch 180 - train loss:  0.9158, accuracy:  98.912797\ntest_loss:  0.9252, test_acc:  97.961495\nEpoch 181 - train loss:  0.9158, accuracy:  98.912797\ntest_loss:  0.9235, test_acc:  98.104945\nEpoch 182 - train loss:  0.9151, accuracy:  99.003398\ntest_loss:  0.9236, test_acc:  98.135145\nEpoch 183 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9259, test_acc:  97.893545\nEpoch 184 - train loss:  0.9161, accuracy:  98.867497\ntest_loss:  0.9263, test_acc:  97.840695\nEpoch 185 - train loss:  0.9176, accuracy:  98.739147\ntest_loss:  0.9257, test_acc:  97.931295\nEpoch 186 - train loss:  0.9176, accuracy:  98.731597\ntest_loss:  0.9242, test_acc:  98.067195\nEpoch 187 - train loss:  0.9161, accuracy:  98.897697\ntest_loss:  0.9234, test_acc:  98.127595\nEpoch 188 - train loss:  0.9148, accuracy:  99.026048\ntest_loss:  0.9252, test_acc:  97.961495\nEpoch 189 - train loss:  0.9162, accuracy:  98.882597\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 190 - train loss:  0.9166, accuracy:  98.822197\ntest_loss:  0.9242, test_acc:  98.052095\nEpoch 191 - train loss:  0.9168, accuracy:  98.807097\ntest_loss:  0.9251, test_acc:  97.961495\nEpoch 192 - train loss:  0.9174, accuracy:  98.746697\ntest_loss:  0.9238, test_acc:  98.059645\nEpoch 193 - train loss:  0.9160, accuracy:  98.890147\ntest_loss:  0.9230, test_acc:  98.203096\nEpoch 194 - train loss:  0.9163, accuracy:  98.867497\ntest_loss:  0.9272, test_acc:  97.734994\nEpoch 195 - train loss:  0.9174, accuracy:  98.739147\ntest_loss:  0.9277, test_acc:  97.712344\nEpoch 196 - train loss:  0.9176, accuracy:  98.731597\ntest_loss:  0.9241, test_acc:  98.052095\nEpoch 197 - train loss:  0.9165, accuracy:  98.844847\ntest_loss:  0.9381, test_acc:  96.670442\nEpoch 198 - train loss:  0.9169, accuracy:  98.776897\ntest_loss:  0.9241, test_acc:  98.082295\nEpoch 199 - train loss:  0.9158, accuracy:  98.927897\ntest_loss:  0.9225, test_acc:  98.240846\nEpoch 200 - train loss:  0.9169, accuracy:  98.791997\ntest_loss:  0.9239, test_acc:  98.104945\nEpoch 201 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9236, test_acc:  98.127595\nEpoch 202 - train loss:  0.9152, accuracy:  98.958097\ntest_loss:  0.9238, test_acc:  98.089845\nEpoch 203 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9261, test_acc:  97.870895\nEpoch 204 - train loss:  0.9147, accuracy:  99.018498\ntest_loss:  0.9226, test_acc:  98.187995\nEpoch 205 - train loss:  0.9154, accuracy:  98.942997\ntest_loss:  0.9235, test_acc:  98.127595\nEpoch 206 - train loss:  0.9172, accuracy:  98.754247\ntest_loss:  0.9244, test_acc:  98.044545\nEpoch 207 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9235, test_acc:  98.120045\nEpoch 208 - train loss:  0.9154, accuracy:  98.958097\ntest_loss:  0.9269, test_acc:  97.780294\nEpoch 209 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9222, test_acc:  98.263496\nEpoch 210 - train loss:  0.9149, accuracy:  98.995847\ntest_loss:  0.9241, test_acc:  98.082295\nEpoch 211 - train loss:  0.9154, accuracy:  98.927897\ntest_loss:  0.9245, test_acc:  98.014345\nEpoch 212 - train loss:  0.9170, accuracy:  98.799547\ntest_loss:  0.9282, test_acc:  97.606644\nEpoch 213 - train loss:  0.9161, accuracy:  98.875047\ntest_loss:  0.9255, test_acc:  97.961495\nEpoch 214 - train loss:  0.9157, accuracy:  98.920347\ntest_loss:  0.9260, test_acc:  97.870895\nEpoch 215 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9244, test_acc:  98.029445\nEpoch 216 - train loss:  0.9154, accuracy:  98.958097\ntest_loss:  0.9263, test_acc:  97.818045\nEpoch 217 - train loss:  0.9152, accuracy:  98.973197\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 218 - train loss:  0.9158, accuracy:  98.905247\ntest_loss:  0.9245, test_acc:  98.036995\nEpoch 219 - train loss:  0.9166, accuracy:  98.829747\ntest_loss:  0.9237, test_acc:  98.150245\nEpoch 220 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9248, test_acc:  98.029445\nEpoch 221 - train loss:  0.9151, accuracy:  98.988297\ntest_loss:  0.9231, test_acc:  98.172895\nEpoch 222 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9227, test_acc:  98.225746\nEpoch 223 - train loss:  0.9149, accuracy:  99.010948\ntest_loss:  0.9266, test_acc:  97.833145\nEpoch 224 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9268, test_acc:  97.780294\nEpoch 225 - train loss:  0.9150, accuracy:  98.973197\ntest_loss:  0.9238, test_acc:  98.104945\nEpoch 226 - train loss:  0.9151, accuracy:  98.973197\ntest_loss:  0.9262, test_acc:  97.840695\nEpoch 227 - train loss:  0.9168, accuracy:  98.822197\ntest_loss:  0.9252, test_acc:  97.953945\nEpoch 228 - train loss:  0.9157, accuracy:  98.927897\ntest_loss:  0.9254, test_acc:  97.916195\nEpoch 229 - train loss:  0.9170, accuracy:  98.784447\ntest_loss:  0.9260, test_acc:  97.863345\nEpoch 230 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9238, test_acc:  98.097395\nEpoch 231 - train loss:  0.9149, accuracy:  99.003398\ntest_loss:  0.9245, test_acc:  97.999245\nEpoch 232 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9225, test_acc:  98.233296\nEpoch 233 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 234 - train loss:  0.9161, accuracy:  98.890147\ntest_loss:  0.9250, test_acc:  97.991695\nEpoch 235 - train loss:  0.9167, accuracy:  98.829747\ntest_loss:  0.9232, test_acc:  98.165345\nEpoch 236 - train loss:  0.9164, accuracy:  98.867497\ntest_loss:  0.9255, test_acc:  97.916195\nEpoch 237 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 238 - train loss:  0.9147, accuracy:  99.026048\ntest_loss:  0.9234, test_acc:  98.104945\nEpoch 239 - train loss:  0.9148, accuracy:  98.980747\ntest_loss:  0.9228, test_acc:  98.203096\nEpoch 240 - train loss:  0.9160, accuracy:  98.875047\ntest_loss:  0.9242, test_acc:  98.052095\nEpoch 241 - train loss:  0.9185, accuracy:  98.625897\ntest_loss:  0.9235, test_acc:  98.104945\nEpoch 242 - train loss:  0.9151, accuracy:  98.973197\ntest_loss:  0.9230, test_acc:  98.180445\nEpoch 243 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9234, test_acc:  98.150245\nEpoch 244 - train loss:  0.9152, accuracy:  98.950547\ntest_loss:  0.9263, test_acc:  97.833145\nEpoch 245 - train loss:  0.9166, accuracy:  98.822197\ntest_loss:  0.9240, test_acc:  98.052095\nEpoch 246 - train loss:  0.9153, accuracy:  98.942997\ntest_loss:  0.9231, test_acc:  98.157795\nEpoch 247 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 248 - train loss:  0.9156, accuracy:  98.912797\ntest_loss:  0.9243, test_acc:  98.036995\nEpoch 249 - train loss:  0.9150, accuracy:  98.980747\ntest_loss:  0.9250, test_acc:  97.953945\nEpoch 250 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 251 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9240, test_acc:  98.059645\nEpoch 252 - train loss:  0.9150, accuracy:  98.988297\ntest_loss:  0.9244, test_acc:  97.999245\nEpoch 253 - train loss:  0.9156, accuracy:  98.920347\ntest_loss:  0.9247, test_acc:  97.991695\nEpoch 254 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9235, test_acc:  98.112495\nEpoch 255 - train loss:  0.9150, accuracy:  98.995847\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 256 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9242, test_acc:  98.044545\nEpoch 257 - train loss:  0.9148, accuracy:  98.995847\ntest_loss:  0.9239, test_acc:  98.074745\nEpoch 258 - train loss:  0.9159, accuracy:  98.905247\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 259 - train loss:  0.9141, accuracy:  99.086448\ntest_loss:  0.9239, test_acc:  98.052095\nEpoch 260 - train loss:  0.9158, accuracy:  98.905247\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 261 - train loss:  0.9145, accuracy:  99.026048\ntest_loss:  0.9230, test_acc:  98.150245\nEpoch 262 - train loss:  0.9141, accuracy:  99.078898\ntest_loss:  0.9314, test_acc:  97.289543\nEpoch 263 - train loss:  0.9155, accuracy:  98.950547\ntest_loss:  0.9237, test_acc:  98.089845\nEpoch 264 - train loss:  0.9150, accuracy:  99.003398\ntest_loss:  0.9246, test_acc:  98.044545\nEpoch 265 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9234, test_acc:  98.120045\nEpoch 266 - train loss:  0.9148, accuracy:  99.010948\ntest_loss:  0.9233, test_acc:  98.127595\nEpoch 267 - train loss:  0.9140, accuracy:  99.086448\ntest_loss:  0.9233, test_acc:  98.142695\nEpoch 268 - train loss:  0.9142, accuracy:  99.063798\ntest_loss:  0.9235, test_acc:  98.097395\nEpoch 269 - train loss:  0.9161, accuracy:  98.867497\ntest_loss:  0.9222, test_acc:  98.263496\nEpoch 270 - train loss:  0.9150, accuracy:  98.988297\ntest_loss:  0.9245, test_acc:  98.006795\nEpoch 271 - train loss:  0.9157, accuracy:  98.935447\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 272 - train loss:  0.9148, accuracy:  99.010948\ntest_loss:  0.9254, test_acc:  97.938845\nEpoch 273 - train loss:  0.9151, accuracy:  98.980747\ntest_loss:  0.9222, test_acc:  98.271046\nEpoch 274 - train loss:  0.9153, accuracy:  98.958097\ntest_loss:  0.9238, test_acc:  98.074745\nEpoch 275 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 276 - train loss:  0.9143, accuracy:  99.041148\ntest_loss:  0.9232, test_acc:  98.150245\nEpoch 277 - train loss:  0.9138, accuracy:  99.101548\ntest_loss:  0.9227, test_acc:  98.203096\nEpoch 278 - train loss:  0.9150, accuracy:  98.980747\ntest_loss:  0.9253, test_acc:  97.931295\nEpoch 279 - train loss:  0.9153, accuracy:  98.942997\ntest_loss:  0.9239, test_acc:  98.082295\nEpoch 280 - train loss:  0.9150, accuracy:  98.995847\ntest_loss:  0.9239, test_acc:  98.089845\nEpoch 281 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9235, test_acc:  98.112495\nEpoch 282 - train loss:  0.9159, accuracy:  98.890147\ntest_loss:  0.9233, test_acc:  98.127595\nEpoch 283 - train loss:  0.9140, accuracy:  99.093998\ntest_loss:  0.9228, test_acc:  98.187995\nEpoch 284 - train loss:  0.9137, accuracy:  99.116648\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 285 - train loss:  0.9154, accuracy:  98.950547\ntest_loss:  0.9227, test_acc:  98.187995\nEpoch 286 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 287 - train loss:  0.9183, accuracy:  98.648547\ntest_loss:  0.9256, test_acc:  97.931295\nEpoch 288 - train loss:  0.9152, accuracy:  98.942997\ntest_loss:  0.9239, test_acc:  98.089845\nEpoch 289 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9234, test_acc:  98.135145\nEpoch 290 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9235, test_acc:  98.120045\nEpoch 291 - train loss:  0.9138, accuracy:  99.109098\ntest_loss:  0.9234, test_acc:  98.165345\nEpoch 292 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9231, test_acc:  98.180445\nEpoch 293 - train loss:  0.9133, accuracy:  99.154398\ntest_loss:  0.9229, test_acc:  98.180445\nEpoch 294 - train loss:  0.9136, accuracy:  99.116648\ntest_loss:  0.9312, test_acc:  97.342393\nEpoch 295 - train loss:  0.9160, accuracy:  98.890147\ntest_loss:  0.9279, test_acc:  97.659494\nEpoch 296 - train loss:  0.9184, accuracy:  98.633447\ntest_loss:  0.9240, test_acc:  98.074745\nEpoch 297 - train loss:  0.9151, accuracy:  98.965647\ntest_loss:  0.9251, test_acc:  97.953945\nEpoch 298 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9232, test_acc:  98.187995\nEpoch 299 - train loss:  0.9158, accuracy:  98.890147\ntest_loss:  0.9231, test_acc:  98.150245\nEpoch 300 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9238, test_acc:  98.104945\nEpoch 301 - train loss:  0.9143, accuracy:  99.056248\ntest_loss:  0.9230, test_acc:  98.172895\nEpoch 302 - train loss:  0.9165, accuracy:  98.844847\ntest_loss:  0.9236, test_acc:  98.142695\nEpoch 303 - train loss:  0.9158, accuracy:  98.897697\ntest_loss:  0.9222, test_acc:  98.255946\nEpoch 304 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9234, test_acc:  98.180445\nEpoch 305 - train loss:  0.9141, accuracy:  99.063798\ntest_loss:  0.9244, test_acc:  98.021895\nEpoch 306 - train loss:  0.9142, accuracy:  99.056248\ntest_loss:  0.9224, test_acc:  98.255946\nEpoch 307 - train loss:  0.9142, accuracy:  99.071348\ntest_loss:  0.9245, test_acc:  98.021895\nEpoch 308 - train loss:  0.9140, accuracy:  99.071348\ntest_loss:  0.9220, test_acc:  98.278596\nEpoch 309 - train loss:  0.9134, accuracy:  99.146848\ntest_loss:  0.9224, test_acc:  98.271046\nEpoch 310 - train loss:  0.9137, accuracy:  99.109098\ntest_loss:  0.9229, test_acc:  98.187995\nEpoch 311 - train loss:  0.9137, accuracy:  99.109098\ntest_loss:  0.9244, test_acc:  98.036995\nEpoch 312 - train loss:  0.9139, accuracy:  99.101548\ntest_loss:  0.9222, test_acc:  98.255946\nEpoch 313 - train loss:  0.9151, accuracy:  98.958097\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 314 - train loss:  0.9143, accuracy:  99.048698\ntest_loss:  0.9238, test_acc:  98.089845\nEpoch 315 - train loss:  0.9151, accuracy:  98.988297\ntest_loss:  0.9223, test_acc:  98.255946\nEpoch 316 - train loss:  0.9132, accuracy:  99.161948\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 317 - train loss:  0.9142, accuracy:  99.063798\ntest_loss:  0.9236, test_acc:  98.112495\nEpoch 318 - train loss:  0.9151, accuracy:  98.965647\ntest_loss:  0.9237, test_acc:  98.089845\nEpoch 319 - train loss:  0.9147, accuracy:  99.003398\ntest_loss:  0.9239, test_acc:  98.104945\nEpoch 320 - train loss:  0.9154, accuracy:  98.927897\ntest_loss:  0.9236, test_acc:  98.127595\nEpoch 321 - train loss:  0.9159, accuracy:  98.897697\ntest_loss:  0.9229, test_acc:  98.195545\nEpoch 322 - train loss:  0.9145, accuracy:  99.033598\ntest_loss:  0.9256, test_acc:  97.901095\nEpoch 323 - train loss:  0.9135, accuracy:  99.131748\ntest_loss:  0.9227, test_acc:  98.225746\nEpoch 324 - train loss:  0.9154, accuracy:  98.942997\ntest_loss:  0.9237, test_acc:  98.120045\nEpoch 325 - train loss:  0.9146, accuracy:  99.041148\ntest_loss:  0.9227, test_acc:  98.203096\nEpoch 326 - train loss:  0.9141, accuracy:  99.086448\ntest_loss:  0.9225, test_acc:  98.225746\nEpoch 327 - train loss:  0.9149, accuracy:  98.965647\ntest_loss:  0.9247, test_acc:  97.999245\nEpoch 328 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9252, test_acc:  97.953945\nEpoch 329 - train loss:  0.9144, accuracy:  99.056248\ntest_loss:  0.9226, test_acc:  98.187995\nEpoch 330 - train loss:  0.9140, accuracy:  99.071348\ntest_loss:  0.9237, test_acc:  98.157795\nEpoch 331 - train loss:  0.9138, accuracy:  99.109098\ntest_loss:  0.9226, test_acc:  98.203096\nEpoch 332 - train loss:  0.9138, accuracy:  99.093998\ntest_loss:  0.9232, test_acc:  98.157795\nEpoch 333 - train loss:  0.9155, accuracy:  98.912797\ntest_loss:  0.9243, test_acc:  98.044545\nEpoch 334 - train loss:  0.9140, accuracy:  99.093998\ntest_loss:  0.9244, test_acc:  98.029445\nEpoch 335 - train loss:  0.9130, accuracy:  99.192148\ntest_loss:  0.9231, test_acc:  98.172895\nEpoch 336 - train loss:  0.9145, accuracy:  99.018498\ntest_loss:  0.9250, test_acc:  97.961495\nEpoch 337 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9285, test_acc:  97.621744\nEpoch 338 - train loss:  0.9148, accuracy:  99.003398\ntest_loss:  0.9232, test_acc:  98.157795\nEpoch 339 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9236, test_acc:  98.104945\nEpoch 340 - train loss:  0.9134, accuracy:  99.146848\ntest_loss:  0.9233, test_acc:  98.150245\nEpoch 341 - train loss:  0.9152, accuracy:  98.965647\ntest_loss:  0.9231, test_acc:  98.157795\nEpoch 342 - train loss:  0.9147, accuracy:  99.033598\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 343 - train loss:  0.9139, accuracy:  99.109098\ntest_loss:  0.9253, test_acc:  97.938845\nEpoch 344 - train loss:  0.9136, accuracy:  99.124198\ntest_loss:  0.9223, test_acc:  98.248396\nEpoch 345 - train loss:  0.9134, accuracy:  99.139298\ntest_loss:  0.9255, test_acc:  97.938845\nEpoch 346 - train loss:  0.9149, accuracy:  98.988297\ntest_loss:  0.9237, test_acc:  98.112495\nEpoch 347 - train loss:  0.9159, accuracy:  98.905247\ntest_loss:  0.9227, test_acc:  98.210646\nEpoch 348 - train loss:  0.9144, accuracy:  99.048698\ntest_loss:  0.9341, test_acc:  97.032843\nEpoch 349 - train loss:  0.9142, accuracy:  99.041148\ntest_loss:  0.9227, test_acc:  98.195545\nEpoch 350 - train loss:  0.9133, accuracy:  99.146848\ntest_loss:  0.9225, test_acc:  98.225746\nEpoch 351 - train loss:  0.9148, accuracy:  99.018498\ntest_loss:  0.9224, test_acc:  98.233296\nEpoch 352 - train loss:  0.9133, accuracy:  99.154398\ntest_loss:  0.9230, test_acc:  98.195545\nEpoch 353 - train "
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/414 [00:00<?, ?it/s]/anaconda/envs/SyftEnv/lib/python3.9/site-packages/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  grad = getattr(obj, \"grad\", None)\n100%|██████████| 414/414 [01:05<00:00,  6.31it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.66it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.78it/s]\n100%|██████████| 414/414 [01:09<00:00,  5.99it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.78it/s]\n100%|██████████| 414/414 [01:00<00:00,  6.81it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:05<00:00,  6.28it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.63it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.63it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.62it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.62it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.62it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:10<00:00,  5.88it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [01:06<00:00,  6.18it/s]\n100%|██████████| 414/414 [01:50<00:00,  3.76it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:45<00:00,  3.91it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.04it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.11it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:04<00:00,  6.43it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.02it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.77it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:37<00:00,  4.23it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.03it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.11it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.09it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.52it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:59<00:00,  7.01it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.51it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.11it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.07it/s]\n100%|██████████| 414/414 [01:22<00:00,  5.03it/s]\n100%|██████████| 414/414 [01:09<00:00,  5.95it/s]\n100%|██████████| 414/414 [01:53<00:00,  3.65it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:31<00:00,  4.50it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:06<00:00,  6.25it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.07it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.50it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.10it/s]\n100%|██████████| 414/414 [01:04<00:00,  6.46it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.09it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.50it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.11it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.52it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.10it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.11it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.10it/s]\n100%|██████████| 414/414 [01:52<00:00,  3.68it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:50<00:00,  3.74it/s]\n100%|██████████| 414/414 [01:04<00:00,  6.38it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:06<00:00,  6.25it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.77it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.02it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.78it/s]\n100%|██████████| 414/414 [00:59<00:00,  6.97it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.61it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:59<00:00,  7.01it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.51it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.13it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.04it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.77it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:43<00:00,  3.99it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.02it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.04it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:13<00:00,  5.64it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.00it/s]\n100%|██████████| 414/414 [01:49<00:00,  3.77it/s]\n100%|██████████| 414/414 [01:09<00:00,  6.00it/s]\n100%|██████████| 414/414 [01:29<00:00,  4.63it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:05<00:00,  6.28it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.09it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.59it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:26<00:00,  4.77it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:52<00:00,  3.69it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:17<00:00,  5.34it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.02it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.52it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.60it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.10it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.52it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.12it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.52it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:45<00:00,  3.93it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.01it/s]\n100%|██████████| 414/414 [01:50<00:00,  3.75it/s]\n100%|██████████| 414/414 [01:07<00:00,  6.11it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.58it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [01:00<00:00,  6.80it/s]\n100%|██████████| 414/414 [01:50<00:00,  3.76it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.03it/s]\n100%|██████████| 414/414 [01:51<00:00,  3.70it/s]\n100%|██████████| 414/414 [01:01<00:00,  6.72it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:06<00:00,  6.24it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:02<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.57it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.48it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.47it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [01:07<00:00,  6.18it/s]\n100%|██████████| 414/414 [01:50<00:00,  3.73it/s]\n100%|██████████| 414/414 [01:09<00:00,  5.95it/s]\n100%|██████████| 414/414 [01:47<00:00,  3.86it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.15it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:58<00:00,  7.14it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.55it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.19it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.56it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.53it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.17it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.16it/s]\n100%|██████████| 414/414 [01:03<00:00,  6.54it/s]\n100%|██████████| 414/414 [00:57<00:00,  7.18it/s]\n100%|██████████| 414/414 [01:16<00:00,  5.38it/s]\n100%|██████████| 414/414 [01:08<00:00,  6.03it/s]\n100%|██████████| 414/414 [01:53<00:00,  3.66it/s]\n100%|██████████| 414/414 [01:09<00:00,  5.95it/s]\n 73%|███████▎  | 302/414 [01:08<00:16,  6.61it/s]"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1631695917428
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d8c1a441a5f9f7733d33e10332ba6605fc14f14734f8e602f9ed7877aacd3dd5"
    },
    "kernel_info": {
      "name": "syftenv"
    },
    "kernelspec": {
      "name": "syftenv",
      "language": "python",
      "display_name": "syft"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}